\chapter{Symbolic calculus}
\label{chapter:symbolic_calculus}

\section{Difference operators}

The Euclidean case uses estimates on the derivatives in Fourier variables of the symbol
to ensure crucial properties of the convolution kernels,
such as the smoothness and Schwartz decay away from the origin,
but also the Calder\'on-Zygmund property of pseudo-differential operators of order $0$.

In~\cite{RuzhanskyTurunen10},
\citeauthor{RuzhanskyTurunen10} introduce the concept of \emph{difference operator}
to generalize the aforementioned derivatives in Fourier variables
and obtain a pseudo-differential calculus on compact Lie groups.

\begin{definition}
\label{definition:difference_operators}
    Let $q \in \SmoothFunctions{\Group}$.
    The \emph{difference operator} associated with $q$, $\DifferenceOperator{q}$ is defined via
    \begin{align*}
        \DifferenceOperator{q} \Fourier f \defeq \Fourier\{q f\},
    \end{align*}
    where $f \in \Schwartz{\Group}$.

    Moreover, if $q$ vanishes up to order $k \in \N$,
    we shall say that $\DifferenceOperator{q}$ is a \emph{difference operator of order $k$}.
\end{definition}

In our definition of symbol classes,
we shall require that the order of our differential operator decrease
every time we apply difference operators from a well-chosen family of smooth functions.

It is thus important to show that this condition is not too restrictive,
which is the aim of the next statement.
As we intend for our symbol classes to contain characteristic polynomials,
we show that applying difference operators \emph{reduces} the order.

\begin{lemma}[Difference operators on characteristic polynomials]
\label{lemma:difference_operators_on_characteristic_polynomials}
    Let $q \in \SmoothFunctions \Group$.
    For every $\alpha \in \N^{\dim \Group}$,
    we have the formula
    \begin{align*}
        \DifferenceOperator q \Rep \lambda(\LeftDifferentialOperator \alpha)
        =
        \sum_{\beta \leq \alpha} \binom \alpha \beta
        (-1)^{\abs \beta}
        \LeftDifferentialOperator \beta q(e_\Group)
        \Rep \lambda(\LeftDifferentialOperator {\alpha - \beta}).
    \end{align*}

    In particular,
    if $\DifferenceOperator q$ is a difference operator of order $k$,
    then $\DifferenceOperator q \Rep \lambda(\LeftDifferentialOperator \alpha)$ is the characteristic polynomial of a differential operator with order $\abs \alpha - k$.
\end{lemma}
\begin{proof}
    By definition of difference operator,
    we have
    \begin{align*}
        \DifferenceOperator q \Rep \lambda(\LeftDifferentialOperator \alpha)
        = (-1)^\alpha \Fourier \{q \LeftDifferentialOperator \alpha \delta_{e_\Group}\}
    \end{align*}

    Let $H \in \Schwartz {\dualGroup \Group}$ and write
    \begin{align*}
        h \defeq \iota \circ \InverseFourier H.
    \end{align*}
    Using the definition of Fourier transform on distributions,
    we know that
    \begin{align}
        \dualBracket [\dualGroup \Group] {%
            \Fourier \{ q \LeftDifferentialOperator \alpha \delta_{e_\Group} \}
        } H
        =
        \dualBracket [\Group] {%
            q \LeftDifferentialOperator \alpha \delta_{e_\Group}
        } h
        =
        (-1)^{\abs \alpha}
        \dualBracket [\Group] {\delta_{e_\Group}} {\LeftDifferentialOperator \alpha (qh)}
        \label{eq:difference_operator_of_X_alpha}
    \end{align}

    Using the Leibniz rule,
    we know that
    \begin{align*}
        \dualBracket [\Group] {\delta_{e_\Group}} {\LeftDifferentialOperator \alpha (qh)}
        &=
        \sum_{\beta \leq \alpha} \binom \alpha \beta
        \dualBracket [\Group] {\delta_{e_\Group}} {\LeftDifferentialOperator \beta q \LeftDifferentialOperator {\alpha - \beta} h}\\
        &=
        \sum_{\beta \leq \alpha} \binom \alpha \beta
        \LeftDifferentialOperator \beta q(e_\Group)
        \dualBracket [\Group] {\delta_{e_\Group}} {\LeftDifferentialOperator {\alpha - \beta} h},
    \end{align*}
    which, after using the definition of distributional derivative,
    becomes
    \begin{align*}
        \dualBracket [\Group] {\delta_{e_\Group}} {\LeftDifferentialOperator \alpha (qh)}
        &=
        \sum_{\beta \leq \alpha} \binom \alpha \beta
        (-1)^{\abs {\alpha - \beta}}
        \LeftDifferentialOperator \beta q(e_\Group)
        \dualBracket [\Group] {\LeftDifferentialOperator {\alpha - \beta} \delta_{e_\Group}} {h}.
    \end{align*}

    Recognising the definition of distributional Fourier transform again,
    we obtain
    \begin{align*}
        \dualBracket [\Group] {\delta_{e_\Group}} {\LeftDifferentialOperator \alpha (qh)}
        &=
        \sum_{\beta \leq \alpha} \binom \alpha \beta
        (-1)^{\abs {\alpha - \beta}}
        \LeftDifferentialOperator \beta q(e_\Group)
        \dualBracket [\dualGroup \Group] {\Fourier\{\LeftDifferentialOperator {\alpha - \beta} \delta_{e_\Group}\}} {H}\\
        &=
        \sum_{\beta \leq \alpha} \binom \alpha \beta
        (-1)^{\abs {\alpha - \beta}}
        \LeftDifferentialOperator \beta q(e_\Group)
        \dualBracket [\dualGroup \Group] {\Rep \lambda(\LeftDifferentialOperator {\alpha - \beta})} {H}.
    \end{align*}

    Combining the above with~\eqref{eq:difference_operator_of_X_alpha},
    we obtain that
    \begin{align*}
        \dualBracket [\dualGroup \Group] {\DifferenceOperator q \Rep \lambda (\LeftDifferentialOperator \alpha)} {H}
        &=
        \sum_{\beta \leq \alpha} \binom \alpha \beta
        (-1)^{\abs \beta}
        \LeftDifferentialOperator \beta q(e_\Group)
        \dualBracket [\dualGroup \Group] {\Rep \lambda(\LeftDifferentialOperator {\alpha - \beta})} {H}.
    \end{align*}

    Since $H$ is arbitrary,
    we obtain the desired formula.
\end{proof}

With our approach
we will not be able to write the composition or adjunction of operators directly in terms of our symbols,
it is thus important to consider a family with respect to which we can use a \emph{Taylor development}.

\begin{definition}
\label{definition:admissibility_of_difference_operators}
\index{difference operators!admissibility}
    A collection of \emph{difference operators} is called \emph{(strongly) admissible}
    if the associated smooth functions form a \emph{(strongly) admissible} collection in the sense of Definition~\ref{definition:admissibility_of_polynomials}.
\end{definition}

The existence of a Taylor expansion and the estimates on the remainder are then given by~\ref{proposition:Taylor_theorem}.
We shall see later that the \emph{strong} admissibility will ensure our the singularity of our kernels is confined to the identity $e_\Group$.

Another technical requirement is that our collection of smooth functions satsify a \emph{Leibniz-like} rule.
This, amongst other things, ensures that our collection of symbols form an algebra with respect to pointwise composition.

\begin{definition}
\label{definition:Leibniz-like_property_for_smooth_functions}
    We shall say that an admissible collection
    \begin{align*}
        q_1, \cdots q_{\dimDifferenceOperators} \in \SmoothFunctions \CompactGroup
    \end{align*}
    satisfies the \emph{Leibniz-like} property
    if for each $j = 1, \cdots, \dimDifferenceOperators$,
    \begin{align*}
        q_j(g h) = q_j(g) + q_j(h) + \sum_{1 \leq k, l \leq \dimDifferenceOperators} c^j_{k, l} q_k(g) q_l(h)
    \end{align*}
    holds for every $g, h \in \Group$.
\end{definition}

It is a routine check to show that the Leibniz-like property for smooth functions
become the following \emph{Leibniz-like rule} for difference operators.

\begin{lemma}[Leibniz-like rule]
\label{lemma:Leibniz-like_property_for_difference_operators}
    Assume that
    \begin{align*}
        \Delta \defeq \{q_1, \dots, q_{\dimDifferenceOperators} \SmoothFunctions \Group\}
    \end{align*}
    is a collection of admissible of smooth functions satisfying the Leibniz-like property.
    Writing
    \begin{align*}
        q^\alpha \defeq q^{\alpha_1}_1 \dots q^{\alpha_{\dimDifferenceOperators}}_{\dimDifferenceOperators},
        \quad \DifferenceOperatorOrder {\alpha} \defeq \DifferenceOperator {q^\alpha(\dummy^{-1})}
    \end{align*}
    for each $\alpha \in \N^{\dimDifferenceOperators}$,
    we have
    \begin{align*}
        \DifferenceOperatorOrder \alpha
        (\Fourier f_1 \Fourier f_2)
        =
        \sum_{\abs \alpha \leq \abs {\alpha_1} + \abs {\alpha_2} \leq 2 \abs \alpha}
        c^{\alpha}_{\alpha_1, \alpha_2}
        \DifferenceOperatorOrder {\alpha_1} \Fourier {f_1} \
        \DifferenceOperatorOrder {\alpha_2} \Fourier {f_2}
    \end{align*}
    for each $f_1, f_2 \in \TemperedDistributions \Group$.
\end{lemma}

We can easily adapt \cite[Lemma 4.4]{RuzhanskyTurunenWirth10} or \cite[Corollay 5.13]{Fischer2015},
to show the following result.

\begin{lemma}
\label{lemma:choice_of_polynomials}
    There exists a strongly admissible family $q_1$, \dots, $q_M \in \SmoothFunctions{\Group}$ on $\Group$ which satisfies the Leibniz-like property and such that
    \begin{align*}
        q_j(x, k) = x_j
    \end{align*}
    for each $j \in \{1, \dots, \dim \VectorSpace\}$.
\end{lemma}
\begin{proof}
    Denote by $F$ the set of all fundamental representations of $\CompactGroup$,
    % TODO: add reference for fundamental representations
    i.e. a finite collection such that for any $\tau \in \dualGroup \CompactGroup$,
    there exists $\tau_1, \cdots, \tau_n \in F$ such that
    \begin{align*}
        \tau = \tau_1 \otimes \cdots \otimes \tau_n.
    \end{align*}
    % Ask Veronique if it's necessary
    We also assume $F$ contains the identity representation.

    Now,
    let us define the following smooth functions
    \begin{align*}
        q_j(x, k) &\defeq \ip {x} {e_j}, &j = 1, \cdots, \dim \VectorSpace\\
        q^\tau_{m n}(x, k) &\defeq {\left(\tau - \Id {H_\tau}\right)}_{m n},
        &\tau \in F, \ 1 \leq m, n \leq \dimRep \tau.
    \end{align*}
    Now we let
    \begin{align*}
        \Delta = \{q_j : 1 \leq j \leq \dim \VectorSpace\}
        \cup \{q^\tau_{m n} : \tau \in F, \ 1 \leq m, n \leq \dimRep \tau\}
    \end{align*}

    \begin{description}
        \item [Strong admissibility]
            Clearly, every $q \in \Delta$ satisfies $q_j(0) = 0$.

            By \cite[Lemma 5.11]{Fischer2015},
            we know that
            \begin{align*}
                \rank \{\dd q^\tau_{m n}(e) : \tau \in F, \ 1 \leq m, n \leq \dimRep \tau\} = \dim \CompactGroup,
            \end{align*}
            so we easily check that
            \begin{align*}
                \rank \Delta = \dim \Group.
            \end{align*}

            By \cite[Lemma 5.11]{Fischer2015},
            if all $q^\tau_{m n}(x, k)$ vanish, then $k = \Id \VectorSpace$,
            while if all $q_j(x, k)$ vanish, this means $x = 0_\VectorSpace$.
            Therefore,
            \begin{align*}
                \bigcap_{q \in \Delta} \{q = 0\} = (0_\VectorSpace, \Id \VectorSpace)
            \end{align*}
        \item [Leibniz-like formula]
            Using \cite[Corollary 5.13]{Fischer2015},
            we only need to show that $q_j$, $j = 1, \cdots, \dim \VectorSpace$ satisfy the Leibniz-like preperty.
            For each $j \in \N$,
            \begin{align*}
                q_j((x, k) (y, l))
                &= \ip {x + k y} {e_j}\\
                &= q_j(x, k) + q_j(y, l) + \ip {(k - \Id \VectorSpace) y} {e_j}\\
                &= q_j(x, k) + q_j(y, l) + \ip y {{(k - \Id \VectorSpace)}^{-1} e_j}
            \end{align*}

            Observing that
            \begin{align*}
                \transpose {(k - \Id \VectorSpace)} e_j
                = \transpose {(k - \Id \VectorSpace)}_{i j} e_i
                = {(k - \Id \VectorSpace)}_{j i} e_i,
            \end{align*}
            we obtain that
            \begin{align*}
                q_j((x, k) (y, l))
                &= q_j(x, k) + q_j(y, l) + \sum_{i = 1}^{\dim \VectorSpace} (k - \Id \VectorSpace)_{j i} \ip y {e_i}\\
                &= q_j(x, k) + q_j(y, l) + \sum_{i = 1}^{\dim \VectorSpace} (k - \Id \VectorSpace)_{j i} q_i(y, l)
            \end{align*}

            Defining
            \begin{align*}
                \tau(k) \defeq k
            \end{align*}
            we observe that $\tau \in F$ and so the above becomes
            \begin{align*}
                q_j((x, k) (y, l))
                &= q_j(x, k) + q_j(y, l) + \sum_{i = 1}^{\dim \VectorSpace} q^{\tau}_{j i}(x, k) q_i(y, l).
            \end{align*}

            We have thus shown that each $q \in \Delta$ satisfies the Leibniz-like formula.
    \end{description}
\end{proof}

\begin{remark}
    From now on, we fix an admissible family $q_1, \cdots, q_{\dimDifferenceOperators}$ on $\Group$
    which satisfies the assumptions of Lemma~\ref{lemma:choice_of_polynomials}.

    Given $\alpha \in \N^{\dimDifferenceOperators}$, we let
    \begin{align*}
        q^\alpha \defeq \prod_{j = 1}^{\dimDifferenceOperators} q_j^{\alpha_j}.
    \end{align*}
    Such maps $q^\alpha$ will be called \emph{polynomials}.

    Moreover, we let $\DifferenceOperatorOrder{\alpha}$ be the difference operator associated with the smooth function
    \begin{align*}
        \Group \to \C : g \mapsto q^\alpha(g^{-1}).
    \end{align*}
\end{remark}

\section{Symbol classes}

Following~\cite{RuzhanskyTurunen10} or~\cite{FischerRuzhansky16},
we can now introduce our main definition.

\begin{definition}[Symbol classes]
\label{definition:symbol_classes}
    Let $m \in \R$ and fix $\rho, \delta \in \R$ such that $0 \leq \rho \leq \delta \leq 1$.
    We shall say that a map
    \begin{align*}
        \sigma : \Group \times \VectorSpace \mapsto \End(\SmoothFunctions \CompactGroup)
    \end{align*}
    is a \emph{symbol of order $m$ and of type $(\rho, \delta)$} if the following conditions are satisfied.
    \begin{enumerate}
        \item
            For each $F \in \SmoothFunctions \CompactGroup$ and each $k \in \CompactGroup$,
            the map
            \begin{align*}
                (g, \lambda) \mapsto \sigma(g, \lambda) F(k)
            \end{align*}
            is smooth.
        \item
            For each $\beta \in \N^{\dim \Group}$,
            $\LeftDifferentialOperator \beta \sigma(g, \dummy) \in \TemperedDistributions {\dualGroup \Group}$
            for each $g \in \Group$ and the map
            \begin{align*}
                g \in \Group \mapsto \LeftDifferentialOperator \beta \sigma(g, \dummy) \in \TemperedDistributions {\dualGroup \Group}
            \end{align*}
            is continuous.
        \item \label{item:symbol_bound_condition}
            For each $\alpha \in \N^{\dim \Group}$, $\beta \in \N^m$, and each $\gamma \in \R$,
            the operator
            \begin{align*}
                \Rep{\lambda} \BesselPotential{\rho \abs\alpha - m - \delta \abs\beta + \gamma} \LeftDifferentialOperator{\beta} \DifferenceOperatorOrder{\alpha} \sigma(g, \lambda) \Rep{\lambda} \BesselPotential{-\gamma}
            \end{align*}
            is bounded in $\Lebesgue 2 \CompactGroup$ by a finite constant that does not depend on $g \in \Group$ or $\lambda \in \VectorSpace$.
    \end{enumerate}

    The set $\SymbolClass{m}{\rho, \delta}$ will be used to denote the set of all symbols of order $m$ and type $(\rho, \delta)$.
\end{definition}

Let us make a few comments on Definition~\ref{definition:symbol_classes}.

\begin{itemize}
    \item If $\alpha = \beta = 0$,
        the \emph{Plancherel theory} (e.g.~\cite[Theorem 1.8.11]{FischerRuzhansky16}) implies that
        if $\sigma \in \SymbolClass m {\rho, \delta}$ does not depend on $g \in \Group$,
        then the map
        \begin{align*}
            \phi \in \Schwartz \Group \mapsto \conv \phi {\InverseFourier \sigma}
        \end{align*}
        extends to a bounded map
        \begin{align*}
            \Sobolev s \to \Sobolev {s - m}
        \end{align*}
        for each $s \in \R$.

        It is hoped that the estimates for non-zero $\alpha \in \N^{\dimDifferenceOperators}$ and $\beta \in \N^{\dim \Group}$
        will imply a similar result for a general $\sigma \in \SymbolClassm {\rho, \delta}$.
        When $\rho > \delta$,
        this is proved later in Theorem~\ref{theorem:L2_boundedness}.
    \item
        In the compact or Euclidean case (see~\cite{RuzhanskyTurunen10}),
        we need only check the case $\gamma = 0$.
        This is due to the fact that in those cases the Laplacian is central.
        The above definition for non-zero $\gamma$ was introduced for the first time in~\cite[Section 3.4]{FischerRuzhansky12} and subsequently in~\cite[Section 5.2]{FischerRuzhansky16}.

        We shall see later, again using the ideas of~\cite{FischerRuzhansky16},
        that we also only need to check for $\gamma = 0$ in our case.
        It is worth remembering that the fact that our Laplacian is not central
        is due to the \emph{semi-direct} structure,
\end{itemize}

We can naturally define a collection of seminorms on our symbol classes,
and check they endow each $\SymbolClass m {\rho, \delta}$ with a structure of \emph{Fr\'echet space}.

\begin{definition}[Symbol semi-norms]
\label{definition:symbol_semi-norms}
    Let $m \in \R$ and fix $\rho, \delta \in \R$ such that $0 \leq \rho \leq \delta \leq 1$.
    If $\sigma \in \SymbolClass m {\rho, \delta}$,
    then for each $N \in \N$,
    we let
    \begin{align*}
        &\SymbolSemiNorm m {\rho, \delta} N {\sigma(g; \lambda)}
        \defeq
        \sup_{\abs \alpha, \abs \beta, \abs \gamma \leq N}
        \\
        &\qquad
        \norm [\Lin{\Lebesgue 2 \CompactGroup}] {%
            \Rep{\lambda} \BesselPotential{\rho \abs\alpha - m - \delta \abs\beta + \gamma} \LeftDifferentialOperator{\beta} \DifferenceOperatorOrder{\alpha} \sigma(g, \lambda) \Rep{\lambda} \BesselPotential{-\gamma}
        }.
    \end{align*}

    Moreover, we also let
    \begin{align*}
        \SymbolSemiNorm m {\rho, \delta} N \sigma
        \defeq \sup_{g \in \Group} \sup_{\lambda \in \VectorSpace}
        \SymbolSemiNorm m {\rho, \delta} N {\sigma(g; \lambda)}
    \end{align*}
    for each $N \in \N$.

    Similarly,
    we let
    \begin{align*}
        &\SymbolSemiNorm {m, R} {\rho, \delta} N {\sigma(g; \lambda)}
        \defeq
        \sup_{\abs \alpha, \abs \beta \leq N}
        \norm [\Lin{\Lebesgue 2 \CompactGroup}] {%
            \LeftDifferentialOperator{\beta} \DifferenceOperatorOrder{\alpha} \sigma(g, \lambda)
            \Rep{\lambda} \BesselPotential{\rho \abs\alpha - m - \delta \abs\beta}
        }
    \end{align*}
    and
    \begin{align*}
        \SymbolSemiNorm {m, R} {\rho, \delta} N \sigma
        \defeq \sup_{g \in \Group} \sup_{\lambda \in \VectorSpace}
        \SymbolSemiNorm {m, R} {\rho, \delta} N {\sigma(g; \lambda)}
    \end{align*}
    for each $N \in \N$.
\end{definition}

Using Lemma~\ref{lemma:difference_operators_on_characteristic_polynomials},
we show that our symbol classes contain the left-invariant differential calculus.

\begin{example}[Characteristic polynomials]
    Given $m \in \N$,
    the map
    \begin{align*}
        \sigma(g, \lambda) \defeq \sum_{\abs \alpha \leq m} c_\alpha(g) \Rep \lambda(X)^\alpha,
        \quad c_\alpha \in C^\infty_c(\Group)
    \end{align*}
    defines a symbol in $\SymbolClass m {1, 0}$.
\end{example}

Naturally,
the requirement that the support be compact in the example above can be relaxed
provided that we assume the the coefficients have bounded derivatives for all orders.

Equipped with the topology of seminorms defined in Definition~\ref{definition:symbol_semi-norms},
we can easily show that the following continuous inclusions.

\begin{lemma}[Inclusion of symbol classes]
    Suppose that $m_1, m_2 \in \R$ and $\rho_1, \rho_2, \delta_1, \delta_2 \in [0, 1]$.
    If the following inequalities hold
    \begin{align*}
        m_1 \leq m_2, \quad \delta_1 \leq \delta_2, \quad \rho_1 \geq \rho_2,
    \end{align*}
    then $\SymbolClass {m_1} {\rho_1, \delta_1} \subset \SymbolClass {m_2} {\rho_2, \delta_2}$,
    and the inclusion is continuous.
\end{lemma}
\begin{proof}
    Let $\sigma \in \SymbolClass {m_1} {\rho_1, \delta_1}$,
    and fix $\alpha \in \N^{\dimDifferenceOperators}$, $\beta \in \N^{\dim \Group}$ and $\gamma \in \R$.

    It is clear that
    \begin{align*}
        \Rep{\lambda} \BesselPotential{\rho_2 \abs\alpha - m_2 - \delta_2 \abs\beta + \gamma}
        \LeftDifferentialOperator{\beta} \DifferenceOperatorOrder{\alpha} \sigma(g, \lambda)
        \Rep{\lambda} \BesselPotential{-\gamma}
        = I_1 I_2,
    \end{align*}
    where
    \begin{align*}
        I_1 &\defeq \Rep \lambda \BesselPotential {m_1 - m_2 + (\rho_2 - \rho_1) \abs \alpha + (\delta_1 - \delta_2) \abs \beta}\\
        I_2 &\defeq \Rep{\lambda} \BesselPotential{\rho_1 \abs\alpha - m_1 - \delta_1 \abs\beta + \gamma}
        \LeftDifferentialOperator{\beta} \DifferenceOperatorOrder{\alpha} \sigma(g, \lambda)
        \Rep{\lambda} \BesselPotential{-\gamma}
    \end{align*}

    Because of our assumption,
    it is clear that
    \begin{align*}
        m_1 - m_2 + (\rho_2 - \rho_1) \abs \alpha + (\delta_1 - \delta_2) \abs \beta \leq 0
    \end{align*}
    so that $I_1$ satisfies
    \begin{align*}
        \norm [\Lin {\Lebesgue 2 \CompactGroup}] {I_1}
        \leq 1.
    \end{align*}

    By our assumption on $\sigma$,
    it is clear that $I_2$ is bounded on $\Lebesgue 2 \Group$ uniformly in $g \in \Group$ and $\lambda \in \Group$,
    so that the same holds for $I_1 I_2$.
\end{proof}

One cannot expect to be able to perform \emph{exact} symbolic computations.
Therefore,
we shall often attempt to obtain results up to symbols which belongs to symbolic classes of ``arbitrarily low orders''.
Such symbols will be called \emph{smoothing symbols}.

\begin{definition}[Smoothing symbols]
\label{definition:smoothing_symbols}
    We let
    \begin{align*}
        \SmoothingSymbols \defeq \bigcap_{m \in \R} \SymbolClass{m}{1, 0}.
    \end{align*}
    The elements of $\SmoothingSymbols$ will be called \emph{smoothing symbols}.
\end{definition}

It is a routine check that we can replace $(1, 0)$ in the above definition
by any $(\rho, \delta) \in [0, 1]^2$ without affecting the resulting set.

\section{Kernels, quantization and operator classes}

We have so far defined a notion of symbol which is similar to the Euclidean case in spirit.
Parts of Definition~\ref{definition:symbol_classes} are directly motivated by the desire to define an analogue of the \emph{Kohn-Nirenberg quantization}.

The process of \emph{quantization} is the association of a symbol with an operator.

\begin{definition}[Quantization]
\label{definition:quantization}
    Let $\sigma \in \SymbolClass{m}{\rho, \delta}$.
    We define the operator $\Op(\sigma)$ via
    \begin{align*}
        \Op(\sigma) \phi(g) \defeq
        \int_\VectorSpace
            \tr\left(\Rep\lambda(g) \sigma(g, \lambda) \Fourier \phi(\lambda)\right)
        \dd \lambda,
    \end{align*}
    where $\phi \in \Schwartz\Group$, and $g \in \Group$.
\end{definition}

Now that we can associate a symbol to an operator,
the latter can inherit properties such as \emph{order} and \emph{type} from the former.

\begin{definition}[Operator classes]
\label{definition:operator_classes}
    If $T = \Op(\sigma)$ for a certain $\sigma \in \SymbolClass{m}{\rho, \delta}$,
    we shall say that $T$ is an \emph{(pseudo-differential) operator of order $m$ and of type $(\rho, \delta)$}.

    The set of all such operators will be denoted by
    \begin{align*}
        \OperatorClass{m}{\rho, \delta} \defeq \Op(\SymbolClass{m}{\rho, \delta}).
    \end{align*}
    Naturally, an operator in
    \begin{align*}
        \SmoothingOperators \defeq \Op(\SmoothingSymbols)
    \end{align*}
    is called \emph{smoothing}.
\end{definition}

To compute adjoints or compose pseudo-differential operators,
it is useful to know their right \emph{convolution kernel}.
Such kernels can be define directly in terms of the symbols,
and we shall subsequently check that they are indeed the right-convolution kernel
associated with the pseudo-differential operator.

\begin{definition}[Kernel of a symbol]
\label{definition:kernel_of_symbol}
    Let $\sigma \in \SymbolClass{m}{\rho, \delta}$.
    For each $g \in \Group$, we let
    \begin{align*}
        \kappa_g \defeq \InverseFourier\{\sigma(g, \dummy)\} \in \TemperedDistributions\Group.
    \end{align*}
    The map
    \begin{align*}
        \kappa : \Group \to \TemperedDistributions\Group : g \mapsto \kappa_g
    \end{align*}
    is called the \emph{kernel} of $\sigma$.
\end{definition}

The symbol classes were defined partly so that the following result holds.

\begin{lemma}
    Let $\sigma \in \SymbolClass m {\rho, \delta}$,
    and denote by $\kappa$ its associated kernel.
    For each $g \in \Group$,
    $\kappa_g$ is a tempered distribution and
    \begin{align*}
        g \in \Group \mapsto \kappa_g \in \TemperedDistributions \Group
    \end{align*}
    is smooth,
    i.e.\ $\kappa \in \SmoothFunctions {\Group, \TemperedDistributions \Group}$.
\end{lemma}
\begin{proof}
    Let $g \in \Group$ and $\beta \in \N^{\dim \Group}$.
    By Proposition~\ref{proposition:image_of_tempered_distributions},
    $\kappa_g = \InverseFourier \{\LeftDifferentialOperator \beta \sigma(g, \dummy)\}$ is a tempered distribution.

    Since the inverse Fourier transform is also continuous,
    the continuity of $\sigma$ in $g$ implies that
    \begin{align*}
        g \mapsto \kappa_g = \InverseFourier \{\LeftDifferentialOperator \beta \sigma(g, \dummy)\}
    \end{align*}
    is continuous.
    This concludes the proof.
\end{proof}

We are now ready to show that the \emph{kernel} associated with a symbol
is in fact the \emph{right-convolution kernel} of its associated pseudo-differential operator.

\begin{proposition}[Quantization]
\label{proposition:quantization}
    Let $\sigma \in \SymbolClass{m}{\rho, \delta}$,
    and denote by $\kappa$ its associated kernel.
    If $\phi \in \Schwartz\Group$, then for each $g \in \Group$, we have
    \begin{align*}
        \Op(\sigma) \phi(g) = \conv{\phi}{\kappa_g}.
    \end{align*}

    In other words, $\kappa$ is the right convolution kernel associated with $\Op(\sigma)$.
\end{proposition}
\begin{proof}
    Let $g \in \Group$ and fix $s < -\max \{\dim \Group/2, \abs m\}$.
    By definition, we know that $\conv \phi \kappa_g \in \Sobolev s$ if and only if
    \begin{align*}
        \Rep \dummy \BesselPotential s \Fourier \{\conv \phi {\kappa_g}\}
        = \Rep \dummy \BesselPotential s \sigma(g, \dummy) \Fourier \phi
    \end{align*}
    belongs to $\LebesgueDual 2 \Group$.
    To show this,
    observe that the above identity implies
    \begin{align*}
        \norm[\SchattenClasses 2 {\Lebesgue 2 \CompactGroup}] {\Rep \dummy \BesselPotential s \Fourier \{\conv \phi {\kappa_g}\}}^2
        \leq C_s \norm[\SchattenClasses 2 {\Lebesgue 2 \CompactGroup}] {\Fourier \phi}^2,
    \end{align*}
    which, since the right-hand side is integrable on $\VectorSpace$,
    means that $\conv \phi {\kappa_g}$ belongs to $\Sobolev s$.
    By Proposition~\ref{proposition:general_Fourier_inverse_formula},
    we get that
    \begin{align*}
        \conv \phi {\kappa_g}(g)
        &= \int_\VectorSpace \tr\left(\Rep \lambda(g) \Fourier \{\conv \phi {\kappa_g}\}\right) \dd \lambda\\
        &= \int_\VectorSpace \tr\left(\Rep \lambda(g) \sigma(g; \lambda) \Fourier \phi(\lambda)\right) \dd \lambda,
    \end{align*}
    which concludes the proof,
    as the right-hand side is exactly $\Op(\sigma) \phi(g)$.
\end{proof}

\subsection{First properties of symbol classes}

We now state elementary properties of our symbol classes and their associated pseudo-differential operators.
In particular,
we claim that applying difference operators or left-invariant differential operators is a continuous operation between symbol classes,
as well as operations such as \emph{pointwise} composition and adjunction.

The proof is a routine check and is left to the reader.
For the pointwise composition,
we use the \emph{Leibniz-like rule} of Lemma~\ref{lemma:Leibniz-like_property_for_difference_operators}.

\begin{proposition}
\label{proposition:first_properties_of_symbol_classes}
    Suppose that $\rho, \delta \in \R$ satisfy $0 \leq \rho, \delta \leq 1$.
    Given $m, m_1, m_2 \in \R$,
    choose three symbols $\sigma \in \SymbolClass m {\rho, \delta}$,
    $\sigma_1 \in \SymbolClass {m_1} {\rho, \delta}$,
    $\sigma_2 \in \SymbolClass {m_2} {\rho, \delta}$.
    The kernels of the aforementioned symbols will be denoted by
    $\kappa$, $\kappa_1$ and $\kappa_2$ respectively.

    The following properties hold.
    \begin{enumerate}
        \item For each $\alpha \in \N^{\dimDifferenceOperators}$ and each $\beta \in \N^{\dim \Group}$,
            \begin{align*}
                (g, \lambda) \in \Group \times \VectorSpace \mapsto
                \LeftDifferentialOperator \beta \DifferenceOperator \alpha \sigma(g, \lambda)
            \end{align*}
            belongs to $\SymbolClass {m - \rho \abs \alpha + \delta \abs \beta} {\rho, \delta}$,
            and its kernel is given by
            \begin{align*}
                g \in \lambda \mapsto q^\alpha \LeftDifferentialOperator \beta \kappa_g.
            \end{align*}
        \item The pointwise adjunction of $\sigma$,
            \begin{align*}
                \adj \sigma(g, \lambda) \defeq \adj {\sigma(g, \lambda)},
            \end{align*}
            defines a symbol in $\SymbolClass m {\rho, \delta}$ whose kernel is given by
            \begin{align*}
                \adj \kappa_g(h) \defeq \conj {\kappa_g(h^{-1})},
            \end{align*}
            where the above is interpreted in the sense of distributions.
        \item
            \label{item:properties_of_symbols:pointwise_composition}
            The pointwise composition
            \begin{align*}
                (g, \lambda) \mapsto \sigma_1(g, \lambda) \sigma_2(g, \lambda)
            \end{align*}
            defines a symbol in $\SymbolClass {m_1 + m_2} {\rho, \delta}$,
            whose symbol is given by
            \begin{align*}
                g \in \Group \mapsto \conv {\kappa_{1, g}} {\kappa_{2, g}}
            \end{align*}
    \end{enumerate}

    All the above operations are continuous with respect to the topology of their respective symbol classes.
\end{proposition}

% TODO Move this
Before we are able to describe smoothing operators,
we need to recall a property of convolution by tempered distributions.
For a proof, see e.g.~\cite[Lemma 3.1.55]{FischerRuzhansky16} which can be easily adapted to our case.

\begin{lemma}
\label{lemma:continuity_of_convolutions}
    Let $f \in \TemperedDistributions \Group$.
    There exists $N \in \N$ and $C \geq 0$ such that
    \begin{align*}
        \abs {(\conv \phi f)(g)}
        \leq
        C
        \seminorm [\TemperedDistributions \Group] N f
        (1 + \norm [\Group] g)^N
        \seminorm [\Schwartz \Group] N \phi
    \end{align*}
\end{lemma}

\begin{proposition}
    Let $T \in \SmoothingOperators$.
    Its convolution kernel
    \begin{align*}
        (g, h) \mapsto \kappa_g(h)
    \end{align*}
    is smooth on $\Group \times \Group$ and given a fixed $g \in \Group$, $\kappa_g(\dummy) \in \Schwartz \Group$.

    As a result,
    the operator $T$ extends to a continuous mapping from $\TemperedDistributions \Group$ to $\SmoothFunctions \Group$.
\end{proposition}
\begin{proof}
    The smoothness of the kernel and Schwartz decay in the second variable follow directly from the kernel estimates (Theorem~\ref{theorem:kernel_estimates}).
    In particular,
    for each $\beta \in \N^{\dim \Group}$ and each $N \in \N$,
    we have
    \begin{align}
        \sup_{g \in \Group}
        \seminorm [\Schwartz \Group] N {\LeftDifferentialOperator [g] \beta \kappa_g}
        \leq
        C
        \SymbolSemiNorm m {\rho, \delta} {N'} {\sigma}
        \label{eq:bound_on_Schwartz_seminorm_of_smoothing_kernel}
    \end{align}
    for some $N \in \N$.

    Fix $\beta \in \N^n$.
    Using the Leibniz rule for left-invariant differential operators,
    we check that
    \begin{align*}
        \LeftDifferentialOperator \beta (T f)(g)
        = \lcsum{\beta = \beta_1 + \beta_2}
        \LeftDifferentialOperator [g_1 = g] {\beta_1}
        (\conv f {\LeftDifferentialOperator [g_2 = g] {\beta_2} \kappa_{g_2}})(g_1)
    \end{align*}

    Passing from left-invariant vector fields to their right-invariant counterpart,
    we obtain
    \begin{align*}
        \abs {\LeftDifferentialOperator \beta (T f)(g)}
        \leq
        C
        \lcsum{\beta = \beta_1 + \beta_2}
        (1 + \norm [\Group] g)^{\abs \beta_1}
        \abs {(\conv {\RightDifferentialOperator [g_1 = g] {\beta_1} f} {\LeftDifferentialOperator [g_2 = g] {\beta_2} \kappa_{g_2}})(g_1)}.
    \end{align*}

    Using Lemma~\ref{lemma:continuity_of_convolutions} and the continuity of $\LeftDifferentialOperator {\beta_1}$ on $\TemperedDistributions \Group$,
    we have
    \begin{align*}
        &\abs {\LeftDifferentialOperator \beta (T f)(g)}\\
        &\leq
        C
        \lcsum{\beta = \beta_1 + \beta_2}
        (1 + \norm [\Group] g)^{\abs \beta_1 + N}
        \seminorm [\TemperedDistributions \Group] N {\RightDifferentialOperator [g_1 = g] {\beta_1} f}
        \seminorm [\TemperedDistributions \Group] N {\LeftDifferentialOperator [g_2 = g] {\beta_2} \kappa_{g_2}}\\
        &\leq
        C
        \lcsum{\beta = \beta_1 + \beta_2}
        (1 + \norm [\Group] g)^{N'}
        \seminorm [\TemperedDistributions \Group] {N'} f
        \seminorm [\Schwartz \Group] {N'} {\LeftDifferentialOperator [g_2 = g] {\beta_2} \kappa_{g_2}}.
    \end{align*}

    Using the above together with~\eqref{eq:bound_on_Schwartz_seminorm_of_smoothing_kernel},
    we conclude easily that $T$ is continuous from $\TemperedDistributions \Group$ to $\SmoothFunctions \Group$.
\end{proof}

\section{Holomorphic functional calculus}

The aim of this section is to show two results concerning functions of symbols which will be essential hereafter.

First, we wish to show that for a well-behaved symbol $\sigma \in \SymbolClass m {\rho, \delta}$,
its powers $\sigma^s$, $s \in \R$ define symbols in $\SymbolClass {s m} {\rho, \delta}$.

Secondly, we would like to show that $\SmoothingSymbols$ is dense in $\SymbolClass m {\rho, \delta}$,
a result whose importance can be compared to that of other density results in analysis.
To this end, we want to create a family of smoothing symbols $\eta_\epsilon$, $\epsilon \in (0, 1]$, in the hope
that $\sigma \eta_\epsilon$ converges to $\sigma$ as $\epsilon$ goes to $0$ in a suitable symbol class.

The results presented herein would be significantly more general with the calculus at our disposal.
However, the proof of the composition and adjunction formulas rely on the fact that $\Rep \lambda \BesselPotential \gamma$ is a symbol of order $\gamma$
and on the aforementioned density of $\SmoothingSymbols$ in the symbol classes $\SymbolClass m {\rho, \delta}$.

The main idea of this section is to follow~\cite{RuzhanskyWirth14},
which uses the following version of the \emph{Cauchy integral formula}
\begin{align}
    F(\sigma) = \int_\Gamma F(z) (\sigma - z\Id{\Lebesgue 2 \CompactGroup})^{-1} \dd z.
    \label{eq:Cauchy_integral_formula_for_operators}
\end{align}
This allows us to carry out our symbolic estimates on the resolvent.

In order to successfully apply~\eqref{eq:Cauchy_integral_formula_for_operators},
we need to identify a class of symbols whose resolvent might give us appropriate bounds.
We are thus led to the following definition.

\begin{definition}[Parameter-dependent ellipticity, \cite{RuzhanskyWirth14}]
\label{definition:parameter-ellipticity}
    Let $\sigma \in \SymbolClass m {\rho, \delta}$ with $m > 0$.
    Given a subset $\Lambda \subset \C$,
    we shall say that $\sigma$ is \emph{parameter-elliptic} with respect to $\Lambda$
    if the following properties hold.
    \begin{enumerate}
        \item For each $z \in \Lambda$ and each $(g, \lambda) \in \Group \times \VectorSpace$,
            the operator
            \begin{align*}
                \sigma(g, \lambda) - z \Id {\Lebesgue 2 \CompactGroup}
            \end{align*}
            is invertible.
        \item
            For each $\gamma_1, \gamma_2 \in \R$,
            the operator
            \begin{align*}
                I_1(m, m + \gamma_1)
                I_2(\gamma_2)
                (\sigma(g, \lambda) - z \Id {\Lebesgue 2 \CompactGroup})^{-1}
                I_2(-\gamma_2)
                I_1(m, -\gamma_1)
            \end{align*}
            is bounded on $\Lebesgue 2 \CompactGroup$ uniformly in $g \in \Group$, $\lambda \in \VectorSpace$ and $z \in \lambda$,
            where
            \begin{align}
                I_1(m, \gamma) &\defeq (\abs z^{\frac 1 m} + \Rep \lambda \BesselPotential 1)^\gamma,\\
                I_2(\gamma) &\defeq \Rep \lambda \BesselPotential \gamma.
                \label{eq:operators_for_parameter-ellipticity}
            \end{align}
    \end{enumerate}

    If $m = 0$,
    we shall say that $\sigma$ is \emph{parameter-elliptic} with respect to $\Lambda$ if
    \begin{align*}
        \sigma(g, \lambda) - z \Id {\Lebesgue 2 \CompactGroup}
    \end{align*}
    is invertible and satisfies
    \begin{align*}
        &\norm [\Lin {\Lebesgue 2 \CompactGroup}] {
            \Rep \lambda \BesselPotential \gamma
            (\sigma(g, \lambda) - z \Id {\Lebesgue 2 \CompactGroup})^{-1}
            \Rep \lambda \BesselPotential {-\gamma}
        }\\
        &\qquad \leq C(1 + \abs z)^{-1}
    \end{align*}
    uniformly in $z \in \Lambda$ and $(g, \lambda) \in \Group \times \VectorSpace$.
\end{definition}

The definition above had to be adapted from the compact case
to take into account that our left-invariant Laplacian is \emph{not} right-invariant.
It makes it somehow difficult to check parameter-ellipticity,
but as we shall mainly be concerned with diagonal symbols,
this is a price we are willing to pay.

\begin{example}
    The symbol $\Rep \lambda \BesselPotentialSquared {}$ is parameter-elliptic of order $2$ with respect to
    \begin{align*}
        \Lambda \defeq \{r \e^{\i \theta} : r \geq 0 \text{ and } \alpha \leq \theta \leq \beta \} \cup \{z \in \C \abs z \leq \frac 1 2  \}
    \end{align*}
    with $0 < \alpha < \beta < \turn$.
\end{example}

\begin{lemma}[\cite{RuzhanskyWirth14}, Theorem 3.1. (1)]
\label{lemma:fall_in_order_for_parameter-elliptic_symbols}
    Let $\sigma \in \SymbolClass m {\rho, \delta}$ be a symbol which does not depend on $g \in \Group$,
    with $m \geq 0$ and $\rho > 0$.

    If $m > 0$ and $\sigma$ is parameter-elliptic with respect to $\Lambda$, then
    for each $\alpha \in \N^{\dimDifferenceOperators}$, $\beta \in \N^{\dim \Group}$, and $\gamma_1, \gamma_2 \in \R$,
    the operator
    \begin{align*}
        &I_1(m, m + \gamma_1)
        I_2(\gamma_2 + \rho \abs \alpha - \delta \abs \beta)\\
        &\quad
        \LeftDifferentialOperator \beta
        \DifferenceOperatorOrder \alpha (\sigma(\lambda) - z \Id {\Lebesgue 2 \CompactGroup})^{-1}
        I_2(-\gamma_2)
        I_1(m, -\gamma_1)
    \end{align*}
    is bounded in $\Lebesgue 2 \CompactGroup$ uniformly in $g \in \Group$, $\lambda \in \VectorSpace$ and $z \in \Lambda$.

    If $m = 0$,
    the resolvent $\sigma - z \Id {\Lebesgue 2 \CompactGroup}$ is a symbol in $\SymbolClass 0 {\rho, \delta}$.

    In the above, $I_1$ and $I_2$ are defined like in~\eqref{eq:operators_for_parameter-ellipticity}.

    Moreover, when we have proved the composition formula,
    the requirement that the symbol not depend on $g$ can be lifted.
\end{lemma}
\begin{proof}[Sketch proof]
    The proof in the compact case (cf~\cite[Theorem 3.1. (1)]{RuzhanskyWirth14}) relies mainly on the \emph{Leibniz-like} rule for difference operators
    and the Leibniz rule for left-invariant differential operators.

    To prove the result, we apply difference operators and differential operators to
    \begin{align*}
        I = (\sigma(\lambda) - z \Id {\Lebesgue 2 \CompactGroup}) (\sigma(\lambda) - z \Id {\Lebesgue 2 \CompactGroup})^{-1}
    \end{align*}
    and use the respective Leibniz rules on the right hand side.

    The proof in~\cite{RuzhanskyWirth14} holds because a similar Leibniz-like rule holds on the motion group.
    Moreover, our definition of parameter-ellipticity ensures that for the purposes of evaluating a norm $\norm [\Lin {\Lebesgue 2 \Group}] \dummy$,
    we can reorder a product of $I_1(m, \gamma_1)$, $I_2(\gamma_2)$ and the resolvent $(\sigma - \Id {\Lebesgue 2 \CompactGroup})^{-1}$ however we like,
    exactly like on the compact group.
\end{proof}

We introduce the following notion of \emph{sector},
whose boundary will provide a good contour for~\eqref{eq:Cauchy_integral_formula_for_operators}.

\begin{definition}[Sector]
    Let $\Lambda \subset \C$.
    We shall say that $\Lambda$ is a \emph{sector} if
    \begin{align*}
        \Lambda
        = \Lambda(\theta_1, \theta_2)
        \defeq \{r \e^{\i \theta} \in \C : r \geq 0, \theta_1 \leq \theta \leq \theta_2\}
    \end{align*}
    for some $\theta_1 < \theta_2$.
\end{definition}

It follows from elementary complex analysis that there exists a determination of $\log$ on the complement of a sector.
As a result,
we can define
\begin{align*}
    z^s \defeq \exp (s \log z),
    \quad z \in \C \setminus \Lambda
\end{align*}
for each $s \in \C$.

We are now ready to state our main result.
\begin{theorem}[\cite{RuzhanskyWirth14}]
\label{theorem:functional_calculus}
    Assume $0 \leq \delta < \rho \leq 1$.
    Let $\sigma \in \SymbolClass m {\rho, \delta}$ be a symbol of strictly positive order,
    which is self-adjoint and parameter-elliptic with respect to a sector $\Lambda \subset \C$.
    If $F$ is analytic in $\C \setminus \Lambda_\epsilon$
    with $\Lambda_\epsilon \defeq (\Lambda \cup \{z \in \C : \abs z \leq \epsilon\})$ for some $\epsilon > 0$
    and satisfies
    \begin{align*}
        \abs {F(z)} \leq C \abs z^s, \quad z \in \Gamma \defeq \partial \Lambda_\epsilon.
    \end{align*}
    for some $s < 0$,
    then $F(\sigma)(g, \lambda) $defines a symbol in $\SymbolClass {s m} {\rho, \delta}$.

    Moreover,
    for each $N \in \N$,
    there exists $C \geq 0$ which does \emph{not} depend on $F$ such that
    \begin{align}
        \SymbolSemiNorm {s m} {\rho, \delta} N {F(\sigma)} \leq C \sup_{z \in \Gamma} \frac {\abs {F(z)}} {\abs z^s}.
        \label{eq:functional_calculus:bound_on_seminorm}
    \end{align}

    If we have not shown the composition formula,
    we can only show the result for a symbol $\sigma$ which does not depend on $g \in \Group$.
\end{theorem}
\begin{proof}
    Let us first assume that $-1 < s < 0$
    and fix $\alpha \in \N^{\dimDifferenceOperators}$, $\beta \in \N^{\dim \Group}$ and $\gamma \in \R$.
    We shall show that
    \begin{align*}
        \Rep \lambda \BesselPotential {-sm + \rho \abs \alpha - \delta \abs \beta + \gamma}
        F(\sigma)(g, \lambda)
        \Rep \lambda \BesselPotential {-\gamma}
    \end{align*}
    is bounded on $\Lin {\Lebesgue 2 \CompactGroup}$ uniformly in $(g, \lambda) \in \Group \times \VectorSpace$.
    For technical convenience,
    we shall check the boundedness in the Peter-Weyl basis of $\Lebesgue 2 \CompactGroup$.
    Therefore, we also fix $\mu, \nu \in \dualGroup \CompactGroup$,
    and integers $m, n, p, q \in \N$ such that
    $1 \leq m, n \leq \dimRep \mu$, $1 \leq p, q \leq \dimRep \nu$.

    By the Helffer-Sj\"ostrand formula,
    % TODO Add reference
    \begin{align*}
        &\abs {%
            \LeftDifferentialOperator \beta \DifferenceOperator \alpha
            F(\sigma)(g, \lambda)_{\mu_{m n}, \nu_{p q}}
        }\\
        &\ \leq C \oint_{\Gamma} \abs {F(z)}
        \abs {%
            \LeftDifferentialOperator \beta \DifferenceOperator \alpha
            (\sigma(g, \lambda) - \Id {\Lebesgue 2 \CompactGroup})^{-1}_{\mu_{m n}, \nu_{p q}}
        } \abs {\dd z}.
    \end{align*}

    Using parameter-ellipticity and Lemma~\ref{lemma:fall_in_order_for_parameter-elliptic_symbols},
    we obtain
    \begin{align*}
        \abs {%
            \LeftDifferentialOperator \beta \DifferenceOperator \alpha
            (\sigma(g, \lambda) - \Id {\Lebesgue 2 \CompactGroup})^{-1}_{\mu_{m n}, \nu_{p q}}
        }
        \leq
        C
        (z^{\frac 1 m} + \norm [\VectorSpace] \lambda + \JapaneseBracket \CompactGroup \mu)^{-m}
        L_{\mu \nu}(\alpha, \beta, \gamma)
    \end{align*}
    where
    \begin{align*}
        L_{\mu \nu}(\alpha, \beta, \gamma) \defeq
        (\norm [\VectorSpace] \lambda + \JapaneseBracket \CompactGroup \mu)^{-\rho \abs \alpha + \delta \abs \beta + \gamma}
        (\norm [\VectorSpace] \lambda + \JapaneseBracket \CompactGroup \nu)^{-\gamma}.
    \end{align*}

    Therefore,
    \begin{align*}
        &\abs {%
            \LeftDifferentialOperator \beta \DifferenceOperator \alpha
            F(\sigma)(g, \lambda)_{\mu_{m n}, \nu_{p q}}
        }\\
        &\ \leq C \oint_{\Gamma}
        \abs z^s
        (\abs z^{\frac 1 m} + \norm [\VectorSpace] \lambda + \JapaneseBracket \CompactGroup \mu)^{-m} L_{\mu \nu}(\alpha, \beta, \gamma) \abs {\dd z}.
    \end{align*}

    It is clear that the above can be estimated by
    \begin{align*}
        \int_{\R^+} r^s (r^{\frac 1 m} + \norm \lambda + \JapaneseBracket \CompactGroup \mu) \dd r
        &\leq \int_{\R^+} ((\norm \lambda + \JapaneseBracket \CompactGroup \mu)^m r)^s (1 + r^{\frac 1 m})^{-m} \dd r\\
        &\leq (\norm \lambda + \JapaneseBracket \CompactGroup \mu)^{m s},
    \end{align*}
    where the inequality on the first line was obtained by substituting $r$ for $(\norm \lambda + \JapaneseBracket \CompactGroup \mu)^m r$,
    and the integrability of $r^s$ is guaranteed by $-1 < s < 0$.

    Going back to our original calculation,
    we then obtain that
    \begin{align*}
        &\abs {%
            \LeftDifferentialOperator \beta \DifferenceOperator \alpha
            F(\sigma)(g, \lambda)_{\mu_{m n}, \nu_{p q}}
        }\\
        &\ \leq C
        \sup_{z \in \Gamma} \frac {\abs {F(z)}} {\abs z^s}
        (\norm \lambda + \JapaneseBracket \CompactGroup \mu)^{m s}
        L_{\mu \nu}(\alpha, \beta, \gamma),
    \end{align*}
    which by definition means that $F(\sigma) \in \SymbolClass {m s} {\rho, \delta}$ and that \ref{eq:functional_calculus:bound_on_seminorm} holds.

    Suppose now that $s < -1$.
    Note that we have a determination of the logarithm on our contour,
    % TODO: not true!
    so we can define
    \begin{align*}
        G(z) \defeq F(z)^{\frac 1 {\Floor{-s} + 1}}
    \end{align*}
    and observe that
    \begin{align*}
        \abs {G(z)} \leq C \abs z^{\frac s {\Floor {-s} + 1}},
        \quad
        -1 < \frac s {\Floor {-s} + 1} < 0.
    \end{align*}

    By the first part of the proof,
    $G(\sigma) \in \SymbolClass {\frac {m s} {\Floor {-s} +1}} {\rho, \delta}$ and
    \begin{align*}
        \SymbolSemiNorm {\frac {m s} {\Floor {-s} + 1}} {\rho, \delta} N {G(\sigma)}
        \leq C
        \sup_{z \in \Gamma} \frac {\abs {G(z)}} {\abs z^{\frac s {\Floor {-s} + 1}}}.
    \end{align*}
    We can now conclude by observing that
    \begin{align*}
        F(\sigma) = G(\sigma)^{\Floor {-s} + 1} \in \SymbolClass {m s} {\rho, \delta},
    \end{align*}
    and
    \begin{align*}
        \SymbolSemiNorm {m s} {\rho, \delta} N {F(\sigma)}
        \leq C
        \sup_{z \in \Gamma} \frac {\abs {F(z)}} {\abs z^s}.
    \end{align*}
    where the inclusion in the symbol class above can only be obtained
    if the symbol is independent on $g$.
    When we have obtained the composition formula,
    note that this will hold for any symbol $\sigma$ satisfying the assumptions of the proof.
\end{proof}

\begin{corollary}
\label{corollary:powers_of_the_Laplacian}
    Let $\gamma \in \R$.
    The map
    \begin{align*}
        \lambda \in \VectorSpace \mapsto \Rep \lambda \BesselPotential \gamma
    \end{align*}
    defines a symbol in $\SymbolClass \gamma {1, 0}$.
\end{corollary}
\begin{proof}
    Since $F(z) = z^s$ with $s < 0$ is holomorphic in $\C \setminus \Lambda$, where
    \begin{align*}
        \Lambda \defeq \Lambda(\frac {\turn} 3, \frac {4 \pi} 3)
    \end{align*}
    and $\BesselPotentialSquared {}$ is parameter elliptic with respect to $\Lambda$,
    we know that
    \begin{align*}
        \BesselPotentialSquared {s} \in \SymbolClass {2 s} {1, 0},
    \end{align*}
    concluding the proof for $\gamma < 0$.

    If $\gamma \geq 0$,
    we let $N \in \N$ be sufficiently large so that
    \begin{align*}
        s \defeq \gamma - 2N < 0,
    \end{align*}
    and conclude that
    \begin{align*}
        \BesselPotential \gamma = \BesselPotential s \BesselPotentialSquared N \in \SymbolClass \gamma {1, 0}.
    \end{align*}
\end{proof}

The following result is central in our analysis.
We show that the Fourier transform of the heat kernel can be used to define a good approximation of the symbol $\Fourier \delta_{e_\Group}$.

\begin{theorem}
\label{theorem:generalized_Littlewood-Paley_decomposition}
    For each $\epsilon \in (0, 1]$,
    we let
    \begin{align*}
        \eta_\epsilon(\lambda) \defeq \e^{-\epsilon \Rep \lambda \BesselPotentialSquared {}}
    \end{align*}
    for each $\lambda \in \VectorSpace$.
    This defines a smoothing symbol in $\SmoothingSymbols$.
    Moreover, we have the following symbol class estimates.
    \begin{itemize}
        \item
            For each $m < 0$ and each $N \in \N$,
            there exists $C \geq 0$ such that
            \begin{align*}
                \SymbolSemiNorm m {\rho, \delta} N {\eta_\epsilon} \leq C \epsilon^\frac m 2
            \end{align*}
        \item
            If $0 \leq m \leq 4$,
            then for each $N \in \N$
            there exists $C \geq 0$ such that
            \begin{align*}
                \SymbolSemiNorm m {\rho, \delta} N {\Id {\Lebesgue 2 \CompactGroup} - \eta_\epsilon} \leq C \epsilon^\frac m 2
            \end{align*}
    \end{itemize}

    In particular, for each $m > 0$, $\eta_\epsilon$ converges to $\Id {\Lebesgue 2 \CompactGroup}$ in $\SymbolClass m {\rho, \delta}$ as $\epsilon \go 0$.
\end{theorem}
\begin{proof}
    In this proof, we consider the following sector
    \begin{align*}
        \Lambda \defeq \Lambda(\frac {\pi} 3, \frac {5 \pi} 3)
    \end{align*}
    and observe that $\Rep \lambda \BesselPotentialSquared {}$ is parameter elliptic with respect to $\Lambda$.
    We also let $\Gamma$ be the boundary of $\Lambda \cup \{z \in \C : \abs z \leq \frac 1 2\}$.

    Let $m < 0$ and write $F_\epsilon(z) = {\e^{-\epsilon z}}$.
    We observe that since $F_\epsilon$ decays faster than any polynomial and does not have a pole at $0$,
    \begin{align*}
        \abs {F_\epsilon(z)} \leq C \abs {\epsilon z}^\frac m 2,
        \quad z \in \Gamma.
    \end{align*}
    where $C$ does not depend on $\epsilon$.
    Theorem~\ref{theorem:functional_calculus} with~\eqref{eq:functional_calculus:bound_on_seminorm} imply that
    \begin{align*}
        \SymbolSemiNorm {m} {\rho, \delta} N {\eta_\epsilon}
        \leq C_{N, n, s} \epsilon^{\frac m 2}.
    \end{align*}

    Now let $0 < m \leq 4$ and let us check the second symbolic estimate.
    To this end,
    we let
    \begin{align*}
        G_\epsilon(z) \defeq (\epsilon z)^{-\frac m 2} (1 - \e^{-\epsilon z})
    \end{align*}
    and observe that
    since $G_1$ vanishes at order $1$ at the origin,
    $\abs {G_\epsilon(z)} \leq C \abs {\epsilon z}^{-m/4}$ on $\Gamma$ where $C$ does not depend on $\epsilon \in (0, 1]$,
    because
    \begin{align*}
        \lim_{z \to 0} \frac {G_1(z)}{z^{-m / 4}}
        = \lim_{z \to 0} \frac {1 - \e^{-z}} {z^{m / 4}}
    \end{align*}
    exists and is finite by our condition on $m$.
    Using Theorem~\ref{theorem:functional_calculus} with~\eqref{eq:functional_calculus:bound_on_seminorm},
    we obtain
    \begin{align*}
        \SymbolSemiNorm {-m/2} {\rho, \delta} N {G_\epsilon(\Rep \lambda (\Laplacian))}
        \leq C \epsilon^{-m/4}
    \end{align*}

    We can now conclude by Corollary~\ref{corollary:powers_of_the_Laplacian} that
    \begin{align*}
        &\SymbolSemiNorm {m} {\rho, \delta } N {\Id {\Lebesgue 2 \CompactGroup} - \eta_\epsilon}\\
        &\leq
        \SymbolSemiNorm {-m/2} {\rho, \delta} {N'} {G_\epsilon(\Rep \lambda \BesselPotentialSquared {})}
        \SymbolSemiNorm {m} {\rho, \delta} {N'} {\left(\epsilon \Rep \lambda \BesselPotentialSquared {}\right)^{m/2}}\\
        &\leq C \epsilon^{-\frac m 4 + \frac m 2} = C \epsilon^\frac m 2.
    \end{align*}

    Now, assume that $m = 0$.
    Defining
    \begin{align*}
        G_\epsilon(z) = (\epsilon z)^{-1} (1 - \e^{-\epsilon z})
    \end{align*}
    it is clear that
    \begin{align*}
        \abs {G_\epsilon(z)} \leq C \abs {\epsilon z}^{-1}
    \end{align*}
    where C does not depend on $\epsilon$.
    Using Theorem~\ref{theorem:functional_calculus} with~\eqref{eq:functional_calculus:bound_on_seminorm},
    we obtain
    \begin{align*}
        \SymbolSemiNorm {-2} {\rho, \delta} N {G_\epsilon(\Rep \lambda (\Laplacian))}
        \leq C \epsilon^{-1}.
    \end{align*}

    We can now conclude like before that
    \begin{align*}
        &\SymbolSemiNorm {0} {\rho, \delta } N {\Id {\Lebesgue 2 \CompactGroup} - \eta_\epsilon}\\
        &\leq
        \SymbolSemiNorm {-2} {\rho, \delta} {N'} {G_\epsilon(\Rep \lambda \BesselPotentialSquared {})}
        \SymbolSemiNorm {2} {\rho, \delta} {N'} {\epsilon \Rep \lambda \BesselPotentialSquared {}}\\
        &\leq C \epsilon^{-1 + 1} = C.
    \end{align*}
\end{proof}

%\begin{corollary}[Littlewood-Paley decomposition]
%    Let $\epsilon \in (0, 1]$.
%    The symbols
%    \begin{align*}
%        \eta'_{\epsilon, j}(\lambda) \defeq \eta_{2^{-j} \epsilon}(\lambda) - \eta_{2^{-j + 1} \epsilon}(\lambda),
%        \quad j = 1, 2, \dots
%    \end{align*}
%    satisfy the following estimate:
%    for each $m > 0$ and each $N \in \N$, there exists $C \geq 0$ such that
%    \begin{align*}
%        \SymbolSemiNorm m {\rho, \delta} N {\eta'_{\epsilon, j}}
%        \leq C (2^{-j} \epsilon)^\frac {\max \{m, 4\}} 2
%    \end{align*}
%    for each $j > 1$.
%
%    Moreover,
%    we have the following decomposition
%    \begin{align*}
%        \Id {\Lebesgue 2 \CompactGroup} =
%        \eta_\epsilon + \sum_{j = 1}^{+\infty} \eta'_{\epsilon, j},
%    \end{align*}
%    where the convergence on the right-hand side is understood in the strong operator topology.
%\end{corollary}
%\begin{proof}
%    Using the symbol classes inclusions,
%    we can assume without loss of generality that $m \geq 4$.
%    We follow the proof of Theorem~\ref{theorem:generalized_Littlewood-Paley_decomposition} when $0 < m \leq 4$.
%    We consider this time the function
%    \begin{align*}
%        G_\epsilon(z) \defeq (\epsilon z)^{-\frac m 2}
%        (\e^{-\epsilon z/2} - \e^{-\epsilon z}),
%    \end{align*}
%    and conclude like in Theorem~\ref{theorem:generalized_Littlewood-Paley_decomposition} that
%    \begin{align*}
%        \SymbolSemiNorm m {\rho, \delta} N {\eta'_{\epsilon, 1}} \leq \epsilon^\frac m 2.
%    \end{align*}
%
%    For $j > 1$,
%    it suffices to observe that
%    \begin{align*}
%        \eta'_{\epsilon, j}
%        = \eta'_{2^{-j + 1} \epsilon, 1}.
%    \end{align*}
%    This concludes the proof.
%\end{proof}

\section{Approximation of symbols}

One of the first applications of Theorem~\ref{theorem:generalized_Littlewood-Paley_decomposition}
is that we can approximate any symbol $\sigma \in \SymbolClass m {\rho, \delta}$ with smoothing symbols,
and control the convergence in all symbol classes of order $m_1 > m$.

\begin{proposition}
\label{proposition:approximation_of_symbols}
    Assume that $1 \geq \rho \geq \delta \geq 0$.
    Let $\sigma \in \SymbolClass m {\rho, \delta}$.
    We can construct a family $(\sigma_\epsilon)_{\epsilon \in (0, 1]} \subset \SmoothingSymbols$ satisfying the following properties.
    \begin{enumerate}
        \item For each $\epsilon \in (0, 1]$,
            $\sigma_\epsilon(g, \lambda)$ has compact support in $g \in \Group$.
            In particular, its associated kernel
            \begin{align*}
                \Group \times \Group : (g, h) \mapsto \kappa_{\epsilon, g}(h)
            \end{align*}
            belongs to $\Schwartz {\Group \times \Group}$ and is also compactly supported in $g \in \Group$.
        \item If $m_1 < m$, then for each $N \in \N$ there exists $C \geq 0$ and $N' \in \N$ such that
            \begin{align*}
                \SymbolSemiNorm {m_1} {\rho, \delta} N {\sigma_\epsilon}
                \leq C \SymbolSemiNorm m {\rho, \delta} {N'} \sigma
                \epsilon^\frac {m_1 - m} 2.
            \end{align*}
            for each $\epsilon \in (0, 1]$.
        \item If $m_1 \geq m$, then for each $N \in \N$ there exists $C \geq 0$ and $N' \in \N$ such that
            \begin{align*}
                \SymbolSemiNorm {m_1} {\rho, \delta} N {\sigma - \sigma_\epsilon}
                \leq C \SymbolSemiNorm m {\rho, \delta} {N'} \sigma
                \epsilon^\frac {\max \{m_1 - m, 4\}} 2
            \end{align*}
            for each $\epsilon \in (0, 1]$.
    \end{enumerate}

    In particular, if $m_1 > m$, $\sigma_\epsilon$ converges to $\sigma$ in $\SymbolClass m_1 {\rho, \delta}$ as $\epsilon \to 0$.
\end{proposition}
\begin{proof}
    Let $\chi \in \SmoothFunctions {\R^+, [0, 1]}$ be a function with compact support
    which satisfies $\chi(r) = 1$ for $\abs r \leq 1$.
    Let $\epsilon \in (0, 1]$.
    We let
    \begin{align*}
        \sigma_\epsilon(g, \lambda)
        \defeq \chi(\epsilon \norm [\Group] g^2) \sigma(g, \lambda) \eta_\epsilon(\lambda),
    \end{align*}
    where $\eta_\epsilon$ was defined in Theorem~\ref{theorem:generalized_Littlewood-Paley_decomposition}.
    It should be clear that the first property holds by our definition of $\chi_\epsilon$
    and the fact that the symbols $\eta_\epsilon$ are smoothing (Theorem~\ref{theorem:generalized_Littlewood-Paley_decomposition}).

    Similarly,
    the second and third point hold by Theorem~\ref{theorem:generalized_Littlewood-Paley_decomposition}
    and Part~\ref{item:properties_of_symbols:pointwise_composition} of Proposition~\ref{proposition:first_properties_of_symbol_classes}.
\end{proof}

Those estimates are crucial in the rest of our analysis.
We present a short overview of how they will be used.

\begin{itemize}
    \item
        If we want to estimate the singularity of the kernel at the origin,
        we approximate the kernel $\kappa_g$ with $\kappa_{\epsilon, g} \defeq \InverseFourier \sigma_\epsilon(g, \dummy)$
        and use the bounds provided by Proposition~\ref{proposition:approximation_of_symbols}.
        For more details, see the proof of Theorem~\ref{theorem:kernel_estimates}.
    \item
        We can prove results such as the composition and adjunction formulae first on $\sigma_\epsilon$,
        a smoothing symbol which has a kernel which is compactly supported in $g \in \Group$.
        For more details, see Section~\ref{section:adjoint_and_composition_formulae}
    \item
        By Proposition~\ref{proposition:approximation_of_symbols},
        \begin{align*}
            \sum_{j = 1}^N \sigma_j
            = \sum_{j = 1}^N (\sigma_j - \sigma_{j, \epsilon_j})
            \quad \text{modulo } \SmoothingSymbols.
        \end{align*}

        If for example,
        the order of $\sigma_j$ decreases as $j \to \infty$ and we choose $\epsilon_j$ carefully,
        the right-hand side could define a convergent series in $\SymbolClass {m_1} {\rho, \delta}$
        using the estimates provided by Proposition~\ref{proposition:approximation_of_symbols}.

        The convergence of the so-called \emph{asymptotic sums} is studied in Proposition~\ref{proposition:asymptotic_sum_of_symbols}
        and is crucial to the construction of parametrices (Theorem~\ref{theorem:construction_of_parametrices}).
\end{itemize}

%\section{Independence on the family of difference operators}
%
%Note that in Definition~\ref{definition:symbol_classes},
%we fixed a strongly admissible family of difference operators.
%We now need to show that,
%had we chosen a different family,
%the resulting symbol classes would be identical.
%
%\begin{proposition}
%    Assume that $1 \geq \rho > \delta \geq 0$.
%    Let $q' \in \SmoothFunctions \Group$ be a function which vanishes up to order $a$ at $e_\Group$.
%    If $\sigma \in \SymbolClass m {\rho, \delta}$,
%    then $\DifferenceOperator {q'} \sigma$ belongs to $\SymbolClass {m - \rho \abs \alpha} {\rho, \delta}$.
%\end{proposition}
%\begin{proof}
%    Using a Taylor development at the origin,
%    we know that for each $N \geq a$
%    \begin{align*}
%        q'(g) = \sum_{a \leq \abs \alpha \leq N} \TaylorLeftDifferentialOperator \alpha q'(e_\Group) q^\alpha(g) + \TaylorRemainder {q'} N {e_\Group}(g),
%    \end{align*}
%    where we used the fact that $q'$ vanishes up to order $a$.
%
%    Using the Taylor remainder theorem,
%    it follows that $\TaylorRemainder {q'} N {e_\Group}$ has a zero of order $N + 1$ at the origin $e_\Group$.
%    % TODO Ask Michael how to conclude
%\end{proof}
%
%\begin{lemma}
%    Let $q, q' \in \SmoothFunctions \Group$ be two smooth functions such that $q / q'$ extends smoothly to a function in $\SmoothFunctions \Group$.
%    It follows that if
%    \begin{align*}
%        \norm [\Lin {\Lebesgue 2 \Group}] {\Rep \lambda \BesselPotential s \DifferenceOperator q \sigma(\lambda)}
%        < \infty
%    \end{align*}
%    for a certain $s \in \R$ and a map $\sigma \in \Fourier(\TemperedDistributions \Group)$,
%    then there exists $C = C_{q, q', s} \geq 0$ such that
%    \begin{align*}
%        \norm [\Lin {\Lebesgue 2 \Group}] {\Rep \lambda \BesselPotential s \DifferenceOperator {q'} \sigma(\lambda)}
%        \leq C
%        \norm [\Lin {\Lebesgue 2 \Group}] {\Rep \lambda \BesselPotential s \DifferenceOperator q \sigma(\lambda)}.
%    \end{align*}
%\end{lemma}
%\begin{proof}
%    Let $T$ and $T'$ be the operators defined via
%    \begin{align*}
%        T \phi(g) \defeq \int_\Group \phi(h) (q \kappa)(h^{-1} g) \dd h,\\
%        T' \phi(g) \defeq \int_\Group \phi(h) (q' \kappa)(h^{-1} g) \dd h,
%    \end{align*}
%    where the integrals are interpreted distributionaly,
%    $\phi \in \Schwartz \Group$ and $g \in \Group$.
%
%    Using our assumption,
%    it follows that after letting
%    \begin{align*}
%        \psi_g(h) = \frac {q'} q(h^{-1} g),
%    \end{align*}
%    we obtain
%    \begin{align*}
%        T' \phi(g) = \int_\Group \phi(h) \psi_g(h) (q \kappa)(h^{-1} g) \dd h = T(\phi \psi_g)(g).
%    \end{align*}
%
%    \begin{align*}
%        \norm [\Lebesgue 2 \Group] {T' \phi}^2
%        &\leq \int_\Group \sup_{g_1 \in \Group} \abs{T (\phi \psi_{g_1})(g)}^2 \dd g\\
%        &\leq \int_\Group \int_\Group \abs{T (\phi \BesselPotential \gamma_{g_1} \psi_{g_1})(g)}^2 \dd g_1 \dd g
%    \end{align*}
%
%    Using Fubini's theorem
%    and the fact that $T \in \Lin{\Lebesgue 2 \Group, \Sobolev s}$,
%    we obtain
%    \begin{align*}
%        \norm [\Lebesgue 2 \Group] {T' \phi}^2
%        &\leq \int_\Group \int_\Group \abs{T (\phi \BesselPotential \gamma_{g_1} \psi_{g_1})(g)}^2 \dd g \dd g_1\\
%        &\leq \norm [\Lin {\Lebesgue 2 \Group, \Sobolev s}] {T} \int_\Group \norm [\Sobolev s] {\phi \BesselPotential \gamma_{g_1} \psi_{g_1}}^2 \dd g_1
%    \end{align*}
%    % TODO Conclude
%\end{proof}

%\section{Link with the H\"ormander classes}
%
%\begin{definition}[Rotation of symbols]
%    Let $\tilde \sigma \in \SymbolClass[\GroupDirect]{m}{\rho, \delta}$.
%    We define the operator
%    \begin{align*}
%        \Rotation {\tilde \sigma} : \SmoothFunctions \CompactGroup \to \SmoothFunctions \CompactGroup
%    \end{align*}
%    via the formula
%    \begin{align*}
%        \Rotation {\tilde \sigma}(x, k; \lambda) F(u) \defeq \tilde \sigma(x, k; k u^{-1} \lambda) F(u),
%    \end{align*}
%    where $x, \lambda \in \VectorSpace$, $k, u \in \CompactGroup$, and $F \in \SmoothFunctions \CompactGroup$.
%
%    Similarly, given $\sigma \in \SymbolClass m {\rho, \delta}$,
%    we define the operator
%    \begin{align*}
%        \InverseRotation \sigma : \SmoothFunctions \CompactGroup \to \SmoothFunctions \CompactGroup
%    \end{align*}
%    via the formula
%    \begin{align*}
%        \InverseRotation \sigma (x, k; \lambda) F(u) \defeq \sigma(x, k; u k^{-1} \lambda) F(u),
%    \end{align*}
%    where again $x, \lambda \in \VectorSpace$, $k, u \in \CompactGroup$, and $F \in \SmoothFunctions \CompactGroup$.
%\end{definition}
%
%\begin{lemma}
%\label{lemma:Y_derivative_on_lambda_variable_of_symbols}
%    Let $Y \in \LieAlgebraCompactGroup$, $\sigma \in \SymbolClass m {\rho, \delta}$, $\tilde \sigma \in \SymbolClass[\GroupDirect] m {\rho, \delta}$.
%    We have the following expression
%    \begin{align*}
%        \LeftDifferentialOperatorFirstOrder Y_l \sigma(x, k; l \lambda)
%        &= \sum_{j = 1}^{\dim \VectorSpace} \DifferenceOperator{j} \sigma(x, k; l \lambda) \Rep {l Y \lambda} (X_j)\\
%        \LeftDifferentialOperatorFirstOrder Y_l \tilde \sigma(x, k; l \lambda)
%        &= \sum_{j = 1}^{\dim \VectorSpace} \DifferenceOperator[\VectorSpace]{j} \tilde \sigma(x, k; l \lambda) \Rep[\GroupDirect] {l Y \lambda} (\partial_j),
%    \end{align*}
%    where $(x, k) \in \GroupDirect$, $\lambda \in \VectorSpace$ and $l \in \CompactGroup$.
%\end{lemma}
%\begin{proof}
%    By definition, we know that
%    \begin{align*}
%        \LeftDifferentialOperatorFirstOrder Y_l \sigma(x, k; l \lambda)
%        &= \eval{\D*{1}{t}}{t = 0} \sigma(x, k; l \exp_\CompactGroup (t Y) \lambda),
%    \end{align*}
%    which after applying the chain rule, becomes
%    \begin{align}
%        &\LeftDifferentialOperatorFirstOrder Y_l \sigma(x, k; l \lambda) \notag\\
%        &\quad = \sum_{j = 1}^{\dim \VectorSpace} \eval{\D*{1}{s}}{s = 0} \sigma(x, k; l \lambda + s u e_j) \eval{\D*{1}{t}}{t = 0} \ip {l \exp_\CompactGroup (t Y) \lambda} {u e_j}.
%        \label{eq:k_differentiation_of_lambda_variable_in_symbol}
%    \end{align}
%
%    Now, we observe that
%    \begin{align*}
%        \eval{\D*{1}{t}}{t = 0} \ip {l \exp_\CompactGroup (t Y) \lambda} {u e_j}
%        = \ip {l Y \lambda} {u e_j} = \frac{1}{\i \turn} \Rep {l Y \lambda} (X_j),
%    \end{align*}
%    while at the same time
%    \begin{align*}
%        \eval{\D*{1}{s}}{s = 0} \sigma(x, k; l \lambda + s u e_j)
%        = \i \turn \DifferenceOperator{j} \sigma(x, k; l \lambda).
%    \end{align*}
%
%    Therefore, it follows that~\eqref{eq:k_differentiation_of_lambda_variable_in_symbol} becomes
%    \begin{align*}
%        \LeftDifferentialOperatorFirstOrder Y_l \sigma(x, k; l \lambda)
%        = \sum_{j = 1}^{\dim \VectorSpace} \DifferenceOperator{j} \sigma(x, k; l \lambda) \Rep {l Y \lambda} (X_j).
%    \end{align*}
%
%    Now, we turn to the case of symbols on the direct product.
%    Again, we start with
%    \begin{align*}
%        \LeftDifferentialOperatorFirstOrder Y_l \tilde \sigma(x, k; l \lambda)
%        &= \eval{\D*{1}{t}}{t = 0} \tilde \sigma(x, k; l \exp_\CompactGroup (t Y) \lambda).
%    \end{align*}
%    Applying the chain rule, we obtain
%    \begin{align}
%        \LeftDifferentialOperatorFirstOrder Y_l \tilde \sigma(x, k; l \lambda)
%        &= \sum_{j = 1}^{\dim \VectorSpace} \eval{\D*{1}{s}}{s = 0} \tilde \sigma(x, k; l \lambda + s e_j) \eval{\D*{1}{t}}{t = 0} \ip {l \exp_\CompactGroup (t Y) \lambda} {e_j}.
%        \label{eq:k_differentiation_of_lambda_variable_in_symbol_2}
%    \end{align}
%
%    By definition, it is clear that
%    \begin{align*}
%        \DifferenceOperator[\VectorSpace]{j} \tilde \sigma(x, k; l \lambda) = \frac 1 {\i \turn} \D{1}[\tilde \sigma]{{\lambda_j} } (x, k, l \lambda),
%    \end{align*}
%    while
%    \begin{align*}
%        \eval{\D*{1}{t}}{t = 0} \ip {l \exp_\CompactGroup (t Y) \lambda} {e_j}
%        &= \ip {l Y \lambda} {e_j}
%        = \frac{1}{\i \turn} \Rep[\GroupDirect] {l Y \lambda} (\partial_j).
%    \end{align*}
%
%    Therefore, it follows that \eqref{eq:k_differentiation_of_lambda_variable_in_symbol_2} becomes
%    \begin{align}
%        \LeftDifferentialOperatorFirstOrder Y_l \tilde \sigma(x, k; l \lambda)
%        &= \sum_{j = 1}^{\dim \VectorSpace} \DifferenceOperator[\VectorSpace]{j} \tilde \sigma(x, k; l \lambda) \Rep[\GroupDirect] {l Y \lambda} (\partial_j).
%    \end{align}
%\end{proof}
%
%\begin{lemma}
%\label{lemma:link_between_symbols}
%    Let $\sigma$ and $\tilde \sigma$ be symbols on $\Group$ and $\GroupDirect$ respectively be such that
%    \begin{align*}
%        \Op[\Group] (\sigma) = \Op[\GroupDirect] (\tilde \sigma).
%    \end{align*}
%    \begin{enumerate}
%        \item
%            \label{item:action_of_difference_operators}
%            If $q \in \SmoothFunctions \Group$,
%            then defining $\tilde q(y, l) = q(l y, l)$ yields
%            \begin{align*}
%                \DifferenceOperator{q} \sigma = \Rotation {\DifferenceOperator[\GroupDirect]{\tilde q} \tilde \sigma}
%                \quad \text{and} \quad
%                \DifferenceOperator[\GroupDirect]{\tilde q} \tilde \sigma = \InverseRotation {\DifferenceOperator{q} \sigma}.
%            \end{align*}
%            In particular, $\sigma = \Rotation {\tilde \sigma}$ and $\tilde \sigma = \InverseRotation \sigma$.
%        \item
%            \label{item:action_of_Euclidean_derivative}
%            If $X \in \LieAlgebra \cap \VectorSpace$, then
%            \begin{align*}
%                \LeftDifferentialOperatorFirstOrder{X} \sigma
%                = \Rotation {\LeftDifferentialOperatorFirstOrder{X} \tilde \sigma}
%                \quad \text{and} \quad
%                \LeftDifferentialOperatorFirstOrder{X} \tilde \sigma
%                = \InverseRotation {\LeftDifferentialOperatorFirstOrder{X} \sigma}.
%            \end{align*}
%        \item
%            \label{item:action_of_K-derivative}
%            If $Y \in \LieAlgebraCompactGroup$, we have
%            \begin{align*}
%                \LeftDifferentialOperatorFirstOrder{Y} \sigma(x, k; \lambda)
%                &= \Rotation {
%                    \LeftDifferentialOperatorFirstOrder{Y} \tilde \sigma
%                    + \sum_{j = 1}^{\dim \VectorSpace} (\DifferenceOperator[\VectorSpace]{j} \tilde \sigma) \Rep[\GroupDirect] {k Y k^{-1} \lambda} (\partial_j)
%                }(x, k; \lambda)\\
%                \LeftDifferentialOperatorFirstOrder Y \tilde \sigma(x, k; \lambda)
%                &= \InverseRotation {\LeftDifferentialOperatorFirstOrder Y \sigma
%                - \sum_{j = 1}^{\dim \VectorSpace} \DifferenceOperator{j} \sigma \ \Rep \lambda (Y^t X_j)
%                }(x, k; \lambda).
%            \end{align*}
%    \end{enumerate}
%\end{lemma}
%\begin{proof}
%    Let us write $T = \Op (\sigma)$.
%    It follows that by
%    % TODO: Reference both quantizations
%    \begin{align*}
%        T \phi(x, k)
%        &= \int_{\GroupDirect} \phi(y, l) {\tilde \kappa}_{x, k}(x - y, l^{-1} k) \dd (y, l)\\
%        &= \int_{\GroupDirect} \phi(y, l) {\kappa}_{x, k}({(y, l)}^{-1} (x, k)) \dd (y, l)
%    \end{align*}
%    in the sense of distributions.
%    Therefore, it follows that we have
%    \begin{align}
%        {\tilde \kappa}_{x, k}(x - y, l^{-1} k) =
%        {\kappa}_{x, k}({(y, l)}^{-1} (x, k)),
%        \label{eq:link_between_the_kernels}
%    \end{align}
%    again in the sense of distributions.
%
%    \begin{enumerate}
%        \item
%            Suppose first that $\sigma \in \SymbolClass m {\rho, \delta}$ for $m < -\dim \Group$
%            so that its kernel $\kappa_{x, k} \in \Schwartz \Group$ by Theorem~\ref{theorem:kernel_estimates}.
%
%            By definition, $\DifferenceOperator{q} \sigma(x, k; \lambda)$ is equal to
%            \begin{align*}
%                &\quad \int_\Group q((y, l)^{-1}) \kappa_{x, k}((y, l)^{-1}) \e^{\i \turn \ip {u^{-1} \lambda} y} \RightRegularRepresentation(l) \dd (y, l)\\
%                &= \int_\Group q((y, l)^{-1} (x, k)) \kappa_{x, k}((y, l)^{-1} (x, k))\\
%                &\qquad \qquad \e^{\i \turn \ip {u^{-1} \lambda} {k^{-1} (y - x)}} \RightRegularRepresentation(k^{-1} l) \dd (y, l)
%            \end{align*}
%            where we substituted $(y, l)$ for $(x, k)^{-1} (y, l)$ to obtain the last line.
%
%            Using
%            \begin{align*}
%                (y, l)^{-1} (x, k) = (l^{-1}(x - y), l^{-1} k)
%            \end{align*}
%            and~\eqref{eq:link_between_the_kernels},
%            if follows that $\DifferenceOperator{q} \sigma(x, k; \lambda)$ becomes
%            \begin{align*}
%                \int_\Group q(l^{-1}(x - y), l^{-1} k) \tilde \kappa_{x, k}(x - y, l^{-1} k) \e^{\i \turn \ip {k u^{-1} \lambda} {(y - x)}} \RightRegularRepresentation(k^{-1} l) \dd (y, l).
%            \end{align*}
%
%            We can now substitute $y$ for $y + x$ and $l$ for $k l$ to obtain that
%            \begin{align*}
%                &\DifferenceOperator{q} \sigma(x, k; \lambda) F(u) =\\
%                &\quad \int_\Group q(-l^{-1} y, l^{-1}) \tilde \kappa_{x, k}(-y, l^{-1}) \e^{\i \turn \ip {k u^{-1} \lambda} y} \RightRegularRepresentation(l) \dd (y, l) F(u)
%            \end{align*}
%            which we recognize to be exactly $\DifferenceOperator {\tilde q} \tilde \sigma(x, k, k u^{-1} \lambda) F(u)$.
%            Therefore, we have shown that
%            \begin{align*}
%                \DifferenceOperator{q} \sigma(x, k; \lambda) F(u)
%                = \DifferenceOperator {\tilde q} \tilde \sigma(x, k, k u^{-1} \lambda) F(u),
%            \end{align*}
%            or in other words $\DifferenceOperator q \sigma = \Rotation {\DifferenceOperator[\GroupDirect] {\tilde q} \tilde \sigma}$.
%
%            Now, suppose that $m \geq -\dim \Group$.
%            Setting
%            \begin{align*}
%                \gamma \defeq -\dim \Group - 1 - m.
%            \end{align*}
%            Since $\Rep \lambda \BesselPotential \gamma \sigma$ is a symbol of order $< -\dim \Group$,
%            then by the adove, we have
%            \begin{align*}
%                \Rep \lambda \BesselPotential \gamma \sigma
%                = \Rotation {\Rep \lambda \BesselPotential \gamma \tilde \sigma}
%                = \Rep \lambda \BesselPotential \gamma \Rotation {\tilde \sigma},
%            \end{align*}
%            or in other words $\sigma = \Rotation {\tilde \sigma}$.
%            % TODO Conclude for difference operators
%
%            The other identity is proven by observing that $\InverseRotation \dummy$ is the inverse of $\Rotation \dummy$.
%        \item
%            This identity follows easily from the previous point.
%        \item
%            Applying $\LeftDifferentialOperatorFirstOrder Y$ on both sides of $\sigma = \Rotation {\tilde \sigma}$,
%            we obtain
%            \begin{align}
%                \LeftDifferentialOperatorFirstOrder Y_k \sigma(x, k; \lambda)
%                &= \LeftDifferentialOperatorFirstOrder Y_{k' = k} \tilde \sigma(x, k'; k u^{-1} \lambda) + \LeftDifferentialOperatorFirstOrder Y_{k' = k} \tilde \sigma(x, k; k' u^{-1} \lambda)\\
%                &= \Rotation {\LeftDifferentialOperatorFirstOrder Y \tilde \sigma}(x, k; \lambda) + \LeftDifferentialOperatorFirstOrder Y_{k' = k} \tilde \sigma(x, k; k' u^{-1} \lambda).
%                \label{eq:Y_derivative_of_rotated_symbol_on_direct_product}
%            \end{align}
%
%            The second term on the right-hand side can be computed via Lemma \ref{lemma:Y_derivative_on_lambda_variable_of_symbols} to be
%            \begin{align*}
%                \LeftDifferentialOperatorFirstOrder Y_{k' = k} \tilde \sigma(x, k; k' u^{-1} \lambda)
%                &= \sum_{j = 1}^{\dim \VectorSpace} \DifferenceOperator[\VectorSpace]{j} \tilde \sigma(x, k; k u^{-1} \lambda) \Rep[\GroupDirect]{k Y u^{-1} \lambda} (\partial_j)\\
%                &= \sum_{j = 1}^{\dim \VectorSpace} \DifferenceOperator[\VectorSpace]{j} \tilde \sigma(x, k; k u^{-1} \lambda) \Rep[\GroupDirect]{k Y k^{-1} (k u^{-1} \lambda)} (\partial_j)\\
%                &= \sum_{j = 1}^{\dim \VectorSpace} \Rotation {\DifferenceOperator[\VectorSpace]{j} \tilde \sigma} (x, k; \lambda) \Rotation {\Rep[\GroupDirect]{k Y k^{-1} \lambda} (\partial_j)}.
%            \end{align*}
%
%            Plugging the above into \eqref{eq:Y_derivative_of_rotated_symbol_on_direct_product}, we obtain
%            \begin{align*}
%                \LeftDifferentialOperatorFirstOrder Y \sigma(x, k; \lambda)
%                &= \Rotation {\LeftDifferentialOperatorFirstOrder Y \tilde \sigma}(x, k; \lambda)
%                + \sum_{j = 1}^{\dim \VectorSpace} \Rotation {\DifferenceOperator[\VectorSpace]{j} \tilde \sigma \ \Rep[\GroupDirect]{k Y k^{-1} \lambda} (\partial_j)}(x, k; \lambda)\\
%                &= \Rotation {\LeftDifferentialOperatorFirstOrder Y \tilde \sigma
%                    + \sum_{j = 1}^{\dim \VectorSpace} \DifferenceOperator[\VectorSpace]{j} \tilde \sigma \ \Rep[\GroupDirect]{k Y k^{-1} \lambda} (\partial_j)
%                }(x, k; \lambda),
%            \end{align*}
%            which is what we wanted to show.
%
%            To show the second identity,
%            we apply $\LeftDifferentialOperatorFirstOrder Y$ on both sides of $\tilde \sigma = \InverseRotation {\sigma}$ to obtain
%            \begin{align*}
%                \LeftDifferentialOperatorFirstOrder Y_k \tilde \sigma(x, k; \lambda)
%                = \LeftDifferentialOperatorFirstOrder Y_{k' = k} \sigma(x, k'; u k^{-1} \lambda) + \LeftDifferentialOperatorFirstOrder Y_{k' = k} \sigma(x, k; u {k'}^{-1} \lambda) \notag\\
%                = \InverseRotation {\LeftDifferentialOperatorFirstOrder Y \sigma}(x, k; \lambda) - \LeftDifferentialOperatorFirstOrder Y_{u} \tilde \sigma(x, k; u k^{-1} \lambda).
%                \label{eq:Y_derivative_of_rotated_symbol_on_semi-direct_product}
%            \end{align*}
%
%            Using Lemma~\ref{lemma:Y_derivative_on_lambda_variable_of_symbols} again to compute the second term of the right-hand side,
%            \begin{align*}
%                \LeftDifferentialOperatorFirstOrder Y_u \tilde \sigma(x, k; u k^{-1} \lambda)
%                &= \sum_{j = 1}^{\dim \VectorSpace} \DifferenceOperator{j} \sigma (x, k; u k^{-1} \lambda) \Rep {u Y k \lambda} (X_j)\\
%                &= \sum_{j = 1}^{\dim \VectorSpace} \DifferenceOperator{j} \sigma (x, k; u k^{-1} \lambda) \Rep {u Y u^{-1} u k \lambda} (X_j)\\
%                &= \sum_{j = 1}^{\dim \VectorSpace} \InverseRotation {\DifferenceOperator{j} \sigma \Rep {u Y u^{-1} \lambda} (X_j)}.
%            \end{align*}
%
%            Observing that in the above,
%            \begin{align*}
%                \Rep {u Y u^{-1} \lambda} (X_j)
%                = \i \turn \ip {u Y u^{-1} \lambda} {u X_j}
%                = \i \turn \ip {\lambda} {u Y^t X_j}
%                = \Rep \lambda (Y^t X_j)
%            \end{align*}
%            so that \eqref{eq:Y_derivative_of_rotated_symbol_on_direct_product} becomes
%            \begin{align*}
%                \LeftDifferentialOperatorFirstOrder Y_k \tilde \sigma(x, k; \lambda)
%                = \InverseRotation {\LeftDifferentialOperatorFirstOrder Y \sigma
%                - \sum_{j = 1}^{\dim \VectorSpace} \DifferenceOperator{j} \sigma \ \Rep \lambda (Y^t X_j)
%                }(x, k; \lambda),
%            \end{align*}
%            concluding the proof.
%    \end{enumerate}
%\end{proof}
%
%\begin{lemma}
%\label{lemma:inclusion_in_zero_class}
%    Let $m \defeq \frac {-\dim \CompactGroup} 2 (1 - \rho)$.
%    % TODO: Can we prove the result for $m = 0$ or improve?
%    \begin{enumerate}
%        \item
%            If $\sigma \in \SymbolClass m {\rho, \delta}$,
%            then $\tilde \sigma = \InverseRotation \sigma$ satisfies
%            \begin{align*}
%                \sup_{(x, k) \in \Group} \esssup_{\lambda \in \VectorSpace}
%                \norm [\Lin {\Lebesgue 2 \CompactGroup}] {\tilde \sigma(x, k; \lambda)} < \infty.
%            \end{align*}
%        \item
%            If $\tilde \sigma \in \SymbolClass [\GroupDirect] m {\rho, \delta}$,
%            then $\sigma = \Rotation {\tilde \sigma}$ satisfies
%            \begin{align*}
%                \sup_{(x, k) \in \Group} \esssup_{\lambda \in \VectorSpace}
%                \norm [\Lin {\Lebesgue 2 \CompactGroup}] {\sigma(x, k; \lambda)} < \infty.
%            \end{align*}
%    \end{enumerate}
%\end{lemma}
%\begin{proof}
%    Let $F \in \Lebesgue 2 \CompactGroup$ and $u \in \CompactGroup$.
%    By the Sobolev Inequality,
%    we know that
%    \begin{align*}
%        \int_\CompactGroup \sup_{v \in \CompactGroup} \abs {\sigma(x, k; v \lambda) F(u)}^2 \dd u
%        \leq C \sum_{\beta} \int_\CompactGroup \int_\CompactGroup \abs{Y^\beta_v \sigma(x, k; v \lambda) F(u)}^2 \dd v \dd u
%    \end{align*}
%    Using Lemma~\ref{lemma:Y_derivative_on_lambda_variable_of_symbols},
%    we know that each $Y^\beta_v \sigma \in \SymbolClass {m + \abs \beta (1 - \rho)} {\rho, \delta} \subset \SymbolClass 0 {\rho, \delta}$ so that the above becomes
%    \begin{align*}
%        \sup_{(x, k) \in \Group} \esssup_{\lambda \in \VectorSpace}
%        \int_\CompactGroup \sup_{v \in \CompactGroup} \abs {\sigma(x, k; v \lambda) F(u)}^2 \dd u
%        \leq C \norm [\Lebesgue 2 \CompactGroup] {F}^2.
%    \end{align*}
%
%    From the above inequality, we easily derive that
%    \begin{align*}
%        \sup_{(x, k) \in \Group}& \esssup_{\lambda \in \VectorSpace} \norm [\Lebesgue 2 \CompactGroup] {\tilde \sigma(x, k; \lambda) F}^2\\
%        &= \sup_{(x, k) \in \Group} \esssup_{\lambda \in \VectorSpace} \int_\CompactGroup \abs {\sigma(x, k; u k^{-1} \lambda) F(u)}^2 \dd u\\
%        &\leq \sup_{(x, k) \in \Group} \esssup_{\lambda \in \VectorSpace} \int_\CompactGroup \sup_{v \in \CompactGroup} \abs {\sigma(x, k; v \lambda) F(u)}^2 \dd u\\
%        &\leq C \norm [\Lebesgue 2 \CompactGroup] {F}^2,
%    \end{align*}
%    which concludes the proof.
%
%    The second bound is obtained with an identical argument.
%\end{proof}
%
%\begin{theorem}
%    Let $\delta' = \max \{\delta, 1 - \rho\}$ and $m' = m + \frac {\dim \CompactGroup} 2 (1 - \rho)$.
%
%    \begin{enumerate}
%        \item
%            For each $\sigma \in \SymbolClass m {\rho, \delta}$,
%            the symbol $\tilde \sigma = \InverseRotation \sigma$ belongs to $\SymbolClass [\GroupDirect] {m'} {\rho, \delta'}$
%            and satisfies
%            \begin{align*}
%                \Op[\Group] (\sigma) = \Op[\GroupDirect] (\tilde \sigma).
%            \end{align*}
%        \item
%            Reciprocally, for each $\tilde \sigma \in \SymbolClass [\GroupDirect] m {\rho, \delta}$,
%            the symbol $\sigma = \Rotation {\tilde \sigma}$ belongs to $\SymbolClass {m'} {\rho, \delta'}$
%            and satisfies
%            \begin{align*}
%                \Op[\GroupDirect] (\tilde \sigma) = \Op[\Group] (\sigma).
%            \end{align*}
%    \end{enumerate}
%
%    In particular, if $\rho = 1$, the symbol classes coincide
%    \begin{align*}
%        \SymbolClass m {1, \delta} = \SymbolClass [\GroupDirect] m {1, \delta}.
%    \end{align*}
%\end{theorem}
%\begin{proof}
%    Let us prove the first claim,
%    as the proof of the second uses an identical argument.
%
%    Let $\sigma \in \SymbolClass m {\rho, \delta}$,
%    and write $\tilde \sigma \defeq \InverseRotation \sigma$.
%
%    \begin{claim}
%        Given $\tilde{q} \in \CompactGroup$ and $\beta \in \N^{\dim \Group}$,
%        there exists a symbol $\tau \in \SymbolClass {m - \rho \order(q) + \delta' \abs \beta} {\rho, \delta'}$ such that
%        \begin{align*}
%            \DifferenceOperator [\GroupDirect] {\tilde q} X^\beta \tilde \sigma = \InverseRotation \tau.
%        \end{align*}
%    \end{claim}
%    \begin{proof}[Proof of the claim]
%        Let us prove the claim by induction on $\abs \beta$.
%        The initial case $\beta = 0$ follows easily from Lemma~\ref{lemma:link_between_symbols} (\ref{item:action_of_difference_operators})
%        and the inclusion
%        \begin{align*}
%            \SymbolClass {m - \rho \order(q)} {\rho, \delta} \subset \SymbolClass {m - \rho \order(q)} {\rho, \delta'}.
%        \end{align*}
%
%        Now, let us assume the claim holds for a certain $\beta$,
%        so that there exists $\tau \in \SymbolClass {m - \rho \order(q) + \delta' \abs \beta} {\rho, \delta'}$ such that
%        \begin{align*}
%            \DifferenceOperator [\GroupDirect] {\tilde q} X^\beta \tilde \sigma = \InverseRotation \tau.
%        \end{align*}
%
%        If $X \in \LieAlgebra \cap \VectorSpace$,
%        then by (\ref{item:action_of_Euclidean_derivative}) of Lemma~\ref{lemma:link_between_symbols} we have
%        \begin{align*}
%            \DifferenceOperator [\GroupDirect] {\tilde q} X X^\beta \tilde \sigma = \InverseRotation {X \tau},
%        \end{align*}
%        where $X \tau \in \SymbolClass {m - \rho \order(q) + \delta' (\abs \beta + 1)} {\rho, \delta'}$.
%
%        If $X \in \LieAlgebraCompactGroup$,
%        then by (\ref{item:action_of_K-derivative}) of Lemma~\ref{lemma:link_between_symbols} we have
%        \begin{align*}
%            \DifferenceOperator [\GroupDirect] {\tilde q} X X^\beta \tilde \sigma = \InverseRotation {X \tau - \sum_{j = 1}^{\dim \VectorSpace} \DifferenceOperator{j} \tau \ \Rep {\lambda} (X^t X_j) }
%        \end{align*}
%        where $X \tau - \sum_{j = 1}^{\dim \VectorSpace} \DifferenceOperator{j} \tau \ \Rep {\lambda} (X^t X_j) \in \SymbolClass {m - \rho \order(q) + \delta' (\abs \beta + 1)} {\rho, \delta'}$.
%        To see this,
%        we observe the condition $\delta' \geq 1 - \rho$ implies that $X \tau$ is the term with higher order.
%
%        Either way, this concludes the induction, and thus the proof of the claim.
%    \end{proof}
%
%    By our claim,
%    there exists a symbol $\tau \in \SymbolClass {m - \rho \order(q) + \delta' \abs \beta} {\rho, \delta'}$ such that
%    \begin{align*}
%        \DifferenceOperator [\GroupDirect] {\tilde q} X^\beta \tilde \sigma = \InverseRotation \tau.
%    \end{align*}
%
%    Note that the above implies that
%    \begin{align*}
%        \Rep[\GroupDirect] \lambda \BesselPotential{-m' + \rho \order(q) - \delta' \abs \beta + \gamma} \DifferenceOperator [\GroupDirect] {\tilde q} X^\beta \tilde \sigma(x, k; \lambda) \Rep [\GroupDirect] \lambda \BesselPotential{-\gamma}\\
%        = \InverseRotation {\Rep \lambda \BesselPotential{-m' + \rho \order(q) - \delta' \abs \beta + \gamma} \tau \Rep \lambda \BesselPotential{-\gamma}} (x, k; \lambda).
%    \end{align*}
%
%    Since the operator inside $\InverseRotation \dummy$ on the second line belongs to
%    \begin{align*}
%        \SymbolClass {-\frac {\dim \CompactGroup} 2 (1 - \rho) } {\rho, \delta'},
%    \end{align*}
%    then Lemma~\ref{lemma:inclusion_in_zero_class} implies that
%    \begin{align*}
%        &\sup_{g \in \GroupDirect} \esssup_{\lambda \in \VectorSpace}\\
%        &\quad
%        \norm [\Lin {\Lebesgue 2 \CompactGroup}] {%
%            \Rep[\GroupDirect] \lambda \BesselPotential{-m' + \rho \abs \alpha  - \delta' \abs \beta} \DifferenceOperator [\GroupDirect] {\tilde q} X^\beta \tilde \sigma(x, k; \lambda) \Rep [\GroupDirect] \lambda
%        }
%        % TODO: show the direct product doesn't require the gamma trick
%    \end{align*}
%    is finite,
%    which by definition means that $\tilde \sigma \in \SymbolClass [\GroupDirect] {m'} {\rho, \delta'}$.
%\end{proof}

%\section{Littlewood-Paley decomposition}
%
%\begin{lemma}
%\label{lemma:derivatives_of_radial_functions}
%    Let $\alpha \in \N^n$,
%    and fix a radial function $\chi \in \SmoothFunctions{\R^n}$.
%    If $\alpha \in \N^n$, then
%    \begin{align}
%        \D{\abs \alpha}[\chi]{x^\alpha}(x)
%        = \sum_{r = 1}^{C_\alpha} f_r(\norm[\R^n]{x}) P_r(x),
%    \end{align}
%    where $P_r$ is a polynomial depending only on $\alpha$.
%
%    Moreover, if $\supp \chi$ is compact
%    and if there exists $\delta > 0$ such that the radial derivative $\D{\abs \alpha}[\chi]{\lambda}$ vanishes on on $\Ball[\R^n]{0}{\delta}$,
%    then we have
%    \begin{align*}
%        \sup_r \sup_{\lambda \in \R^+} \abs{f_r} < \infty
%    \end{align*}
%\end{lemma}
%\begin{proof}
%    Using the chain rule, we know that for a purely radial function $f$
%    \begin{align}
%        \D{1}[f]{{x_i} } = \D{1}[\lambda]{{x_i} } \D{1}[f]{\lambda} = \frac{\D{1}[f]{\lambda}}{\norm[\R^n]{x}} x_i.
%    \end{align}
%
%    We know proceed to show the claim by induction on $\alpha$.
%    The result is clearly true when $\abs{\alpha} = 0$.
%    If we assume it is true for some $\alpha \in \N^n$, then by the above,
%    \begin{align}
%        \D{\abs \alpha + 1}[\chi]{{x_i} , x^\alpha}(x)
%        &= \D{1}{{x_i} } \sum_{r = 1}^{C_\alpha} f_r(\norm[\R^n]{x}) P_r(x)\\
%        &= \sum_{r = 1}^{C_\alpha} \frac{\D{1}[f_r]{\lambda}}{\norm[\R^n]{x}}(\norm[\R^n]{x}) x_i P_r(x)
%        + \sum_{r = 1}^{C_\alpha} f_r(\norm[\R^n]{x}) \D{1}[P_r]{{x_i} }(x),
%    \end{align}
%    which concludes the proof.
%\end{proof}
%
%\begin{lemma}
%\label{lemma:left_regular_representation_of_polynomials}
%    Let $P \in \SmoothFunctions{\dualGroup{\VectorSpace}}$ be a polynomial.
%    We can find functions $q_i \in \Polynomials{\CompactGroup}$, $f_i \in \Lebesgue{2}{\dualGroup{\VectorSpace}}$, $i = 1, \cdots, N$ such that
%    \begin{align*}
%        P(k \lambda) = \sum_{i = 1}^N q_i(k) f_i(\lambda)
%    \end{align*}
%    for each $k \in \CompactGroup$ and each $\lambda \in \dualGroup{\VectorSpace}$.
%
%    Moreover, the $q_i$ satisfy the bound
%    \begin{align*}
%        \sup_i \sup_\CompactGroup \abs{q_i} < \infty.
%    \end{align*}
%\end{lemma}
%
%The singularities of the kernel associated with a smooth symbol
%arise from the behaviour of the latter at high frequencies,
%as illustrated by the Euclidean or compact case.
%Therefore, an idea would be to cut off those high frequencies.
%
%\begin{theorem}
%\label{theorem:generalized_Littlewood-Paley_decomposition}
%    Let $\chi \in \SmoothFunctions {\R^+}$ be a positive bounded smooth function.
%
%    For each $\epsilon \in (0, 1]$,
%    we let
%    \begin{align*}
%        \eta_\epsilon(\lambda)
%        \defeq
%        \bigoplus_{\tau \in \dualGroup \CompactGroup} \chi(\epsilon(\JapaneseBracket \CompactGroup \tau^2 + \norm {\turn \lambda}^2)^{\frac 1 2}) \Id {V_\tau},
%    \end{align*}
%    where $V_\tau \defeq \Span \{\tau_{i j} \in \Lebesgue 2 \CompactGroup : 1 \leq i, j \leq \dimRep \tau\}$.
%
%    For each $\epsilon \in (0, 1]$,
%    $\eta_\epsilon$ is a symbol in $\SymbolClass 0 {1, 0}$,
%    and the following properties hold.
%
%    \begin{enumerate}
%        \item \label{item:generalized_Littlewood-Paley_decomposition:negative_m}
%            If $\chi$ has compact support, then $\eta_\epsilon \in \SmoothingSymbols$ for each $\epsilon \in (0, 1]$.
%            Moreover, for each $m \leq 0$ and each $N \in \N$,
%            there exists $C_{m, N} \geq 0$ such that
%            \begin{align*}
%                \SymbolSemiNorm m {\rho, \delta} N {\eta_\epsilon} \leq C_{m, N} \epsilon^m
%            \end{align*}
%            for every $\epsilon \in (0, 1]$.
%        \item \label{item:generalized_Littlewood-Paley_decomposition:positive_m}
%            If there exists $c > 0$ such that $\chi$ vanishes on $[0, c]$,
%            then for each $m \geq 0$ and each $N \in \N$,
%            there exists $C_{c, m, N} \geq 0$ such that
%            \begin{align*}
%                \SymbolSemiNorm m {\rho, \delta} N {\eta_\epsilon} \leq C_{c, m, N} \epsilon^m
%            \end{align*}
%            for every $\epsilon \in (0, 1]$.
%    \end{enumerate}
%\end{theorem}
%\begin{proof}
%    First, let us find a smooth real function $\chi \in \SmoothFunctions \R$ such that
%    \begin{align*}
%        \chi(r) = 1 \  \text{if}\  \abs r \leq 1, \quad \text{and} \quad
%        \chi(r) = 0 \ \text{if}\  \abs r \geq 2.
%    \end{align*}
%
%    For every $\tau \in \dualGroup \CompactGroup$ and every $\epsilon \in (0, 1]$,
%    we let
%    \begin{align*}
%        \chi_{\epsilon, \tau}(\lambda)
%        \defeq \chi(\epsilon(\JapaneseBracket \CompactGroup \tau^2 + \norm \lambda^2)^{\frac 1 2})
%    \end{align*}
%
%    Then, for each $\epsilon \in (0, 1]$,
%    we define
%    \begin{align*}
%        \eta_\epsilon(\lambda)
%        \defeq \sum_{\tau \in \dualGroup \CompactGroup} \chi_{\epsilon, \tau}(\lambda) \Id {V_\tau},
%    \end{align*}
%    where in the above $V_\tau \defeq \Span \{\tau_{ij} : 1 \leq i, j \leq \dimRep \tau\}$.
%
%    We check that
%    \begin{align*}
%        \lim_{\epsilon \to 0} \eta_\epsilon(\lambda)
%        &= \lim_{\epsilon \to 0} \sum_{\tau \in \dualGroup \CompactGroup} \chi_{\epsilon, \tau} (\lambda) \Id {V_\tau}\\
%        &= \sum_{\tau \in \dualGroup \CompactGroup} \Id {V_\tau}
%        = \Id {\Lebesgue 2 \CompactGroup}
%    \end{align*}
%
%    \begin{description}
%        \item [Step 1] Computing the associated kernel $\kappa_\epsilon$.
%
%            By applying the inverse Fourier Transform (Proposition~\ref{proposition:inverse_Fourier_Transform}),
%            we know that the kernel is given by
%            \begin{align}
%                \kappa_\epsilon(x, k)
%                = \sum_{\tau \in \dualGroup \CompactGroup}
%                \int_\VectorSpace
%                \tr \left(\chi_{\epsilon, \tau} (\lambda) \eval {\Rep \lambda(x, k)} {V_\tau}\right) \dd \lambda \notag\\
%                = \sum_{\tau \in \dualGroup \CompactGroup}
%                \tr \left(\int_\VectorSpace
%                \chi_{\epsilon, \tau} (\lambda) \eval {\Rep \lambda(x, k)} {V_\tau}\right) \dd \lambda,
%                \label{eq:Littlewood-Paley:computing_kernel}
%            \end{align}
%            where we are allowed to permutate integral and trace because the support of $\xi$ is compact
%            and the operator $\eval {\Rep \lambda(x, k)} {V_\tau}$ is finite-dimensional.
%
%            Using the invariance of $\chi$ under rotations,
%            we obtain that
%            for each $F \in \Lebesgue 2 \CompactGroup$ and each $u \in \CompactGroup$,
%            \begin{align*}
%                &\left(\int_\VectorSpace \chi_{\epsilon, \tau} (\lambda) \eval {\Rep \lambda(x, k)} {V_\tau} \dd \lambda\right) F(u)\\
%                &\quad = \int_\VectorSpace \chi_{\epsilon, \tau u} (\lambda) \eval {\Rep {u \lambda}(x, k)} {V_\tau} F(u) \dd \lambda\\
%                &\quad = \left(\int_\VectorSpace \chi_{\epsilon, \tau} (\lambda) \e^{\i \turn \ip \lambda x} \eval {\RightRegularRepresentation(k)} {V_\tau}\right) F(u)\\
%                &\quad = \InverseFourier [\R^n] \chi_{\epsilon, \tau}(x) \eval {\RightRegularRepresentation(k)} {V_\tau} F(u)
%            \end{align*}
%            Taking the trace on both sides of the above,
%            and keeping in mind that $\eval {\RightRegularRepresentation(k)} {V_\tau} \simeq \tau$,
%            we get
%            \begin{align*}
%                &\tr \left(\int_\VectorSpace \chi_{\epsilon, \tau} (\lambda) \eval {\Rep \lambda(x, k)} {V_\tau} \dd \lambda\right)\\
%                &\quad = \InverseFourier [\R^n] \chi_{\epsilon, \tau}(x) \chi_\tau(k),
%            \end{align*}
%            where $\chi_\tau \defeq \tr \tau$ is the character of $\tau$.
%
%            Injecting the above in~\eqref{eq:Littlewood-Paley:computing_kernel},
%            we obtain
%            \begin{align}
%                \kappa_\epsilon(x, k)
%                = \sum_{\tau \in \dualGroup \CompactGroup}
%                \InverseFourier [\R^n] \chi_{\epsilon, \tau}(x) \chi_\tau(k).
%                \label{eq:Littlewood-Paley:kernel}
%            \end{align}
%        \item [Step 2] Computing $\DifferenceOperatorOrder \alpha \eta_\epsilon$.
%
%            % Conditions on polynomials
%            First, select a strongly admissible family of operators such that
%            \begin{align*}
%                q_j((x, k)^{-1}) = x_j, \quad j = 1, \cdots, \dim \VectorSpace
%            \end{align*}
%            and $q_j$ does not depend on $x$ for $j > \dim \VectorSpace$.
%
%            Fix $\alpha = \alpha_1 + \alpha_2 \in \N^{\dimDifferenceOperators}$ with $\alpha_1 \in \N^{\dim \VectorSpace}$.
%            Using~\eqref{eq:Littlewood-Paley:kernel},
%            we can multiply by $q^\alpha$ and take the Fourier Transform to obtain
%            \begin{align*}
%                &\DifferenceOperatorOrder \alpha \eta_\epsilon(\lambda) F(u)\\
%                &= \sum_{\tau \in \dualGroup \CompactGroup} \int_\Group
%                q^{\alpha_1}((x, k)^{-1}) \InverseFourier [\R^n] \chi_{\epsilon, \tau}(x) \e^{\i \turn \ip \lambda {u x}}\\
%                & \qquad \qquad \qquad (q^{\alpha_2} \chi_\tau)(k^{-1}) F(u k) \dd (x, k)
%            \end{align*}
%            Note that to obtain the above,
%            we used the fact that $\InverseFourier [\R^n] \chi_{\epsilon, \tau}$ is invariant under rotations.
%
%            Using our choice of difference operators and grouping the terms depending on
%            wether they depend on $x$ or on $k$,
%            we obtain
%            \begin{align*}
%                \DifferenceOperatorOrder \alpha \eta_\epsilon(\lambda) F(u)
%                &= \sum_{\tau \in \dualGroup \CompactGroup}
%                \int_\VectorSpace x^{\alpha_1} \InverseFourier [\R^n] \chi_{\epsilon, \tau}(x) \e^{\i \turn \ip \lambda {u x}} \dd x\\
%                & \qquad \qquad \times \int_\CompactGroup (q^{\alpha_2} \chi_\tau)(k^{-1}) F(u k) \dd k.
%            \end{align*}
%
%            Recognising that the integral on $\CompactGroup$ can be seen as a Fourier Transform on $\CompactGroup$,
%            we get the formula
%            \begin{align*}
%                \DifferenceOperatorOrder \alpha \eta_\epsilon(\lambda) F(u)
%                &= \sum_{\tau \in \dualGroup \CompactGroup}
%                \iD {\lambda^{\alpha_1} } \chi_{\epsilon, \tau}(u^{-1} \lambda)
%                \DifferenceOperatorOrder [\CompactGroup] {\alpha_2} \Fourier [\CompactGroup] \chi_\tau F(u),
%            \end{align*}
%            which can be rewritten more elegantly as follows
%            \begin{align}
%                \DifferenceOperatorOrder \alpha \eta_\epsilon(\lambda) F(u)
%                = \bigoplus_{\tau \in \dualGroup \CompactGroup}
%                \iD {\lambda^{\alpha_1} } \chi_{\epsilon, \tau}(u^{-1} \lambda)
%                \DifferenceOperatorOrder [\CompactGroup] {\alpha_2} \Id {V_\tau} F(u).
%                \label{eq:Littlewood-Paley:difference_operators}
%            \end{align}
%
%        \item [Step 3a] If $F \in V_\tau$ for some $\tau \in \dualGroup \CompactGroup$,
%            then there exists $c_\alpha, C_\alpha \geq 0$ such that
%            \begin{align*}
%                \DifferenceOperatorOrder \alpha \eta_\epsilon(\lambda) F
%                \subset \bigoplus_{c_\alpha \leq \JapaneseBracket \CompactGroup \tau^{-1} \JapaneseBracket \CompactGroup \mu \leq C_\alpha} V_{\mu}
%            \end{align*}
%
%        \item [Step 3b] We show that there exists $C = C_{\alpha, \gamma} \geq 0$ which does \emph{not} depend on $\epsilon$ or $\lambda$ such that
%            \begin{align*}
%                \norm [\Lin {\Lebesgue 2 \CompactGroup}] {%
%                    \Rep \lambda \BesselPotential {\rho \abs \alpha + \gamma}
%                    \DifferenceOperatorOrder \alpha \eta_\epsilon(\lambda)
%                    \Rep \lambda \BesselPotential {-\gamma}
%                } \leq C_{\alpha, \gamma}.
%            \end{align*}
%
%            From~\eqref{eq:Littlewood-Paley:difference_operators},
%            we deduce that
%            \begin{align*}
%                \norm [\Lin {\Lebesgue 2 \CompactGroup}] {%
%                    \DifferenceOperatorOrder \alpha \eta_\epsilon(\lambda)
%                    \Rep \lambda \BesselPotential {\rho \abs \alpha}
%                }
%                \leq C_\alpha
%            \end{align*}
%            holds if and only if
%            \begin{align*}
%                \norm [\Lin {\Lebesgue 2 \CompactGroup}] {%
%                    \iD {\lambda^{\alpha_1} } \chi_{\epsilon, \tau}(u^{-1} \lambda)
%                    \DifferenceOperatorOrder {\alpha_2} \Id {V_\tau}
%                    } \leq C_\alpha (\JapaneseBracket \CompactGroup \tau + \norm {\turn \lambda})^{-\rho \abs {\alpha}}.
%            \end{align*}
%
%            By the chain rule,
%            we have
%            \begin{align*}
%                \iD {\lambda^{\alpha_1} } &\chi_{\epsilon, \tau}(u^{-1} \lambda)\\
%                &= \epsilon^{\alpha_1} \lcsum{n \leq \abs {\alpha_1}}
%                \D*{n}[\chi]{r^n}(\epsilon (\JapaneseBracket \CompactGroup \tau^2 + \norm {\turn \lambda}^2)^{\frac 1 2})
%                \iD {\lambda^{\alpha_1} } (\JapaneseBracket \CompactGroup \tau^2 + \norm {\turn \lambda}^2)^{\frac 1 2}.
%            \end{align*}
%
%            We now check that \cite[Lemma A.10]{Fischer2015} implies that
%            \begin{align*}
%                &\norm [\Lebesgue 2 \CompactGroup] {%
%                    \DifferenceOperatorOrder {\alpha_2} \left(%
%                        \D*{n}[\chi]{r^n}(\epsilon (\JapaneseBracket \CompactGroup \tau^2 + \norm {\turn \lambda}^2)^{\frac 1 2})
%                        \Id {V_\tau}
%                    \right)
%                }\\
%                &\qquad \leq
%                C (\JapaneseBracket \CompactGroup \tau + \norm {\turn \lambda}^2)^{-\rho \abs \alpha_2}.
%            \end{align*}
%
%            Combining the last two equations,
%            we get
%            \begin{align}
%                \norm [\Lin {\Lebesgue 2 \CompactGroup}] {%
%                    \iD {\lambda^{\alpha_1} } \chi_{\epsilon, \tau}(u^{-1} \lambda)
%                    \DifferenceOperatorOrder {\alpha_2} \Id {V_\tau}
%                    } \leq C_\alpha (\JapaneseBracket \CompactGroup \tau + \norm {\turn \lambda})^{-\rho \abs {\alpha}}.
%                \label{eq:eta_epsilon_symbol_norm_for_gamma_0}
%            \end{align}
%
%            To conclude,
%            observe first that
%            \begin{align*}
%                &\norm [\Lin {\Lebesgue 2 \CompactGroup}] {%
%                    \Rep \lambda \BesselPotential {\gamma + \rho \abs \alpha}
%                    \DifferenceOperatorOrder \alpha \eta_\epsilon
%                    \Rep \lambda \BesselPotential {-\gamma}
%                }\\
%                &\leq C
%                \sup_{\tau \in \dualGroup \CompactGroup}
%                \norm [\Lin {\Lebesgue 2 \CompactGroup}] {%
%                    \Rep \lambda \BesselPotential {\gamma + \rho \abs \alpha}
%                    \eval {\DifferenceOperatorOrder \alpha \eta_\epsilon (\lambda)} {V_\tau}
%                }
%                (1 + \JapaneseBracket \CompactGroup \tau + \norm \lambda)^{-\gamma}.
%            \end{align*}
%
%            By Step 3a,
%            \begin{align*}
%                \eval {%
%                    \Rep \lambda \BesselPotential {\gamma + \rho \abs \alpha}
%                    } {\DifferenceOperatorOrder \alpha \eta_\epsilon(V_\tau)}
%                    \asymp
%                    (1 + \JapaneseBracket \CompactGroup \tau + \norm \lambda)^{\gamma + \rho \alpha} \Id {\DifferenceOperatorOrder \alpha \eta_\epsilon(V_\tau)}
%            \end{align*}
%            which,
%            if injected into the above calculation, yields
%            \begin{align*}
%                &\norm [\Lin {\Lebesgue 2 \CompactGroup}] {%
%                    \Rep \lambda \BesselPotential {\gamma + \rho \abs \alpha}
%                    \DifferenceOperatorOrder \alpha \eta_\epsilon (\lambda)
%                    \Rep \lambda \BesselPotential {-\gamma}
%                }\\
%                &\leq C
%                \sup_{\tau \in \dualGroup \CompactGroup}
%                \norm [\Lin {\Lebesgue 2 \CompactGroup}] {%
%                    \DifferenceOperatorOrder \alpha \eta_\epsilon (\lambda)
%                }
%                (1 + \JapaneseBracket \CompactGroup \tau + \norm \lambda)^{\rho \abs \alpha}\\
%                &\leq C
%                \norm [\Lin {\Lebesgue 2 \CompactGroup}] {%
%                    \Rep \lambda \BesselPotential {\rho \abs \alpha}
%                    \DifferenceOperatorOrder \alpha \eta_\epsilon (\lambda)
%                }
%            \end{align*}
%
%            However,
%            the right-hand side of the above is bounded by $C_\alpha$
%            by~\eqref{eq:eta_epsilon_symbol_norm_for_gamma_0}.
%
%        \item [Step 4a] Prove~\ref{item:generalized_Littlewood-Paley_decomposition:negative_m}.
%
%            Let $m \leq 0$.
%
%            From~\eqref{eq:Littlewood-Paley:difference_operators} and Lemma~\ref{lemma:left_regular_representation_of_polynomials},
%            % TODO: Make lemmas more relevant
%            we know that the range of the operator
%            \begin{align}
%                \Rep \lambda \BesselPotential {\rho \abs \alpha + \gamma}
%                \DifferenceOperatorOrder \alpha \eta_\epsilon(\lambda)
%                \Rep \lambda \BesselPotential {-\gamma}
%                \label{eq:Littlewood-Paley:central_operator}
%            \end{align}
%            is finite-dimensional,
%            and is actually contained in
%            \begin{align*}
%                R_\epsilon(\lambda) =
%                \bigoplus \{V_\tau : \norm \lambda \leq C_\alpha \epsilon^{-1} \text{ and } \JapaneseBracket \CompactGroup \tau \leq C_\alpha \epsilon^{-1} \}
%            \end{align*}
%            for some $c_\alpha, C_\alpha \geq 0$ depending only on $\alpha$.
%            As a result,
%            we can define the operator
%            \begin{align*}
%                L_\epsilon(\lambda) \defeq
%                \eval {\Rep \lambda \BesselPotential 1} {R_\epsilon(\lambda)}
%            \end{align*}
%            and be certain that $L_\epsilon(\lambda)$ and $\Rep \lambda \BesselPotential 1$ coincide on the range of~\eqref{eq:Littlewood-Paley:central_operator}
%            for every $\lambda \in \VectorSpace$.
%
%            Moreover,
%            it is clear that from the way we constructed $L_\epsilon(\lambda)$ that
%            \begin{align*}
%                \norm [\Lin {\Lebesgue 2 \CompactGroup}] {L_\epsilon(\lambda)} \leq C_\alpha \epsilon^{-1}.
%            \end{align*}
%            Therefore,
%            \begin{align*}
%                &\norm [\Lin {\Lebesgue 2 \CompactGroup}] {%
%                    \Rep \lambda \BesselPotential {-m + \rho \abs\alpha + \gamma}
%                    \DifferenceOperatorOrder \alpha \eta_\epsilon(\lambda)
%                    \Rep \lambda \BesselPotential {-\gamma}
%                }\\
%                &\quad \leq \norm [\Lin {\Lebesgue 2 \CompactGroup}] {%
%                    L_\epsilon(\lambda)^{-m}
%                    \Rep \lambda \BesselPotential {\rho \abs \alpha + \gamma}
%                    \DifferenceOperatorOrder \alpha \eta_\epsilon(\lambda)
%                    \Rep \lambda \BesselPotential {-\gamma}
%                }\\
%                &\quad \leq C_{\alpha, \gamma, m} \epsilon^{m},
%            \end{align*}
%            which concludes the proof of~\ref{item:generalized_Littlewood-Paley_decomposition:negative_m}
%
%        \item [Step 4b] Prove~\ref{item:generalized_Littlewood-Paley_decomposition:positive_m}
%
%            Let $m \geq 0$.
%            Clearly,
%            \begin{align*}
%                \DifferenceOperatorOrder \alpha \eta_\epsilon(\lambda) F(u)
%                &= \sum_{\tau \in \dualGroup \CompactGroup}
%                \iD {\lambda^{\alpha_1} } (1 - \chi_{\epsilon, \tau})(u^{-1} \lambda)
%                \DifferenceOperatorOrder [\CompactGroup] {\alpha_2} \Fourier [\CompactGroup] \chi_\tau F(u),
%            \end{align*}
%
%            Since $1 - \chi_{\epsilon, \tau}$ vanishes only when $\JapaneseBracket \CompactGroup \tau \norm \lambda \geq c \epsilon^{-2}$,
%            we can deduce that the range of~\eqref{eq:Littlewood-Paley:central_operator} is contained in
%            \begin{align*}
%                R_\epsilon(\lambda) \defeq \bigoplus \{V_\tau : \JapaneseBracket \CompactGroup \tau \norm \lambda \geq c_\alpha \epsilon^{-2} \}.
%            \end{align*}
%
%            Now, if we define the operator
%            \begin{align*}
%                L_\epsilon(\lambda) \defeq \eval {\Rep \lambda \BesselPotential 1} {R_\epsilon(\lambda)} \bigoplus c_\alpha \epsilon^{-1} \Id {\R_\epsilon(\lambda)^\perp},
%            \end{align*}
%            then by construction our operator satisfies
%            \begin{align*}
%                \norm [\Lin {\Lebesgue 2 \CompactGroup}] {L_\epsilon(\lambda)} \geq \epsilon^{-1}.
%            \end{align*}
%
%            Therefore,
%            \begin{align*}
%                &\norm [\Lin {\Lebesgue 2 \CompactGroup}] {%
%                    \Rep \lambda \BesselPotential {-m + \rho \abs\alpha + \gamma}
%                    \DifferenceOperatorOrder \alpha \eta_\epsilon(\lambda)
%                    \Rep \lambda \BesselPotential {-\gamma}
%                }\\
%                &\quad \leq \norm [\Lin {\Lebesgue 2 \CompactGroup}] {%
%                    L_\epsilon(\lambda)^{-m}
%                    \Rep \lambda \BesselPotential {\rho \abs \alpha + \gamma}
%                    \DifferenceOperatorOrder \alpha \eta_\epsilon(\lambda)
%                    \Rep \lambda \BesselPotential {-\gamma}
%                }\\
%                &\quad \leq C_{\alpha, \gamma, m} \epsilon^{m},
%            \end{align*}
%            which concludes the proof of~\ref{item:generalized_Littlewood-Paley_decomposition:positive_m}
%    \end{description}
%\end{proof}
%
%\begin{corollary}[Littlewood-Paley decomposition]
%    Let $\sigma \in \SymbolClass m {\rho, \delta}$.
%    There exists a sequence $(\sigma_l)_{l \in \N} \subset \SmoothingSymbols$
%    such that
%    \begin{align*}
%        \sigma = \sum_{l = 0}^{+\infty} \sigma_l.
%    \end{align*}
%
%    Moreover, for each $m \in \R$,
%    there exists $C \geq 0$ such that
%    \begin{align*}
%        \SymbolSemiNorm m {\rho, \delta} N {\sigma_l} \leq C 2^{-l m}
%    \end{align*}
%    holds for each $l \in \N$.
%\end{corollary}
%
%\begin{corollary}
%    Let $\sigma \in \SymbolClass m {\rho, \delta}$ for $m \in \R$ and $0 \leq \rho, \delta \leq 1$.
%    Fix a cut-off function $\chi \in \SmoothFunctions \Group$ satisfying
%    \begin{align*}
%        \chi(x, k) =
%        \begin{cases}
%            1 & \text{if } \norm x \leq 1\\
%            0 & \text{if } \norm x \geq 2
%        \end{cases},
%    \end{align*}
%    which allows us, for each $\epsilon \in (0, 1]$ to define
%    \begin{align*}
%        \sigma_\epsilon(x, k; \lambda) \defeq \chi(\epsilon x, k) \sigma(x, k; \lambda) \eta_\epsilon(\lambda)
%    \end{align*}
%    for each $g \in \Group$ and each $\lambda \in \VectorSpace$.
%
%    The symbol $\sigma_\epsilon$ is smoothing,
%    and satisfies the following estimates.
%    \begin{enumerate}
%        \item For every $m_1 \leq m$ and each $N \in \N$,
%            there exists $C = C_{m, m_1, N, \sigma} \geq 0$ such that
%            \begin{align*}
%                \SymbolSemiNorm {m_1} {\rho, \delta} N {\sigma_\epsilon}
%                \leq C \epsilon^{m_1 - m}
%            \end{align*}
%            holds for every $\epsilon \in (0, 1]$.
%        \item For every $m_1 \geq m$ and each $N \in \N$
%            there exists $C = C_{m, m_1, N, \sigma} \geq 0$ such that
%            \begin{align*}
%                \SymbolSemiNorm {m_1} {\rho, \delta} N {\sigma - \sigma_\epsilon}
%                \leq C \epsilon^{m_1 - m}
%            \end{align*}
%            holds for every $\epsilon \in (0, 1]$.
%    \end{enumerate}
%\end{corollary}
%
%%\begin{corollary}[Littlewood-Paley decomposition]
%%    There exists a sequence $\eta_l \in \SmoothingSymbols$, $l \in \N$ of smoothing symbols satisfying the following properties
%%    \begin{enumerate}
%%        \item the semi-norms decay in the following way
%%            \begin{align}
%%                \SymbolSemiNorm{m}{\rho, \delta} N {\eta_l} \leq C 2^{-lm}
%%            \end{align}
%%        \item the associated kernels $\kappa_l$ satisfy
%%            \begin{align*}
%%                \sum_{l = 0}^\infty \kappa_l = \DiracDelta{e_\Group}
%%            \end{align*}
%%            in the sense of distributions.
%%    \end{enumerate}
%%\end{corollary}
%%\begin{proof}
%%    Let $\eta'_\epsilon$, $\epsilon \in (0, 1]$ be the family given by Theorem~\ref{theorem:generalized_Littlewood-Paley_decomposition}.
%%    For each $l \in \N$,
%%    we define
%%    \begin{align*}
%%        \begin{cases}
%%            \eta_0 \defeq \eta'_1\\
%%            \eta_l \defeq \eta'_{2^{-l}} - \eta'_{2^{-l + 1}}
%%        \end{cases}
%%    \end{align*}
%%    For $l \geq 1$,
%%    we have
%%    \begin{align*}
%%        &\norm [\Lin {\Lebesgue 2 \Group}] {%
%%        \Rep \lambda \BesselPotential {-m + \rho \abs \alpha + \gamma}
%%        \DifferenceOperatorOrder \alpha \left( \eta'_{2^{-l}} - \eta'_{2^{-l + 1}} \right)
%%        \Rep \lambda \BesselPotential {-\gamma}
%%        }\\
%%        & \qquad \leq C_{\alpha, \gamma, m} (1 + 2^{-m}) 2^{-l m}\\
%%        & \qquad \leq C_{\alpha, \gamma, m} 2^{-l m},
%%    \end{align*}
%%    while the case $l = 1$ follows directly from Theorem~\ref{theorem:generalized_Littlewood-Paley_decomposition}.
%%
%%    The second claim follows from the fact that
%%    \begin{align*}
%%        \sum_{l = 0}^{L} \eta_l
%%        &= \eta'_1 + \sum_{l = 1}^{L} \eta_l
%%        = \eta'_{2^{-1}} + \sum_{l = 2}^{L} \eta_l\\
%%        &= \eta'_{2^{-L + 1}} + \eta_L
%%        = \eta'_{2^{-L}}
%%    \end{align*}
%%    and Theorem~\ref{theorem:generalized_Littlewood-Paley_decomposition}.
%%\end{proof}

\section{Kernel estimates}

Of particular importance is the study of the kernel.
Firstly, we want our pseudo-differential operators in $\OperatorClass 0 {1, 0}$ to be Calder\'on-Zygmund,
which requires that the singularity only appear at the origin and be of a certain strength.
Moreover,
we shall compute the composition and adjunction on the kernel side
and rely on precise estimates to prove the celebrated \emph{composition and adjunction formulae}.

%As we have seen so far,
%a pseudo-differential operator is entirely determined by either its \emph{right-convolution kernel} or its \emph{symbol}.
%Symbols have the distinctive advantage of being \emph{smooth},
%which is why for \emph{abelian} Lie groups,
%a pseudo-differential calculus can be developed by doing all the calculations on the symbolic side
%(for this, see e.g.\ \cite{RuzhanskyTurunen10}).
%
%For non-commutative groups such as the motion group,
%the Fourier transform is \emph{operator valued} and therefore, so are symbols.
%This unfortunately means that it will sometimes be impractical to work with symbols,
%and that calculations will have to be carried out in terms of the kernels.
%It is therefore crucial to study their properties,
%such as their \emph{singularity} or their \emph{decay} away from the origin.

It is important to note that all the results in this section rely on the reduction of the order
through the application of difference operators.
Therefore,
we shall henceforth assume that $\rho > 0$
and every result concerning or using kernel estimates will have that assumption.

We shall see that the regularity of the kernel increases
as the order of the symbol decreases.
Since $\rho > 0$, applying difference operators decreases the order of the symbol
which can be reformulated equivalently
by saying that multiplying kernels by some suitable polynomial increases its regularity.
However, this can only happen if at each $g \in \Group$,
either the kernel is smooth around that point or the polynomial vanishes at $g$.
The reader should therefore expect smoothness and Schwartz decay away from the origin,
as the latter is the only point where we allow \emph{all} our polynomials to vanish
(see Definition~\ref{definition:admissibility_of_polynomials}).

Before stating the main result of this section,
let us define the quantity
\begin{align*}
    \norm [\Group] {(x, k)} \defeq \norm {x} + d_\CompactGroup(k, \Id{\VectorSpace}), \quad (x, k) \in \Group,
\end{align*}
where $d_\CompactGroup$ is a left-invariant Riemannian distance on $\CompactGroup$.
The above is of course an abuse of notation, as $\norm [\Group] \dummy$ is not a norm.

The aim of this section is to prove the following result.

\begin{theorem}[Kernel estimates]
\label{theorem:kernel_estimates}
    Let $\rho, \delta \in \R$ be such that $1 \geq \rho \geq \delta \geq 0$
    and assume further that $\rho > 0$.
    Suppose that $\sigma \in \SymbolClass{m}{\rho, \delta}$,
    and $\kappa \in \SmoothFunctions {\Group, \TemperedDistributions \Group}$ is its associated kernel.
    \begin{enumerate}
        \item \label{item:kernel_estimates:at_infinity}
            For every $d > 0$ and every $N \in \N$,
            there exists $C \geq 0$ such that for every $g, h = (y, l) \in \Group$ with $\norm {y} \geq d$, we have
            \begin{align*}
                \abs{\kappa_g(h)} \leq C \norm y^{-N}.
            \end{align*}
        \item \label{item:kernel_estimates:at_origin:positive}
            If $m > - \dim \Group$ and $\rho < 1$, there exists $C \geq 0$ such that for every $g, h \in \Group$ with $h \neq 0$, we have
            \begin{align*}
                \abs{\kappa_g(h)} \leq C \norm [\Group] h^{- \frac{\dim \Group + m}{\rho}}.
            \end{align*}
        \item \label{item:kernel_estimates:at_origin:zero}
            If $m \geq -\dim \Group$ or $\rho = 1$,
            then for every $\gamma < -(m + \dim \Group)/\rho$,
            there exists $C \geq 0$ such that for every $g, h \in \Group$ with $h \neq 0$, we have
            \begin{align*}
                \abs{\kappa_g(h)} \leq C \norm [\Group] h^\gamma.
            \end{align*}
        \item \label{item:kernel_estimates:at_origin:negative}
            If $m < -\dim \Group$, $\kappa_g$ is continuous on $\Group$ and is bounded
            \begin{align*}
                \sup_{g, h \in \Group} \abs{\kappa_g(h)} \leq C < \infty.
            \end{align*}
    \end{enumerate}
\end{theorem}

The estimates at the origin in Theorem~\ref{theorem:kernel_estimates} are sufficient to obtain the pseudo-differential calculus but not the Calder\'on-Zygmund property.
This is due to the fact that our proof will rely exclusively on the \emph{Sobolev inequality}.

The following example illustrates very well the relationship between
the estimates around the origin of Theorem~\ref{theorem:kernel_estimates}
and the \emph{Sobolev inequality}.
Moreover, it shows that the estimates at the origin in Theorem~\ref{theorem:kernel_estimates} are not optimal.

\begin{example}[Bessel potential]
    Suppose that
    \begin{align*}
        \sigma_m(\lambda) \defeq \Rep \lambda \BesselPotential m,
        \quad
        \kappa_m(h) \defeq (\InverseFourier \sigma_m)(h)
    \end{align*}
    for each $m \in \R$.
    The Bessel potential is smooth away from the origin and satisfies
    \begin{align*}
        \abs {\kappa_m(h)} \leq
        \begin{cases}
            C \norm [\Group] h^\gamma & \text{if } m > -\dim \Group \text{ and } \gamma < -(m + \dim \Group)\\
            C & \text {if } m < -\dim \Group.
        \end{cases}
    \end{align*}

    By carrying direct estimates on the \emph{heat kernel} (see Subsubsection~\ref{subsubsection:kernel_estimates_revisited}),
    we can show
    \begin{align*}
        \abs {\kappa_m(h)} \leq C \norm [\Group] h^{-(m + \dim \Group)} \quad \text{if } m > -\dim \Group.
    \end{align*}
\end{example}

\subsection{\texorpdfstring{$L^2$}{L2} estimates for the kernel}

The first step towards establishing estimates on $\sup_{g, h \in \Group} \abs {\kappa_g(h)}$
is to provide $\Lebesgue 2 \Group$ estimates for derivatives of $\kappa_g$ that are not dependent on $g \in \Group$.
This is, of course, a consequence of the Sobolev inequality (Proposition~\ref{proposition:Sobolev_embedding}).

\begin{proposition}
\label{proposition:L2_bound_on_the_kernel}
    Let $\sigma \in \SymbolClass m {\rho, \delta}$ with $1 \geq \rho \geq \delta \geq 0$,
    and denote by $\kappa \in \SmoothFunctions {\Group, \TemperedDistributions \Group}$ its associated kernel.
    If $m < -\dim \Group / 2$,
    then $\kappa_g \in \Lebesgue 2 \Group$ for every $g \in \Group$,
    \begin{align*}
        \sup_{g \in \Group} \norm [\Lebesgue 2 \Group] {\kappa_g} < \infty.
    \end{align*}
\end{proposition}
\begin{proof}
    Let $g \in \Group$ and $\lambda \in \VectorSpace$.
    Clearly,
    \begin{align*}
        &\norm [\SchattenClasses 2 {\Lebesgue 2 \CompactGroup}] {\sigma(g, \lambda)}^2\\
        &\quad= \norm [\SchattenClasses 2 {\Lebesgue 2 \CompactGroup}] {\Rep \lambda \BesselPotential m \Rep \lambda \BesselPotential {-m} \sigma(g, \lambda)}^2\\
        &\quad\leq
        \norm [\SchattenClasses 2 {\Lebesgue 2 \CompactGroup}] {\Rep \lambda \BesselPotential {-m}}^2
        \norm [\Lin {\Lebesgue 2 \CompactGroup}] {\Rep \lambda \BesselPotential {-m} \sigma(g, \lambda)}^2.
    \end{align*}

    Using $\sigma \in \SymbolClass m {\rho, \delta}$,
    the above becomes
    \begin{align*}
        \norm [\SchattenClasses 2 {\Lebesgue 2 \CompactGroup}] {\sigma(g, \lambda)}^2
        \leq C \norm [\SchattenClasses 2 {\Lebesgue 2 \CompactGroup}] {\Rep \lambda \BesselPotential {-m}}^2.
    \end{align*}

    Integrating both sides of the above with respect to $\lambda \in \VectorSpace$
    and using the Plancherel formula (Proposition~\ref{proposition:Plancherel_formula}) on either sides,
    we get
    \begin{align*}
        \norm [\Lebesgue 2 \CompactGroup] {\kappa_g}^2 \leq C \norm [\Lebesgue 2 \CompactGroup] {\BesselPotentialKernel {-m}}^2.
    \end{align*}

    We conclude the proof by observing that the right-hand side is finite by assumption on $m$ and Proposition~\ref{proposition:Sobolev_embedding},
    but also that the right-hand side does not depend on $g$.
\end{proof}

\begin{corollary}
\label{corollary:Sobolev_estimates_on_the_kernel}
    Let $\sigma \in \SymbolClass m {\rho,\delta}$ with $1 \geq \rho \geq \delta \geq 0$,
    and denote by $\kappa \in \SmoothFunctions {\Group, \TemperedDistributions \Group}$ its associated kernel.

    For every $s \in \R$ satisfying
    \begin{align*}
        s < -\frac{\dim \Group} 2 - m,
    \end{align*}
    the kernel $\kappa_g$ belongs to $\Sobolev s$ for every $g \in \Group$.
    Moreover, for such an $s \in \R$, we have the estimate:
    \begin{align*}
        \sup_{g \in \Group} \norm [\Sobolev s] {\kappa_g} < \infty.
    \end{align*}
\end{corollary}
\begin{proof}
    The symbol
    \begin{align*}
        \Rep \lambda \BesselPotential s \sigma(g, \lambda)
    \end{align*}
    belongs to $\SymbolClass {m + s} {\rho, \delta}$,
    with $m + s \leq -\dim \Group/2$ by our assumption.

    Therefore, applying Proposition~\ref{proposition:L2_bound_on_the_kernel},
    we know that for every $g \in \Group$,
    \begin{align*}
        \BesselPotential s \kappa_g \in \Lebesgue 2 \Group,
    \end{align*}
    or in other words, $\kappa_g \in \Sobolev s$, and
    \begin{align*}
        \sup_{g \in \Group} \norm [\Sobolev s] {\kappa_g}
        = \sup_{g \in \Group} \norm [\Lebesgue 2 \Group] {\BesselPotential s \kappa_g}
        < \infty,
    \end{align*}
    concluding the proof.
\end{proof}

We can now prove Part~\ref{item:kernel_estimates:at_origin:negative} of Theorem~\ref{theorem:kernel_estimates}.

\begin{corollary}
\label{corollary:kernel_estimates:at_origin:negative}
    Let $\sigma \in \SymbolClass m {\rho,\delta}$ with $1 \geq \rho \geq \delta \geq 0$,
    and denote by $\kappa \in \SmoothFunctions {\Group, \TemperedDistributions \Group}$ its associated kernel.

    If $m < -\dim \Group$,
    then $\kappa_g \in \ContinuousFunctions \Group$ is continuous for every $g \in \Group$ and
    \begin{align*}
        \sup_{g \in \Group} \norm [\ContinuousFunctions \Group] {\kappa_g} < \infty.
    \end{align*}
\end{corollary}
\begin{proof}
    Choose $s \in \R$ such that
    \begin{align*}
        \frac {\dim \Group} 2 < s < -\frac {\dim \Group} 2 - m,
    \end{align*}
    which is possible since $m < -\dim \Group$.

    Since $m < -\dim \Group/2 - s$,
    Corollary~\ref{corollary:Sobolev_estimates_on_the_kernel} implies that
    $\kappa_g \in \Sobolev s$ for every $g \in \Group$,
    \begin{align*}
        \sup_{g \in \Group} \norm [\Sobolev s] {\kappa_g} < \infty.
    \end{align*}

    However,
    since $s > \dim \Group / 2$,
    the Sobolev inequality (Proposition~\ref{proposition:Sobolev_embedding})
    implies that
    \begin{align*}
        \sup_{g \in \Group} \norm [\ContinuousFunctions \Group] {\kappa_g}
        \leq C \sup_{g \in \Group} \norm [\Sobolev s] {\kappa_g} < \infty.
    \end{align*}
    This concludes the proof.
\end{proof}

\subsection{Estimates at infinity}

We start by proving Part \ref{item:kernel_estimates:at_infinity} of Theorem~\ref{theorem:kernel_estimates}.

\begin{proof}
    Let $M \in \R$ and choose $p \in 2 \N$ sufficiently large so that
    \begin{align*}
        g \geq M \quad \text{and} \quad
        m - \rho p + \Ceiling {\dim \Group / 2} < -\frac {\dim \Group} 2
    \end{align*}

    Fix $d > 0$,
    and let $\chi \in \SmoothFunctions \Group$ be a smooth radial function satisfying
    \begin{align*}
        \chi(y, l) =
        \begin{cases}
            0 & \text{if } \norm y \leq d/2\\
            1 & \text{if } \norm y \geq d
        \end{cases}
    \end{align*}

    From now on, we shall write $h = (y, l)$.

    By the Sobolev inequality (Proposition~\ref{proposition:Sobolev_embedding}),
    we have
    \begin{align}
        \sup_{\norm y \geq d} &\abs{\norm y^M \kappa_g(h)} \notag\\
        &\leq \sup_{h \in \Group} \abs{\norm y^M \kappa_g(h) \chi(h)} \notag\\
        &\leq C \sum_{\abs \beta \leq \Ceiling {\dim \Group / 2}} \norm [\Lebesgue 2 {\Group, \dd h}] {\LeftDifferentialOperator [h] \beta \{\norm y^M \kappa_g(h) \chi(h)\}}.
        \label{eq:Schwartz_decay_of_kernel:first_estimate}
    \end{align}

    Let us do some calculations on the right-hand side of the above.
    By the Leibniz formula, we have
    \begin{align}
        &\abs {\LeftDifferentialOperator [h] \beta \{\kappa_g(h) \chi(h)\}} \notag\\
        &\leq \lcsum {\beta' \leq \beta} \abs{\LeftDifferentialOperator [h] {\beta - \beta'} \{\norm y^{M - p} \chi(h)\} \LeftDifferentialOperator [h] {\beta'} \{\norm y^p \kappa_g(h)\}} \notag\\
        &\leq
        \left(\lcsum {\beta' \leq \beta} \abs{\LeftDifferentialOperator [h] {\beta'} \{\norm y^{M - p} \chi(h)\}}^2\right)^{\frac 1 2}
        \left(\lcsum {\beta' \leq \beta} \abs{\LeftDifferentialOperator [h] {\beta'} \{\norm y^p \kappa_g(h)\}}^2\right)^{\frac 1 2},
        \label{eq:Schwartz_decay_of_kernel:Leibniz}
    \end{align}
    where the last line was obtained by applying the Cauchy-Schwartz inequality to the sum.
    Since $p \geq M$ and $\chi$ vanishes around $\{0_\VectorSpace\} \times \CompactGroup$,
    it follows that
    \begin{align*}
        \sup_{h \in \Group} \lcsum {\beta' \leq \beta} \abs{\LeftDifferentialOperator [h] {\beta'} \{\norm y^{M - p} \chi(h)\}}^2 < \infty,
    \end{align*}
    which means that~\eqref{eq:Schwartz_decay_of_kernel:Leibniz} becomes
    \begin{align*}
        \abs {\LeftDifferentialOperator [h] \beta \{\kappa_g(h) \chi(h)\}}
        \leq C \left(\lcsum {\beta' \leq \beta} \abs{\LeftDifferentialOperator [h] {\beta'} \{\norm y^p \kappa_g(h)\}}^2\right)^{\frac 1 2}.
    \end{align*}

    Therefore, if we square both sides of the above and integrate with respect to $h$, we obtain
    \begin{align*}
        &\int_\Group \abs {\LeftDifferentialOperator [h] \beta \{\kappa_g(h) \chi(h)\}}^2 \dd h\\
        &\qquad \leq C \int_\Group \lcsum {\beta' \leq \beta} \abs{\LeftDifferentialOperator [h] {\beta'} \{\norm y^p \kappa_g(h)\}}^2 \dd h\\
        &\qquad \leq C \lcsum {\beta' \leq \beta} \sum_{\abs \alpha = p} \int_\Group \abs{\LeftDifferentialOperator {\beta'} \{q^\alpha \kappa_g\}}^2 \dd h,
    \end{align*}
    where the last line was obtained by using ??. % TODO: reference!
    Continuing the above calculation,
    we get
    \begin{align*}
        &\int_\Group \abs {\LeftDifferentialOperator [h] \beta \{\kappa_g(h) \chi(h)\}}^2 \dd h\\
        &\quad \leq C \sum_{\abs \alpha = p} \int_\Group \abs{\BesselPotential {\Ceiling {\dim \Group / 2}} \{q^\alpha \kappa_g\}}^2 \dd h.
    \end{align*}

    Combinig the above with~\eqref{eq:Schwartz_decay_of_kernel:first_estimate},
    this yields
    \begin{align}
        \sup_{\norm y \geq d} &\abs{\norm y^M \kappa_g(h)}
        \leq C \sum_{\abs \alpha = p} \norm [\Lebesgue 2 \Group] {\BesselPotential {\Ceiling {\dim \Group / 2}} \{q^\alpha \kappa_g\}}.
        \label{eq:Schwartz_decay_of_kernel:final_step}
    \end{align}
    In the above,
    each symbol $\Rep \lambda \BesselPotential {\Ceiling {\dim \Group / 2}} \DifferenceOperatorOrder \alpha \sigma(g, \lambda)$ is of order
    \begin{align*}
        m - \rho p + \Ceiling {\dim \Group / 2} < -\frac {\dim \Group} 2
    \end{align*}
    so that its kernel $\BesselPotential {\Ceiling {\dim \Group / 2}} \{q^\alpha \kappa_g\}$ belongs to $\Lebesgue 2 \Group$ uniformly in $g \in \Group$ by Proposition~\ref{proposition:L2_bound_on_the_kernel}.
    This implies that~\eqref{eq:Schwartz_decay_of_kernel:final_step} becomes
    \begin{align*}
        \sup_{g \in \Group} \sup_{\norm y \geq d} &\abs{\norm y^M \kappa_g(h)} < \infty,
    \end{align*}
    concluding the proof.
\end{proof}

\subsection{Estimates at the origin}

We have shown so far that the regularity of the kernel is linked to the order of its corresponding symbol in the following way:
the lower the order, the more regular the kernel is.
As applying difference operator strictly \emph{reduces the order} when $\rho > 0$,
the distribution
\begin{align*}
    q^\alpha \kappa_g \defeq \InverseFourier \{ \DifferenceOperatorOrder \alpha \sigma(g, \dummy) \}
\end{align*}
becomes more regular as $\abs \alpha$ increases.
This means that $\kappa_g$ can only have singularities at the common zeros
\begin{align*}
    \bigcap_{j = 1}^{\dimDifferenceOperators} \{ q_j = 0 \} = (0_\VectorSpace, \Id \VectorSpace),
\end{align*}
which happens to simply be the origin
as the family $\{q_j : j = 1, \cdots, \dimDifferenceOperators\}$ was chosen to be \emph{strongly admissible}.

The aim of this subsection is therefore to study the strength of the only singularity that a kernel can have,
which will lead to the proof of parts \ref{item:kernel_estimates:at_origin:positive} and \ref{item:kernel_estimates:at_origin:zero} of Theorem~\ref{theorem:kernel_estimates}.

\begin{theorem}[Kernel estimates at the origin]
\label{theorem:kernel_estimates:at_origin}
    Let $\rho, \delta \in \R$ be such that $1 \geq \rho \geq \delta \geq 0$
    and assume further that $\rho > 0$.
    Suppose that $\sigma \in \SymbolClass{m}{\rho, \delta}$,
    and $\kappa \in \SmoothFunctions {\Group, \TemperedDistributions \Group}$ denotes its associated kernel.
    \begin{enumerate}
        \item
            If $\rho < 1$ and $m > -\dim \Group$, there exists $C \geq 0$ such that for every $g, h \in \Group$ with $h \neq 0$, we have
            \begin{align*}
                \abs{\kappa_g(h)} \leq C \norm [\Group] h^{- \frac{\dim \Group + m}{\rho}}.
            \end{align*}
        \item
            If $\rho = 1$ or if $m = -\dim \Group$,
            then for every $\gamma < -(\dim \Group + m)/\rho$,
            there exists $C \geq 0$ such that for every $g, h \in \Group$ with $h \neq 0$, we have
            \begin{align*}
                \abs{\kappa_g(h)} \leq C \norm [\Group] h^\gamma.
            \end{align*}
    \end{enumerate}
\end{theorem}
\begin{proof}
    Fix $h \in \Group \setminus \{(0, \Id \VectorSpace)\}$ such that $\epsilon \defeq \norm [\Group] h \leq 1$.
    Define the symbol
    \begin{align*}
        \sigma_\epsilon(g, \lambda) \defeq \sigma(g, \lambda),
        \quad g \in \Group, \lambda \in \VectorSpace,
    \end{align*}
    and denote by $\kappa_\epsilon \defeq \InverseFourier \{\sigma(g, \dummy)\}$
    its associated kernel.

    Using
    \begin{align*}
        \abs {\kappa_g(h)} \leq \abs{\kappa_{\epsilon, g}(h)} + \abs{\kappa_g(h) - \kappa_{\epsilon, g}(h)},
    \end{align*}
    the idea of the proof is to estimate both terms of the right-hand side above separately.

    As we have shown earlier in Corollary~\ref{corollary:Sobolev_estimates_on_the_kernel}
    we can get a bound on the kernel provided the order of its associated symbol is strictly less than $-\dim \Group$.
    For $\kappa_\epsilon$, this will be easy since $\sigma_\epsilon$ is smoothing;
    for $\kappa_g - \kappa_{g, \epsilon}$, we will have to use difference operators.

    Note that the case $m = -\dim \Group$ is a simple consequences of the other estimates,
    and the inclusion $\SymbolClass m {\rho, \delta} \subset \SymbolClass {m'} {\rho, \delta}$ when $m \leq m'$.
    We can therefore assume without loss of generality that $m > -\dim \Group$.

    \begin{description}
        \item[Estimates on $\kappa_\epsilon$]
            We observe that for each $\gamma \in \R$,
            we have
            \begin{align*}
                \sigma_\epsilon(g, \lambda)
                &= \sigma(g, \lambda) \Rep \lambda \BesselPotential {-m}\\
                &\qquad \eta_\epsilon(\lambda) \Rep \lambda \BesselPotential {-\gamma}
                \Rep \lambda \BesselPotential {-m + \gamma}.
            \end{align*}

            Using the Holder inequality on Schatten classes,
            together with Theorem~\ref{theorem:generalized_Littlewood-Paley_decomposition},
            we obtain
            \begin{align}
                \norm [\SchattenClasses 1 {\Lebesgue 2 \CompactGroup}] {\sigma_\epsilon(g, \lambda)} \leq C
                \epsilon^{\gamma} \norm [\SchattenClasses 1 {\Lebesgue 2 \CompactGroup}] {\Rep \lambda \BesselPotential {m + \gamma}}
                \label{eq:estimate_on_the_schatten_norm_of_sigma_epsilon}
            \end{align}
            for every $\gamma \leq 0$.

            The idea is now to pick $\gamma < \min \{0, -(\dim \Group + m)\}$, so that
            \begin{align}
                \abs{\kappa_{\epsilon, g}(h)}
                \leq \int_\VectorSpace \norm [\SchattenClasses 1 {\Lebesgue 2 \CompactGroup}] {\sigma_\epsilon(g, \lambda)} \dd \lambda
                \leq C
                \epsilon^{\gamma},
                \label{eq:estimate_on_the_smoothened_kernel}
            \end{align}
            where the last inequality was obtained by the Sobolev inequality (Proposition~\ref{proposition:Sobolev_embedding}).

            The idea is now to pick a suitable $\gamma \leq 0$ and obtain an estimate on the kernel via~\eqref{eq:estimate_on_the_smoothened_kernel}.
            Keeping in mind that $\epsilon = \norm [\Group] h$,
            let us now treat the different cases separately.
            \begin{description}
                \item[$\rho = 1$ and $m > -\dim \Group$.] We pick $\gamma < -(\dim \Group + m)$ to obtain
                    \begin{align*}
                        \abs {\kappa_{\epsilon, g}(h)}
                        &\leq C \norm [\Group] h^\gamma.
                    \end{align*}
                \item[$\rho < 1$ and $m > -\dim \Group$.]
                    We pick
                    \begin{align*}
                        \gamma \defeq -\frac {\dim \Group + m} \rho,
                    \end{align*}
                    and check that $\gamma < 0$ by the condition on $m$ and
                    $\gamma < -(\dim \Group + m)$ by our condition on $\rho$.

                    Therefore, \eqref{eq:estimate_on_the_smoothened_kernel} yields
                    \begin{align*}
                        \abs {\kappa_{\epsilon, g}(h)}
                        \leq C \norm [\Group] h^{-\frac {\dim \Group + m} {\rho}}.
                    \end{align*}

                    Note that we could get a better estimate here,
                    but we choose not to do so,
                    because in this setting our choice of $\gamma$ will turn out to be appropriate when estimating $\kappa_g - \kappa_{g, \epsilon}$.
                \item[$m = -\dim \Group$]
                    Letting $\gamma = 0$ in \eqref{eq:estimate_on_the_smoothened_kernel} yields
                    \begin{align*}
                        \abs {\kappa_{\epsilon, g}(h)}
                        \leq C \log \norm [\Group] h.
                    \end{align*}
            \end{description}

        \item[Estimate on $\kappa_g - \kappa_{g, \epsilon}$].
            The strategy of the proof is the same,
            but slightly more delicate.
            As $\gamma$ needs to be positive to apply Theorem~\ref{theorem:generalized_Littlewood-Paley_decomposition},
            we will need to apply difference operators so that $m$ would be replaced by $m - \rho \abs \alpha$,
            thus making it possible for $\gamma + m - \rho \abs \alpha$ to be small enough.

            By the Leibniz rule,
            we have
            \begin{align*}
                \DifferenceOperator \alpha (\sigma - \sigma_\epsilon)
                &= \lcsum{\abs {\alpha_1} + \abs {\alpha_2} = \abs \alpha}
                \DifferenceOperator {\alpha_1} \sigma \DifferenceOperator {\alpha_2} \eta_\lambda\\
                &= \lcsum{\abs {\alpha_1} + \abs {\alpha_2} = \abs \alpha}
                I_{1, \alpha_1} I_{2, \alpha_2, \gamma} I_{3, \gamma},
            \end{align*}
            where
            \begin{align*}
                I_{1, \alpha_1} &\defeq \DifferenceOperator {\alpha_1} \sigma(g, \lambda) \Rep \lambda \BesselPotential {-m + \rho \abs {\alpha_1}}\\
                I_{2, \alpha_2, \gamma} &\defeq \Rep \lambda \BesselPotential {m - \rho \abs {\alpha_1}} \DifferenceOperatorOrder {\alpha_2} (\Id {\Lebesgue 2 \CompactGroup} - \eta_\epsilon(\lambda))\\
                &\qquad \qquad\Rep \lambda \BesselPotential {-\gamma + \rho \abs {\alpha_2} - m + \rho \abs {\alpha_1})}\\
                I_{3, \gamma} &\defeq \Rep \lambda \BesselPotential {\gamma + m - \rho \abs \alpha}
            \end{align*}

            Since $\sigma \in \SymbolClass m {\rho, \delta}$,
            $\norm [\Lin {\Lebesgue 2 \CompactGroup}] {I_{1, \alpha_1}}$ is bounded uniformly in $\alpha_1$,
            while
            \begin{align*}
                \norm [\Lin {\Lebesgue 2 \CompactGroup}] {I_{2, \alpha_2, \gamma}}
                \leq C \epsilon^\gamma
            \end{align*}
            holds for every $\gamma \geq 0$ by Theorem~\ref{theorem:generalized_Littlewood-Paley_decomposition}.
            Therefore, for every $\gamma \geq 0$, we have
            \begin{align*}
                &\norm [\SchattenClasses 1 {\Lebesgue 2 \CompactGroup}] {\DifferenceOperator \alpha (\sigma - \sigma_\epsilon)(g, \lambda)}\\
                & \qquad \leq C \epsilon^\gamma
                \norm [\SchattenClasses 1 {\Lebesgue 2 \CompactGroup}] {\Rep \lambda \BesselPotential {\gamma + m - \rho \abs \alpha}},
            \end{align*}
            where the Schatten norm on the right hand side is not necessarily finite.

            Integrating the above with respect to $\lambda \in \VectorSpace$,
            we obtain
            \begin{align*}
                \abs {(q^\alpha(\kappa_g - \kappa_{g, \epsilon}))(h)}
                \leq C \epsilon^\gamma
            \end{align*}
            provided that $\gamma \geq 0$ and $\gamma + m - \rho \abs \alpha < -\dim \Group$.
            Observe that those two conditions can be summarized by the inequality
            \begin{align*}
                0 \leq \gamma < \rho \abs \alpha - (\dim \Group + m).
            \end{align*}

            Since for every $r \in 2 \N$, we have
            \begin{align*}
                \norm [\Group] h^r \abs{(\kappa_g - \kappa_{g, \epsilon})(h)}
                &\leq C \sum_{\abs \alpha = r} \abs{q^\alpha(h) (\kappa_g - \kappa_{g, \epsilon})(h)},
            \end{align*}
            we have so far shown, keeping in mind that $\epsilon = \norm [\Group] h$ that
            \begin{align}
                \abs{(\kappa_g - \kappa_{g, \epsilon})(h)}
                &\leq C \norm [\Group] h^{\gamma - r}
                \label{eq:estimate_on_the_remainder}
            \end{align}
            provided $0 \leq \gamma < \rho r - (\dim \Group + m)$.

            We observe that the best estimate is achieved when
            \begin{align*}
                r \defeq \min \{n \in 2 \N : n > \frac{\dim \Group + m} \rho \}
            \end{align*}
            because it should be as small as possible,
            but also the condition on $\gamma$ must be possible.

            Let us now treat the different cases.
            \begin{description}
                \item[$\rho = 1$ and $m > -\dim \Group$]
                    Choose $\tilde \gamma \defeq \gamma - r$
                    so that $-r \leq \tilde \gamma < -(\dim \Group + m)$.
                    Clearly, we have
                    \begin{align*}
                        \abs{(\kappa_g - \kappa_{g, \epsilon})(h)}
                        \leq \norm [\Group] h^{\tilde \gamma}.
                    \end{align*}
                \item[$\rho < 1$ and $m > -\dim \Group$]
                    Pick $\gamma$ as follows:
                    \begin{align*}
                        \gamma - r = -\frac{\dim \Group + m} \rho.
                    \end{align*}
                    We check that
                    \begin{align*}
                        \gamma = r - \frac {\dim \Group + m} \rho > 0,
                    \end{align*}
                    and similarly,
                    \begin{align*}
                        \gamma - \rho r &= r(1 - \rho) - \frac {\dim \Group + m} \rho\\
                        &= -\rho r(1 - \frac 1 \rho) - (\dim \Group + m) \frac 1 \rho\\
                        &< -(\dim \Group + m)(1 - \frac 1 \rho + \frac 1 \rho),
                    \end{align*}
                    which can be rewritten as $\gamma < \rho r - (\dim \Group + m)$.
                    Note that we could not have obtained the strict inequality above
                    had we not assumed that $\rho < 1$.
                    We can thus apply~\eqref{eq:estimate_on_the_remainder} to obtain
                    \begin{align*}
                        \abs{(\kappa_g - \kappa_{g, \epsilon})(h)}
                        \leq \norm [\Group] h^{-\frac {\dim \Group + m} \rho}
                    \end{align*}
            \end{description}
    \end{description}
    The kernel estimates now follow from the triangle inequality.
\end{proof}

\begin{remark}[Kernel estimates when $m = -\dim \Group$]
    We might wonder whether it is possible to obtain better estimates for the case $m = -\dim \Group$
    than the ones they inherit from the symbol classes inclusion.

    Let $h \in \Group$ be such that $\epsilon \defeq \norm [\Group] h \in (0, 1]$
    Writing
    \begin{align*}
        \sigma_\epsilon(g, \lambda)
        = \sigma(g, \lambda) \Rep \lambda \BesselPotential {-m} \eta_\epsilon(\lambda) \Rep \lambda \BesselPotential {m},
    \end{align*}
    we see that
    \begin{align*}
        \abs {\kappa_{\epsilon, g}}
        &\leq C \int_\VectorSpace \norm [\SchattenClasses 1 {\Lebesgue 2 \CompactGroup}] {\eta_\epsilon(\lambda) \Rep \lambda \BesselPotential m}\\
        &\leq C \log \epsilon = C \log \norm [\Group] h,
    \end{align*}
    which is better than what Theorem~\ref{theorem:kernel_estimates:at_origin} gives us.

    Unfortunately,
    a similar estimate cannot be achieved for $\kappa_g - \kappa_{\epsilon, g}$.
    This can be seen by setting
    \begin{align*}
        \sigma(g, \lambda) \defeq \Rep \lambda \BesselPotential {-\dim \Group}
    \end{align*}
    and observing that
    $\abs {\kappa_g - \kappa_{\epsilon, g}}$ could not be bounded.
\end{remark}

\section{Adjoint and composition formulas}
\label{section:adjoint_and_composition_formulae}

We are now ready to prove our two main results.

\begin{itemize}
    \item Provided $\rho > \delta$,
        each operator class $\OperatorClass m {\rho, \delta}$ is stable under adjunction.
    \item Provided $\rho > \delta$,
        the composition of $T_1 \in \OperatorClass {m_1} {\rho, \delta}$ and $T_2 \in \OperatorClass {m_2} {\rho, \delta}$ is in $\OperatorClass {m_1 + m_2} {\rho, \delta}$.
\end{itemize}

Importantly,
the \emph{composition formula} will relate the composition of operators
to the pointwise composition of symbols,
leading to the most beautiful application of pseudo-differential calculus:
the construction of parametrices.

The stability under adjunction will in particular imply that we can extend our pseudo-differential operators (and their parametrices when they exist) onto the set of tempered distributions.

\subsection{Asymptotic sums of symbols}

More complex operations on operators
like composition and adjunction
cannot be written in terms of symbols without using a Taylor development on the kernel side.
This yields an infinite sum of symbols,
and we need to find out whether it converges in a satisfactory sense for our purposes.

\begin{proposition}[Asymptotic sum]
\label{proposition:asymptotic_sum_of_symbols}
    Given $1 \geq \rho \geq \delta \geq 0$,
    let $(\sigma_j)_{j \in \N}$ be a sequence of symbols such that $\sigma_j \in \SymbolClass {m_j} {\rho, \delta}$,
    where $(m_j)_{j \in \N}$ is a \emph{strictly decreasing} sequence of real numbers.

    There exists a symbol $\sigma \in \SymbolClass {m_0} {\rho, \delta}$
    such that
    \begin{align}
        \sigma - \sum_{j = 0}^N \sigma_j \in \SymbolClass {m_{N + 1}} {\rho, \delta}
        \label{eq:asymptotic_sum_of_symbols}
    \end{align}
    for each $N \in \N$.
    Moreover, $\sigma$ is unique modulo $\SmoothingSymbols$.
\end{proposition}

\begin{definition}[Asymptotic sum]
    With the notation of Proposition~\ref{proposition:asymptotic_sum_of_symbols},
    we shall write
    \begin{align*}
        \sigma \sim \sum_{j = 0}^{+\infty} \sigma_j
    \end{align*}
    when~\eqref{eq:asymptotic_sum_of_symbols} holds for each $N \in \N$.
\end{definition}

\begin{proof}[Proof of Proposition~\ref{proposition:asymptotic_sum_of_symbols}]
    Using Theorem~\ref{theorem:generalized_Littlewood-Paley_decomposition},
    for each $l \in \N$ we can find $C_l \geq 0$ and $N_l \in \N$ such that
    \begin{align*}
        \SymbolSemiNorm {m_0} {\rho, \delta} l {\sigma_j (\Id {\Lebesgue 2 \CompactGroup} - \eta_\epsilon)}
        \leq C_l \SymbolSemiNorm {m_0} {\rho, \delta} {N_l} {\sigma_j}
        \epsilon^{\frac {\max\{m_0 - m_j, 4\}} 2}
    \end{align*}
    for each $0 < \epsilon \leq 1$ and each $j \in \N$.
    Without loss of generality,
    we assume that $N_l \geq l$.

    Choosing a decreasing sequence of sufficiently small $\epsilon_j > 0$, $j \in \N$
    so that the right-hand side of the above satisfies
    \begin{align*}
        C_j \SymbolSemiNorm {m_0} {\rho, \delta} {N_j} {\sigma_j} \epsilon_j^{\frac {\max \{m_0 - m_j, 4\}} 2}
        \leq 2^{-j},
    \end{align*}
    we now obtain that the symbols
    \begin{align*}
        \tilde \sigma_j \defeq \sigma_j (\Id {\Lebesgue 2 \CompactGroup} - \eta_{\epsilon_j})
    \end{align*}
    satisfy the estimate
    \begin{align}
        \SymbolSemiNorm {m_0} {\rho, \delta} j {\tilde \sigma_j}
        \leq 2^{-j}.
        \label{eq:dyadic_decay_in_asymptotic_sum_of_modified_symbols}
    \end{align}

    Fix $l \in \N$.
    we have
    \begin{align}
        \sum_{j = 0}^\infty \SymbolSemiNorm {m_0} {\rho, \delta} l {\tilde \sigma_j}
        &\leq \sum_{j = 0}^l \SymbolSemiNorm {m_0} {\rho, \delta} l {\tilde \sigma_j}
        + \sum_{j = l + 1}^{+\infty} \SymbolSemiNorm {m_0} {\rho, \delta} {j} {\tilde \sigma_j} \notag\\
        &\leq \sum_{j = 0}^l \SymbolSemiNorm {m_0} {\rho, \delta} l {\tilde \sigma_j}
        + \sum_{j = l + 1}^{+\infty} 2^{-j} < + \infty,
        \label{eq:convergence_of_asymptotic_sum_of_modified_symbols}
    \end{align}
    where the last line was obtained by applying~\eqref{eq:dyadic_decay_in_asymptotic_sum_of_modified_symbols}.
    As $\SymbolClass {m_0} {\rho, \delta}$ is a Fr\'echet space,
    it follows from REF that the sum
    \begin{align*}
        \sum_{j = 0}^{+\infty} \tilde \sigma_j
    \end{align*}
    converges to some $\sigma \in \SymbolClass {m_0} {\rho, \delta}$.

    For each $N \in \N$,
    applying~\eqref{eq:convergence_of_asymptotic_sum_of_modified_symbols} to the sequence $\tilde \sigma'_j \defeq \tilde \sigma_{j + N + 1}$,
    we have thus shown that
    \begin{align}
        \sum_{j = N + 1}^{+\infty} \tilde \sigma_j
        \in \SymbolClass {m_{N + 1}} {\rho, \delta}.
        \label{eq:remander_of_asymptotic_sum_of_modified_symbols}
    \end{align}

    Therefore,
    it follows that for each $N \in \N$,
    we have
    \begin{align*}
        \sigma - \sum_{j = 0}^N \sigma_j
        &= \sum_{j = 0}^{+\infty} \sigma_j (\Id {\Lebesgue 2 \CompactGroup} - \eta_{\epsilon_j}) - \sum_{j = 0}^N \sigma_j\\
        &= -\sum_{j = 0}^N \sigma_j \eta_{\epsilon_j} + \sum_{j = N + 1}^{+\infty} \tilde \sigma_j,
    \end{align*}
    which, if combined with~\eqref{eq:remander_of_asymptotic_sum_of_modified_symbols}
    and Theorem~\ref{theorem:generalized_Littlewood-Paley_decomposition},
    means that
    \begin{align*}
        \sigma - \sum_{j = 0}^N \sigma_j
        \in \SymbolClass {m_{N + 1}} {\rho, \delta},
    \end{align*}
    as $\eta_{\epsilon_j} \in \SmoothingSymbols$.
    We have thus shown~\eqref{eq:asymptotic_sum_of_symbols}.

    Let us now check the uniqueness of $\sigma$ modulo $\SmoothingSymbols$.
    To this end,
    assume that $\tau$ also satisfies~\eqref{eq:asymptotic_sum_of_symbols}
    and fix $N \in \N$.
    It is clear that
    \begin{align*}
        \sigma - \tau
        = \left(\sigma - \sum_{j = 0}^N \sigma_j\right) -
        \left(\tau - \sum_{j = 0}^N \sigma_j\right)
        \in \SymbolClass {m_{N + 1}} {\rho, \delta}.
    \end{align*}

    As $N$ is arbitrary
    and $m_{N + 1}$ decreases to $-\infty$ as $N \to +\infty$,
    it follows that $\sigma - \tau \in \SmoothingSymbols$.
\end{proof}

\subsection{Composition formula}

First, we show that $\SmoothingOperators$ is stable under composition.

\begin{lemma}
    Let $\sigma_1, \sigma_2 \in \SmoothingSymbols$
    and denote by $\kappa_1$ and $\kappa_2$ their respective associated kernels.
    We also set
    \begin{align*}
        \kappa_g(h) \defeq \int_\Group \kappa_{2, g l^{-1}}(h l^{-1}) \kappa_{1, g}(l) \dd l
    \end{align*}
    for each $g, h \in \Group$,
    and subsequently define the map
    \begin{align*}
        \sigma(g, \lambda) \defeq \Fourier \kappa_g(\lambda),
        \quad g \in \Group, \lambda \in \VectorSpace.
    \end{align*}

    The map $\sigma$ defined above is a smoothing symbol for which
    \begin{align}
        \sigma(g, \lambda) = \int_\Group \kappa_{1, g}(l) \adj {\Rep \lambda(l)} \sigma_2(g l^{-1}, \lambda) \dd l
        \label{eq:formal_expression_for_the_symbol_obtained_by_composition}
    \end{align}
    holds for all $g \in \Group$ and $\lambda \in \VectorSpace$.
\end{lemma}
\begin{proof}
    % Check it defines a symbol
    It should be clear that $\kappa$ is smooth on $\Group \times \Group$.
    To show that the Fourier transform of $\kappa_g$ is well defined,
    check that $\kappa_g \in \Lebesgue 1 \CompactGroup$.
    Indeed,
    \begin{align*}
        \int_\Group \abs{\kappa_g(h)} \dd h
        &\leq \int_\Group \int_\Group \abs {\kappa_{2, g l^{-1}}(h l^{-1}) \kappa_{1, g}(l)} \dd l \dd h\\
        &\leq \max_{g' \in \Group} \int_\Group \abs {\kappa_{2, g'}(h')} \dd h'
        \int_\Group \abs{\kappa_{1, g}(l)} \dd l
    \end{align*}

    Let us check that $\kappa_g$ is the kernel of $\Op(\sigma_1) \Op(\sigma_2)$.
    Applying the quantization formula twice (Proposition~\ref{proposition:quantization}),
    we obtain
    \begin{align*}
        \Op(\sigma_1) \Op(\sigma_2) \phi(g)
        &= \int_\Group \Op(\sigma_2) \phi(h) \kappa_1(g, h^{-1} g) \dd h\\
        &= \int_\Group \int_\Group \phi(l) \kappa_2(h, l^{-1} h) \kappa_1(g, h^{-1} g) \dd l \dd h.
    \end{align*}

    In the right hand side of the above,
    we can let $m = h^{-1} g$ to obtain
    \begin{align*}
        \Op(\sigma_1) \Op(\sigma_2) \phi(g)
        &= \int_\Group \phi(l) \int_\Group \kappa_2(g m^{-1}, l^{-1} x m^{-1}) \kappa_1(g, m) \dd m \dd l\\
        &= \int_\Group \phi(l) \kappa_g(l^{-1} g) \dd l
        = \conv \phi {\kappa_g}(g),
    \end{align*}
    which means that $\Op(\sigma_1) \Op(\sigma_2) = \Op(\sigma)$.

    From there, let us try to obtain a more explicit formula describing $\sigma$.
    Taking the Fourier Transform,
    we get
    \begin{align*}
        \sigma(g, \lambda)
        &= \int_\Group \kappa_g(h) \adj{\Rep \lambda(h)} \dd h\\
        &= \int_\Group \int_\Group \kappa_2(g m^{-1}, h m^{-1}) \kappa_1(x, m) \adj{\Rep \lambda(m)} \adj{\Rep \lambda(h m^{-1})} \dd h \dd m\\
        &= \int_\Group \kappa_1(g, m) \adj{\Rep \lambda(m)} \sigma_2(g m^{-1}, \lambda) \dd m,
    \end{align*}
    concluding the proof.
\end{proof}

\begin{lemma}
\label{lemma:integrability_of_kernel}
    Let $\sigma \in \SymbolClass m {\rho, \delta}$ with $1 \geq \rho \geq \delta \geq 0$ with $\rho \neq 0$,
    and denote by $\kappa$ its associated kernel.
    If $\gamma \in \R$ satisfies
    \begin{align*}
        \gamma > \max \left\{\frac {m + \dim \Group} \rho, 0\right\} - \dim \Group,
    \end{align*}
    then we can find $C \geq 0$ and $N \in \N$ such that
    \begin{align*}
        \int_\Group \norm [\Group] h^\gamma \abs {\kappa_g(h)} \dd h
        \leq C \SymbolSemiNorm m {\rho, \delta} N \sigma.
    \end{align*}
\end{lemma}
\begin{proof}
    We split the above integral like this
    \begin{align*}
        \int_\Group \dd h
        = \int_{\norm [\Group] h \leq 1} \dd h
        + \int_{\norm [\Group] h \geq 1} \dd h
    \end{align*}

    \begin{description}
        \item [Integral on] $\norm [\Group] h \geq 1$

            By Part~\eqref{item:kernel_estimates:at_infinity} of
            Theorem~\ref{theorem:kernel_estimates},
            for each $M \in \N$ we can find $N \in \N$ such that
            \begin{align*}
                \sup_{\norm [\Group] {h} \geq 1} \abs {\kappa_g(h)}
                \leq C \SymbolSemiNorm m {\rho, \delta} N \sigma \norm [\Group] h^{-M}.
            \end{align*}

            Taking $M$ sufficiently large, it implies that
            \begin{align*}
                \int_{\norm [\Group] h \geq 1} \norm [\Group] h^\gamma \abs {\kappa_g(h)} \dd h
                \leq C \SymbolSemiNorm m {\rho, \delta} N \sigma,
            \end{align*}
            as required.

        \item [Integral on] $\norm [\Group] h \leq 1$

            If $m \geq -\dim \CompactGroup$,
            then by Part~\eqref{item:kernel_estimates:at_origin:positive} of Theorem~\ref{theorem:kernel_estimates} implies
            that if we pick $\tilde \gamma$ satisfying
            \begin{align}
                \begin{cases}
                    \gamma + \dim \Group > \tilde \gamma > \frac {m + \dim \Group} \rho & \text{if } m \geq \dim \Group\\
                    \tilde \gamma = 0 & \text{if } m < -\dim \Group
                \end{cases},
                \label{eq:consequence_of_kernel_estimates:choice_of_tilde_gamma}
            \end{align}
            there exists $N \in \N$ such that
            \begin{align*}
                \sup_{0 < \norm [\Group] h \leq 1} \abs{\kappa_g(h)}
                \leq
                    C \SymbolSemiNorm m {\rho, \delta} N \sigma \norm [\Group] h^{\tilde \gamma}.
            \end{align*}

            From there, it follows that
            \begin{align*}
                \int_{\norm [\Group] h \leq 1} \norm [\Group] h^\gamma \abs {\kappa_g(h)} \dd h \leq
                C \SymbolSemiNorm m {\rho, \delta} N \sigma
                \int_{\norm [\Group] h \leq 1}
                \norm [\Group] h^{\gamma + \tilde \gamma}.
            \end{align*}

            We conclude the proof by observing that ~\eqref{eq:consequence_of_kernel_estimates:choice_of_tilde_gamma}
            implies
            \begin{align*}
                \gamma + \tilde \gamma > -\dim \Group.
            \end{align*}
            which means that the above integral is finite.
    \end{description}
\end{proof}

\begin{lemma}
\label{lemma:prepare_composition_formula}
    Let $m_1, m_2 \in \R$ and suppose $\rho, \delta \in \R$ are chosen such that $1 \geq \rho > \delta \geq 0$.

    Suppose further that $\alpha_0, \beta_0 \in \N^{\dim \Group}$, $N, M \in \N$ are such that
    \begin{align}
        \begin{cases}
            \frac {m_2 + \delta \abs {\beta_{0}}} {1 - \delta} \leq 2 M
            \leq N - \dim \Group - m_1 - \delta \abs {\beta_0} + \rho (\dim \Group)\\
            m_2 + \delta(N + 1 + \abs {\beta_0})
            \leq 2M <
            -\dim \Group - m_1 - \delta \abs {\beta_0} + \rho (\dim \Group + N + 1).
        \end{cases}
        \label{eq:composition_formula:conditions_on_M}
    \end{align}
    There exists $C \geq 0$ and an $P \in \N$ such that
    for any $\sigma_1, \sigma_2 \in \SmoothingSymbols$ and any $(g, \lambda) \in \Group \times \VectorSpace$,
    we have
    \begin{align*}
        &\norm [\Lin {\Lebesgue 2 \CompactGroup}] {%
            \LeftDifferentialOperator [g] \beta \DifferenceOperatorOrder {\alpha_0} \left(
                \sigma_1 \circ \sigma_2(g, \lambda)
                - \sum_{\abs \alpha \leq M} \DifferenceOperatorOrder \alpha \sigma_1(g, \lambda) \TaylorLeftDifferentialOperator \alpha \sigma_2(g, \lambda)
            \right)
        }\\
        &\qquad \leq C \SymbolSemiNorm {m_1, R} {\rho, \delta} P {\sigma_1} \SymbolSemiNorm {m_2} {\rho, \delta} P {\sigma_2}
    \end{align*}
\end{lemma}
\begin{proof}
    For each $N \in \N$,
    let us define
    \begin{align*}
        \tau_N(g, \lambda) \defeq
        \sigma(g, \lambda) - \sum_{\abs \alpha \leq N} \DifferenceOperatorOrder \alpha \sigma_1(g, \lambda) \TaylorLeftDifferentialOperator \alpha \sigma_2(g, \lambda)
    \end{align*}
    We want to estimate
    \begin{align}
        &\tau_N(g, \lambda) \notag\\
        &= \int_\Group \kappa_{1, g}(h) \adj{\Rep \lambda(h)}
        \left(\sigma_2(g h^{-1}, \lambda) - \sum_{\abs \alpha \leq N} q_\alpha(h^{-1}) \TaylorLeftDifferentialOperator \alpha \sigma_2(g, \lambda)\right) \dd h \notag\\
        &= \int_\Group \kappa_{1, g}(h) \adj {\Rep \lambda(h)} \TaylorRemainder {\sigma_2(g \dummy, \lambda)} {e_\Group} N (h^{-1}) \dd h.
        \label{eq:remainder_of_composition_formula}
    \end{align}

    Let $\alpha_0 \in \N^{\dimDifferenceOperators}$ and $\beta_0 \in \N^{\dim \Group}$.
    Applying the Leibniz-like rule for difference operators
    and the Leibniz rule for left-invariant differential operators,
    we obtain
    \begin{align*}
        &\LeftDifferentialOperator {\beta_0} \DifferenceOperatorOrder {\alpha_0} \tau_N(g, \lambda) =\\
        &\sum_{%
            \substack{%
                \abs{\alpha_0} \leq \abs{\alpha_{01}} + \abs{\alpha_{02}} \leq 2 \abs{\alpha_0}\\
                \beta_{01} + \beta_{02} = \beta_0
            }
        }
        \int_\Group q^{\alpha_{01}}(h) \LeftDifferentialOperator [g] {\beta_{01}} \kappa_{1, g}(h) \adj{\Rep \lambda(h)}
        \TaylorRemainder {\LeftDifferentialOperator [g_2 = g] {\beta_{02}} \DifferenceOperatorOrder {\alpha_{02}} \sigma_2(g_2 \dummy, \lambda)} {e_\Group} N (h^{-1}) \dd h.
    \end{align*}

    Now, we would like to introduce powers of $\Rep \lambda \BesselPotentialSquared {}$ near $\sigma_2$,
    which will allow to estimate the above in terms of the symbol semi-norms of $\sigma_2$.
    To this end,
    observe that if $M \in \N$,
    \begin{align*}
        \adj{\Rep \lambda(h)}
        &= \adj{\Rep \lambda(h)} \Rep \lambda \BesselPotentialSquared M \Rep \lambda \BesselPotentialSquared {-M}\\
        &= \lcsum{\abs \beta \leq 2 M} \adj{\Rep \lambda(h)} \Rep \lambda(X)^\beta \Rep \lambda \BesselPotentialSquared {-M},
    \end{align*}
    which, after using $\adj {\Rep \lambda(h)} \Rep \lambda (X)^\beta = (-1)^{\abs \beta} \adj {(\RightDifferentialOperator[h] \beta \Rep \lambda (h))}$, becomes
    \begin{align*}
        \adj{\Rep \lambda(h)}
        &=
        \lcsum{\abs \beta \leq 2 M}
        \adj{(\RightDifferentialOperator \beta \Rep \lambda(h))} \Rep \lambda \BesselPotentialSquared {-M},
    \end{align*}

    Therefore,
    injecting the above into \eqref{eq:remainder_of_composition_formula} and using integration by parts yields
    \begin{align*}
        &\LeftDifferentialOperator {\beta_0} \DifferenceOperatorOrder {\alpha_0} \tau_N(g, \lambda) =\\
        &\quad \lcsum{%
            \substack{%
                \abs{\alpha_0} \leq \abs{\alpha_{01}} + \abs{\alpha_{02}} \leq 2 \abs{\alpha_0}\\
                \beta_{01} + \beta_{02} = \beta_0\\
                \abs {\beta_1} + \abs {\beta_2} \leq 2 M
            }
        }
        \int_\Group \RightDifferentialOperator[h_1 = h] {\beta_1} (\LeftDifferentialOperator [g] {\beta_{01}} q^{\alpha_{01}} \kappa_{1, g})(h_1) \adj {\Rep \lambda(h)}\\
        &\quad \times
        \RightDifferentialOperator[h_2 = h] {\beta_2} \TaylorRemainder {\Rep \lambda \BesselPotentialSquared {-M} \LeftDifferentialOperator [g_2 = g] {\beta_{02}} \DifferenceOperatorOrder {\alpha_{02}} \sigma_2(g_2 \dummy, \lambda)} {e_\Group} N (h_2^{-1}) \dd h,
    \end{align*}
    Now, using REFERENCE, %TODO add reference
    the above becomes
    \begin{align*}
        &\LeftDifferentialOperator {\beta_0} \DifferenceOperatorOrder {\alpha_0} \tau_N(g, \lambda) =\\
        &\quad \lcsum{%
            \substack{%
                \abs{\alpha_0} \leq \abs{\alpha_{01}} + \abs{\alpha_{02}} \leq 2 \abs{\alpha_0}\\
                \beta_{01} + \beta_{02} = \beta_0\\
                \abs {\beta_1} + \abs {\beta_2} \leq 2 M
            }
        }
        \int_\Group \RightDifferentialOperator[h_1 = h] {\beta_1} (\LeftDifferentialOperator [g] {\beta_{01}} q^{\alpha_{01}} \kappa_{1, g})(h_1) \adj {\Rep \lambda(h)}\\
        &\quad \times
        \TaylorRemainder {\Rep \lambda \BesselPotentialSquared {-M} \LeftDifferentialOperator [g_2 = g] {\beta_{02}} \LeftDifferentialOperator {\beta_2} \DifferenceOperatorOrder {\alpha_{02}} \sigma_2(g_2 \dummy, \lambda)} {e_\Group} {N - \abs {\beta_2}} (h_2^{-1}) \dd h.
    \end{align*}

    Therefore,
    if we take the operator norm,
    we obtain
    \begin{align}
        &\norm [\Lin {\Lebesgue 2 \CompactGroup}] {\LeftDifferentialOperator {\beta_0} \DifferenceOperatorOrder {\alpha_0} \tau_n(g, \lambda)} \notag\\
        &\quad \lcsum{%
            \substack{%
                \abs{\alpha_0} \leq \abs{\alpha_{01}} + \abs{\alpha_{02}} \leq 2 \abs{\alpha_0}\\
                \beta_{01} + \beta_{02} = \beta_0\\
                \abs {\beta_1} + \abs {\beta_2} \leq 2 M
            }
        }
        \int_\Group \abs {\RightDifferentialOperator[h_1 = h] {\beta_1} (\LeftDifferentialOperator [g] {\beta_{01}} q^{\alpha_{01}} \kappa_{1, g})(h_1)} \notag\\
        &\quad \times
        \norm [\Lin {\Lebesgue 2 \CompactGroup}] {%
            \TaylorRemainder {\Rep \lambda \BesselPotentialSquared {-M} \LeftDifferentialOperator [g_2 = g] {\beta_{02}} \LeftDifferentialOperator {\beta_2} \DifferenceOperatorOrder {\alpha_{02}} \sigma_2(g_2 \dummy, \lambda)} {e_\Group} {N - \abs {\beta_2}} (h_2^{-1})
        } \dd h.
        \label{eq:composition_formula:main_bound_for_negative_order}
    \end{align}

    Suppose first that $N - \abs {\beta_2} < 0$.
    It follows by Lemma~\ref{lemma:integrability_of_kernel}
    that~\eqref{eq:composition_formula:main_bound_for_negative_order} is bounded by $C \SymbolSemiNorm {m_1, R} {\rho, \delta} {N'} {\sigma_1} \SymbolSemiNorm {m_2} {\rho, \delta} {N'} {\sigma_2}$
    provided that
    \begin{align*}
        \begin{cases}
            m_1 - \rho \abs {\alpha_{01}} + \delta (\abs {\beta_{01}} + \abs {\beta_1}) + \dim \Group < \rho(\dim \Group + \abs {\beta_{02}})\\
            -2 M + \delta(\abs {\beta_{02}} + \abs {\beta_2}) - \rho \abs {\alpha_{02}} \leq - m_2.
        \end{cases}
    \end{align*}

    Using $\abs {\beta_1} \leq 2M - N$,
    it is sufficient that
    \begin{align*}
        \begin{cases}
            m_1 + \delta \abs {\beta_{0}} + 2 M - N + \dim \Group < \rho(\dim \Group)\\
            -2 M + \delta(\abs {\beta_{0}} + 2 M) \leq - m_2,
        \end{cases}
    \end{align*}
    which can be rewritten in one line as
    \begin{align}
        \frac {m_2 + \delta \abs {\beta_{0}}} {1 - \delta} \leq 2 M
        \leq N - \dim \Group - m_1 - \delta \abs {\beta_0} + \rho (\dim \Group).
        \label{eq:composition_formula:first_condition_on_M}
    \end{align}

    Applying the Taylor Remainder Theorem (Proposition~\ref{proposition:Taylor_theorem}),
    we have
    \begin{align*}
        &\norm [\Lin {\Lebesgue 2 \CompactGroup}] {\TaylorRemainder {\Rep \lambda \BesselPotentialSquared {-M} \LeftDifferentialOperator [g_2 = g] {\beta_{02}} \LeftDifferentialOperator {\beta_2} \DifferenceOperatorOrder {\alpha_{02}} \sigma_2(g_2 \dummy, \lambda)} g {N - \abs {\beta_2}} (h^{-1})}\\
        &\ \leq
        \sup_{\abs \gamma \leq N - \abs {\beta_2} + 1}
        \norm [\Group] h^{N - \abs {\beta_2} + 1}
        S(h, M, \gamma, \beta_{02}, \beta_2, \alpha_{02}),
    \end{align*}
    where
    \begin{align*}
        S(h, M, &\gamma, \beta_{02}, \beta_2, \alpha_{02}) \defeq
        \sup_{\norm [\Group] {g_1} \leq \eta \norm [\Group] h}\\
        &\norm [\Lin {\Lebesgue 2 \CompactGroup}] {%
            \Rep \lambda \BesselPotentialSquared {-M}
            \LeftDifferentialOperator [g_1] {\gamma}
            \LeftDifferentialOperator [g_2 = g] {\beta_{02}}
            \LeftDifferentialOperator [g_1] {\beta_2}
            \DifferenceOperatorOrder {\alpha_{02}}
            \sigma_2(g_2 g_1, \lambda)
        }.
    \end{align*}

    Observing that we can replace $\LeftDifferentialOperator [g_2] {\beta_{02}}$ by $\RightDifferentialOperator [g_1] {\beta_{02}}$ in the above,
    Corollary~\ref{corollary:from_right_to_left-invariant_differential_operators},
    \begin{align}
        &S(h, M, \gamma, \beta_{02}, \beta_2, \alpha_{02})
        \leq C \norm [\Group] h^{\abs {\beta_{02}}} \notag\\
        &\ \sum_{\abs {\beta'_{02}} \leq \abs {\beta_{02}}}
        \sup_{g_1 \in \Group}
        \norm [\Lin {\Lebesgue 2 \CompactGroup}] {%
            \Rep \lambda \BesselPotentialSquared {-M}
            \LeftDifferentialOperator [g_1] {\gamma + \beta'_{02} + \beta_2}
            \DifferenceOperatorOrder {\alpha_{02}}
            \sigma_2(g_1, \lambda)
        }.
        \label{eq:composition_formula:bound_on_S}
    \end{align}

    We have thus shown so far that
    \begin{align}
        &\norm [\Lin {\Lebesgue 2 \CompactGroup}] {\sigma(g, \lambda) - \sum_{\abs \alpha \leq N} \DifferenceOperatorOrder \alpha \sigma_1(g, \lambda) \TaylorLeftDifferentialOperator \alpha \sigma_2(g, \lambda)} \notag\\
        &\leq
        \lcsum{\abs {\beta_1} + \abs {\beta_2} \leq 2M}
        \sup_{\abs \gamma \leq N - \abs {\beta_2} + 1}
        S(M, \gamma, \beta_{02}, \beta_2, \alpha_{02}) \notag\\
        &\qquad \qquad
        \int_\Group \abs {\RightDifferentialOperator[h_1 = h] {\beta_1} (\LeftDifferentialOperator [g] {\beta_{01}} q^{\alpha_{01}} \kappa_{1, g})(h_1)} \norm [\Group] h^{N - \abs {\beta_2} + 1} \dd h.
        \label{eq:composition_formula:bound_on_the_remainder}
    \end{align}

    Combining~\eqref{eq:composition_formula:bound_on_S} and~\eqref{eq:composition_formula:bound_on_the_remainder},
    we obtain that
    Lemma~\eqref{lemma:integrability_of_kernel} implies
    that~\eqref{eq:composition_formula:bound_on_the_remainder} is bounded (up to a constant) by $\SymbolSemiNorm {m_1, R} {\rho, \delta} {N'} {\sigma_1} \SymbolSemiNorm {m_2} {\rho, \delta} {N'} {\sigma_2}$ if both
    \begin{align*}
        \begin{cases}
            m_1 - \rho \abs {\alpha_{01}} + \delta \abs {\beta_{01}} + \abs {\beta_1} + \dim \Group < \rho (\dim \Group + N - \abs {\beta_2} + 1 + \abs{\beta_{02}})\\
            -2 M + \delta(\abs \gamma + \abs {\beta'_{02}} + \abs {\beta_2}) - \rho \abs {\alpha_{02}} \leq -m_2.
        \end{cases}
    \end{align*}
    hold.
    For that it suffices that (using $\rho \geq \delta$)
    \begin{align*}
        \begin{cases}
            m_1 + \delta \abs {\beta_{0}} + 2 M + \dim \Group < \rho (\dim \Group + N + 1)\\
            -2M + \delta(N + 1 + \abs {\beta_{0}}) \leq -m_2,
        \end{cases}
    \end{align*}
    which can be rewritten in one line as the following
    \begin{align}
        m_2 + \delta(N + 1 + \abs {\beta_0})
        \leq 2M <
        -\dim \Group - m_1 - \delta \abs {\beta_0} + \rho (\dim \Group + N + 1).
        \label{eq:composition_formula:second_condition_on_M}
    \end{align}
\end{proof}

\begin{proposition}
\label{proposition:composition_formula}
    Assume that $1 \geq \rho > \delta \geq 0$.
    For each $m_1, m_2 \in \R$, and each $N_0, P \in \N$,
    there exists $C > 0$ and $P' \in \N$ such that
    \begin{align*}
        &\SymbolSemiNorm {m_1 + m_2 - N_0 (\rho - \delta), R} {\rho, \delta} P {%
        (\sigma_1 \circ \sigma_2)(g, \lambda)
        - \sum_{\abs \alpha \leq N_0} \DifferenceOperatorOrder \alpha \sigma_1(g, \lambda) \LeftDifferentialOperator \alpha \sigma_2(g, \lambda)
        }\\
        &\qquad \leq C
        \SymbolSemiNorm {m_1, R} {\rho, \delta} {P'} {\sigma_1}
        \SymbolSemiNorm {m_2} {\rho, \delta} {P'} {\sigma_2}
    \end{align*}
    holds for every $\sigma_1, \sigma_2 \in \SmoothingSymbols$.
\end{proposition}
\begin{proof}
    Let $N_0, P \in \N$.
    Consider the symbols
    \begin{align*}
        \tilde \sigma_1(g, \lambda) &\defeq \sigma_1(g, \lambda)\\
        \tilde \sigma_2(g, \lambda) &\defeq \sigma_2(g, \lambda) \Rep \lambda \BesselPotential {-m_1 - m_2 + (\rho - \delta) N_0 + \rho \abs {\alpha_0} - \delta \abs {\beta_0}}\\
    \end{align*}
    which are symbols of order
    \begin{align*}
        \tilde m_1 &\defeq m_1\\
        \tilde m_2 &\defeq -m_1 + (\rho - \delta) N_0 - \delta \abs {\beta_0}
    \end{align*}
    We will apply Lemma~\ref{lemma:prepare_composition_formula} to $\tilde \sigma_1$ and $\tilde \sigma_2$.

    To this end,
    fix $N \in \N$ satisfying $N \geq N_0$ so that the conditions~\eqref{eq:composition_formula:conditions_on_M} make sense.
    More precisely,
    select $N$ so that the difference between the right-hand side and the left-hand side is strictly greater than $2$ for both lines of~\eqref{eq:composition_formula:conditions_on_M},
    and note that this is possible because $\rho > \delta$.
    In particular,
    we can find $M \in \N$ such that~\eqref{eq:composition_formula:conditions_on_M} holds.

    By Lemma~\ref{lemma:prepare_composition_formula},
    it follows that
    \begin{align*}
        &\norm [\Lin {\Lebesgue 2 \CompactGroup}] {%
        \LeftDifferentialOperator [g] {\beta_0}
        \DifferenceOperatorOrder {\alpha_0}
        \left(
                \tilde \sigma_1 \circ \tilde \sigma_2(g, \lambda)
                - \sum_{\abs \alpha \leq N} \tilde \sigma_1(g, \lambda) \LeftDifferentialOperator [g] \alpha \tilde \sigma_2(x, \lambda)
            \right)
        }\\
        &\qquad \leq C \SymbolSemiNorm {\tilde m_1, R} {\rho, \delta} P {\tilde \sigma_1} \SymbolSemiNorm {\tilde m_2} {\rho, \delta} P {\tilde \sigma_2}.
    \end{align*}

    In particular,
    this implies that
    \begin{align*}
        &\norm [\Lin {\Lebesgue 2 \CompactGroup}] {%
        \LeftDifferentialOperator [g] {\beta_0}
        \DifferenceOperatorOrder {\alpha_0}
        \tau_N(g, \lambda)
        \Rep \lambda \BesselPotential {-m_1 - m_2 + (\rho - \delta) N_0 + \rho \abs {\alpha_0} - \delta \abs {\beta_0}}
        }\\
        &\qquad \leq C \SymbolSemiNorm {m_1, R} {\rho, \delta} {P'} {\sigma_1} \SymbolSemiNorm {\tilde m_2} {\rho, \delta} {P'} {\tilde \sigma_2}\\
        &\qquad \leq C \SymbolSemiNorm {m_1, R} {\rho, \delta} {P''} {\sigma_1} \SymbolSemiNorm {m_2} {\rho, \delta} {P''} {\sigma_2},
    \end{align*}
    which can be rewritten as
    \begin{align*}
        \SymbolSemiNorm {m_1 + m_2 - N_0 (\rho - \delta)} {\rho, \delta} P {\tau_N}
        \leq C \SymbolSemiNorm {m_1, R} {\rho, \delta} {P''} {\sigma_1} \SymbolSemiNorm {m_2} {\rho, \delta} {P''} {\sigma_2}.
    \end{align*}

    We conclude by observing that
    \begin{align*}
        \tau_N - \tau_{N_0}
        = \sum_{N_0 < \abs \alpha \leq N}
        \frac 1 {\alpha!}
        \DifferenceOperatorOrder \alpha \sigma_1(g, \lambda)
        \TaylorLeftDifferentialOperator \alpha \sigma_2(g, \lambda)
        \in \SymbolClass {m_1 + m_2 - N_0 (\rho - \delta)} {\rho, \delta},
    \end{align*}
    where the right-hand side is dominated appropriately by the symbol seminorms of $\sigma_1$ and $\sigma_2$.
\end{proof}

\subsection{Adjunction formula}

\begin{lemma}
    Let $\sigma \in \SmoothingSymbols$ and denote by $\kappa$ its associated kernel.
    We let
    \begin{align*}
        \kappa_g^{(*)}(h) \defeq \conj \kappa_{g h^{-1}}(h^{-1}).
    \end{align*}
    Then $\kappa^{(*)}$ is smooth on $\Group \times \Group$ and the map
    \begin{align*}
        g \in \Group \mapsto \kappa_g^{(*)}(\dummy) \in \Schwartz \Group
    \end{align*}
    is smooth.
    Moreover,
    the map
    \begin{align*}
        \sigma^{(*)}(g, \lambda)
        \defeq \Fourier \kappa_g^{(*)}(\lambda),
        \quad (g, \lambda) \in \Group \times \VectorSpace.
    \end{align*}
    defines a smoothing symbol which satisfies
    \begin{align*}
        \adj {\Op(\sigma)}
        = \Op(\sigma^{(*)}).
    \end{align*}
\end{lemma}
\begin{proof}
    Let $\phi, \psi \in \Schwartz \Group$ and fix $g \in \Group$.
    \begin{align*}
        \ip [\Lebesgue 2 \Group] {\Op(\sigma) \phi} \psi
        &= \int_\Group \int_\Group \phi(h) \kappa_g(h^{-1} g) \conj \psi(g) \dd g\\
        &= \int_\Group \int_\Group \phi(h) \conj \kappa^{(*)}_{g (h^{-1} g)^{-1}}((h^{-1} g)^{-1}) \conj \psi(g) \dd g
    \end{align*}
    by definition of $\kappa^{(*)}$.
    Continuing our calculation,
    we get
    \begin{align*}
        \ip [\Lebesgue 2 \Group] {\Op(\sigma) \phi} \psi
        &= \int_\Group \int_\Group \phi(h) \conj{\kappa^{(*)}_{h}(g^{-1} h) \psi(g)} \dd g\\
        &= \int_\Group \phi(h) (\conj {\conv \psi {\kappa^{(*)}_h}})(h) \dd h,
    \end{align*}
    which shows that $\kappa^{(*)}$ is the right-convolution kernel of the adjoint.
\end{proof}

\begin{lemma}
\label{lemma:prepare_adjoint_formula}
    Let $m \in \R$ and
    assume that $1 \geq \rho > \delta \geq 0$.
    For each $\beta_0 \in \N^{\dim \Group}$ and each $M, N \in \N$ satisfying
    \begin{align*}
        (\rho - \delta) (N + 1) + \rho (\dim \Group)
        > m + 2 M + \delta \abs {\beta_0} + \dim \Group,
    \end{align*}
    there exists $C \geq 0$ and $P \in \N$ such that for any $\sigma \in \SmoothingSymbols$,
    \begin{align*}
        &\norm [\Lin {\Lebesgue 2 \Group}] {%
        \LeftDifferentialOperator [g] {\beta_0} (
            \sigma^{(*)}(g,\lambda)
            - \sum_{\abs \alpha \leq N} \DifferenceOperatorOrder \alpha \LeftDifferentialOperator \alpha \adj \sigma(g, \lambda))
            \Rep \lambda \BesselPotential M
        }\\
        &\quad \leq C \SymbolSemiNorm m {\rho, \delta} P \sigma
    \end{align*}
    holds for every $(g, \lambda) \in \Group \times \VectorSpace$.
\end{lemma}
\begin{proof}
    For each $N \in \N$,
    we define
    \begin{align}
        \tau_N(g, \lambda) &\defeq
        \sigma^{(*)}(g, \lambda)
        - \sum_{\abs \alpha \leq N} \DifferenceOperatorOrder \alpha \LeftDifferentialOperator \alpha \adj \sigma(g, \lambda) \notag\\
        &= \int_\Group \TaylorRemainder {\kappa_{g \dummy}^{(*)}(h)} g N (h^{-1}) \adj{\Rep \lambda (h)} \dd h.
        \label{eq:adjunction_formula:Taylor_remainder}
    \end{align}

    Fix $\beta_0 \in \N^{\dim \Group}$.
    Applying $\LeftDifferentialOperator {\beta_0}$ on either side of~\eqref{eq:adjunction_formula:Taylor_remainder},
    we obtain
    \begin{align*}
        \LeftDifferentialOperator {\beta_0} \tau_N (g, \lambda)
        &= \int_\Group \TaylorRemainder {\LeftDifferentialOperator {\beta_0} \kappa_{g \dummy}^{(*)}(h)} g N (h^{-1}) \adj{\Rep \lambda (h)} \dd h.
    \end{align*}

    Multiplying both sides by $\Rep \lambda \BesselPotentialSquared M$,
    and arguing like in Lemma~\ref{lemma:prepare_composition_formula},
    we obtain
    \begin{align*}
        \LeftDifferentialOperator {\beta_0} &\tau_N (g, \lambda) \Rep \lambda \BesselPotentialSquared M\\
        &= \sum_{\abs {\beta_1} + \abs {\beta_2} \leq 2M} \int_\Group \TaylorRemainder {\RightDifferentialOperator [h_2 = h] {\beta_2} \LeftDifferentialOperator [g_1] {\beta_1} \LeftDifferentialOperator [g] {\beta_0} \kappa_{g g_1}^{(*)}(h_2)} {g_1 = e_\Group} {N - \abs {\beta_1}} (h^{-1}) \adj{\Rep \lambda (h)} \dd h.
    \end{align*}

    Taking the operator norm,
    we obtain
    \begin{align*}
        &\norm [\Lin {\Lebesgue 2 \CompactGroup}] {%
            \LeftDifferentialOperator {\beta_0} \tau_N (g, \lambda) \Rep \lambda \BesselPotentialSquared M
        }\\
        &\leq \sum_{\abs {\beta_1} + \abs {\beta_2} \leq 2M} \int_\Group
        \norm [\Lin {\Lebesgue 2 \CompactGroup}] {%
            \TaylorRemainder {\RightDifferentialOperator [h_2 = h] {\beta_2} \LeftDifferentialOperator [g_1] {\beta_1} \LeftDifferentialOperator [g] {\beta_0} \kappa_{g g_1}^{(*)}(h_2)} {g_1 = e_\Group} {N - \abs {\beta_1}} (h^{-1})
        }
        \dd h.
    \end{align*}

    Using Proposition~\ref{proposition:Taylor_theorem},
    we can estimate the remainder via
    \begin{align*}
        &\norm [\Lin {\Lebesgue 2 \CompactGroup}] {%
            \TaylorRemainder {\RightDifferentialOperator [h_2 = h] {\beta_2} \LeftDifferentialOperator [g_1] {\beta_1} \LeftDifferentialOperator [g] {\beta_0} \kappa_{g g_1}^{(*)}(h_2)} {g_1 = e_\Group} {N - \abs {\beta_1}} (h^{-1})
        }\\
        &\leq
        \sum_{\abs \gamma = N - \abs {\beta_1} + 1}
        \norm [\Group] h^{N - \abs {\beta_1} + 1}
        \sup_{\norm [\Group] z \leq \eta \norm [\Group] h}
        \abs {%
            \LeftDifferentialOperator [z] \gamma
            \RightDifferentialOperator [h_2 = h] {\beta_2}
            \LeftDifferentialOperator [z] {\beta_1}
            \LeftDifferentialOperator [g] {\beta_0}
            \kappa^*_{g g_1}(h_2)
        }
    \end{align*}
    Using $\LeftDifferentialOperator [g] {\beta_0} = \RightDifferentialOperator [z] {\beta_0}$
    and passing from left to right-invariant derivatives with Corollary~\ref{corollary:from_right_to_left-invariant_differential_operators},
    \begin{align*}
        &\norm [\Lin {\Lebesgue 2 \CompactGroup}] {%
            \TaylorRemainder {\RightDifferentialOperator [h_2 = h] {\beta_2} \LeftDifferentialOperator [g_1] {\beta_1} \LeftDifferentialOperator [g] {\beta_0} \kappa_{g g_1}^{(*)}(h_2)} {g_1 = e_\Group} {N - \abs {\beta_1}} (h^{-1})
        }\\
        &\leq
        \sum_{\abs \gamma = N - \abs {\beta_1} + 1}
        \norm [\Group] h^{N - \abs {\beta_1} + 1 + \abs {\beta_0}}
        \sup_{\substack {g_1 \in \Group\\ \beta_0' \leq \abs {\beta_0}}}
        \abs {%
        \LeftDifferentialOperator [g_1] {\gamma + \beta_1 + \beta_0'}
            \RightDifferentialOperator [h_2 = h] {\beta_2}
            \kappa^*_{g_1}(h_2)
        },
    \end{align*}
    which is integrable,
    with the integral being bounded by $C \SymbolSemiNorm m {\rho, \delta} P \sigma$
    provided
    \begin{align*}
        m + \abs {\beta_2} + \delta(\gamma + \abs {\beta_1} + \abs {\beta_0'}) + \dim \Group
        <
        \rho (N - \abs {\beta_1} + 1 + \abs {\beta_0} + \dim \Group).
    \end{align*}

    Naturally,
    the above condition is satisfied when
    \begin{align*}
        m + 2 M + \delta(N + 1 + \abs {\beta_0}) + \dim \Group
        <
        \rho (N + 1 + \dim \Group)
    \end{align*}
    which can be rewritten
    \begin{align*}
        (\rho - \delta) (N + 1) + \rho (\dim \Group)
        > m + 2 M + \delta \abs {\beta_0} + \dim \Group.
    \end{align*}
\end{proof}

\begin{proposition}
\label{proposition:adjoint_formula}
    Assume that $1 \geq \rho > \delta \geq 0$.
    For each $m \in \R$ and each $P, N_0 \in \N$,
    there exists $C \geq 0$ and $P' \in \N$ such that
    \begin{align*}
        \SymbolSemiNorm {m - N_0 (\rho - \delta), R} {\rho, \delta} P {%
        \sigma^{(*)}(g, \lambda)
        - \sum_{\abs \alpha \leq N_0} \frac 1 {\alpha!} \DifferenceOperatorOrder \alpha \TaylorLeftDifferentialOperator \alpha \adj \sigma(g, \lambda)
        } \leq
        C
        \SymbolSemiNorm m {\rho, \delta} {P'} \sigma
    \end{align*}
    holds for each $\sigma \in \SmoothingSymbols$.
\end{proposition}
\begin{proof}
    Let $N_0 \in \N$, $\beta_0 \in \N^{\dim \Group}$ and $\alpha_0 \in \N^{\dimDifferenceOperators}$.
    For each $N \in \N$,
    we write
    \begin{align*}
        \tau_N(g, \lambda) \defeq
        \sigma^{(*)}(g, \lambda)
        - \sum_{\abs \alpha \leq N} \frac 1 {\alpha!} \DifferenceOperatorOrder \alpha \TaylorLeftDifferentialOperator \alpha \adj \sigma(g, \lambda).
    \end{align*}

    We shall apply Lemma~\ref{lemma:prepare_adjoint_formula} to the symbol
    \begin{align*}
        \tilde \sigma(g, \lambda)
        = \sigma(g, \lambda)
        \Rep \lambda \BesselPotential {-m + (\rho - \delta) N_0 + \rho \abs {\alpha_0} - \delta \abs {\beta_0}}
    \end{align*}
    which is of order $\tilde m \defeq (\rho - \delta) N_0 + \rho \abs {\alpha_0} - \delta \abs {\beta_0}$.
    Let $M \in \N$ be the smallest natural number such that
    \begin{align*}
        \frac {-\tilde m + (\rho - \delta) N_0 + \delta \abs {\beta_0}} 2 \geq M.
    \end{align*}

    We now choose $N \geq \max \{N_0, 2M\}$ such that
    \begin{align*}
        (\rho - \delta) (N + 1) + \rho (\dim \Group)
        > \tilde m + 2 M + \delta \abs {\beta_0} + \dim \Group,
    \end{align*}
    since it is possible by $\rho > \delta$.
    By Lemma~\ref{lemma:prepare_adjoint_formula},
    we obtain that
    \begin{align*}
        &\norm [\Lin {\Lebesgue 2 \Group}] {%
        \LeftDifferentialOperator [g] {\beta_0}
            \tau_N(g, \lambda)
            \Rep \lambda \BesselPotential {-m + (\rho - \delta) N_0 + \rho \abs {\alpha_0} - \delta \abs {\beta_0}}
        }\\
        &\quad \leq C \SymbolSemiNorm {\tilde m} {\rho, \delta} P {\tilde \sigma}
        = C \SymbolSemiNorm m {\rho, \delta} P \sigma,
    \end{align*}
    concluding our proof.
\end{proof}

\subsection{Simplification of symbol classes definition}

We shall see in this subsection that it is possible to considerably simplify our definition of symbol classes (Definition~\ref{definition:symbol_classes})
by writing it ``without $\gamma$'',
i.e.\ by considering the action of powers of $\Rep \lambda \BesselPotential 1$
only on the right (resp. only on the left) of $\sigma$.

This will allow us to conclude the proof that our collection of operators $\OperatorClass m {\rho, \delta}$, $m \in \R$ does behave well under composition and adjunction.

\begin{theorem}
    Assume that $1 \geq \rho > \delta \geq 0$ and fix $m \in \R$.
    A symbol $\sigma$ is in $\SymbolClass m {\rho, \delta}$ if and only if
    \begin{align*}
        \sup_{g \in \Group} \esssup_{\lambda \in \VectorSpace}
        \norm [\Lin {\Lebesgue 2 \CompactGroup}] {%
            \LeftDifferentialOperator \beta
            \DifferenceOperatorOrder \alpha
            \sigma(g, \lambda)
            \Rep \lambda \BesselPotential {-m + \rho \abs \alpha - \delta \abs \beta}
        } < \infty.
    \end{align*}

    Moreover,
    the semi-norms
    \begin{align*}
        &\sigma \in \SymbolClass m {\rho, \delta} \mapsto \SymbolSemiNorm m {\rho, \delta} N \sigma\\
        &\sigma \in \SymbolClass {m} {\rho, \delta} \mapsto \SymbolSemiNorm {m, R} {\rho, \delta} N \sigma
    \end{align*}
    yield the same topology on $\SymbolClass m {\rho, \delta}$.
\end{theorem}
\begin{proof}
    Let $N \in \N$ and $\sigma \in \SmoothingSymbols$.

    It is clear by definition of $\SymbolClass m {\rho, \delta}$-topology
    that there exists $c_N \geq 0$ such that
    \begin{align}
        \SymbolSemiNorm m {\rho, \delta} {N} \sigma
        \leq \max_{\abs \gamma \leq c_{N}} \SymbolSemiNorm {m + \gamma, R} {\rho, \delta} {N'} {\Rep \lambda \BesselPotential \gamma \sigma}.
        \label{eq:equivalence_of_symbol_classes_definitions:crude_inequality}
    \end{align}

    By Proposition~\ref{proposition:composition_formula} and Corollary~\ref{corollary:powers_of_the_Laplacian},
    we know that
    \begin{align*}
        \sup_{\abs \gamma \leq c_N} \SymbolSemiNorm {m + \gamma, R} {\rho, \delta} N {\Rep \lambda \BesselPotential \gamma \sigma}
    \end{align*}
    is finite.

    Since taking the adjoint is continuous in the $\SymbolClass {m, R} {\rho, \delta}$-topology (Proposition~\ref{proposition:adjoint_formula}),
    we have
    \begin{align*}
        \SymbolSemiNorm {m + \gamma, R} {\rho, \delta} N {\Rep \lambda \BesselPotential \gamma \sigma}
        &\leq C
        \SymbolSemiNorm {m + \gamma, R} {\rho, \delta} {N'} {\adj \sigma \Rep \lambda \BesselPotential \gamma}\\
        &\leq C
        \SymbolSemiNorm {m, R} {\rho, \delta} {N''} {\adj \sigma}
        = C \SymbolSemiNorm {m, R} {\rho, \delta} {N'''} {\sigma},
    \end{align*}
    which,
    if combined with~\eqref{eq:equivalence_of_symbol_classes_definitions:crude_inequality},
    yields that for every $N \in \N$,
    there exists $N' \in \N$ such that
    \begin{align*}
        \SymbolSemiNorm m {\rho, \delta} {N} \sigma
        \leq C \SymbolSemiNorm {m, R} {\rho, \delta} {N'} {\sigma}.
    \end{align*}

    Since it is very clear that
    \begin{align*}
        \SymbolSemiNorm {m, R} {\rho, \delta} {N} {\sigma}
        \leq \SymbolSemiNorm m {\rho, \delta} {N} \sigma,
    \end{align*}
    It follows that the seminorms $\SymbolSemiNorm {m, R} {\rho, \delta} N \dummy, N \in \N$ define the same topology as $\SymbolSemiNorm m {\rho, \delta} N \dummy, N \in \N$.
    As $\SymbolClass m {\rho, \delta}$ is the completion of $\SmoothingSymbols$ with respect to the family $\SymbolSemiNorm m {\rho, \delta} N \dummy$, $N \in \N$ of seminorms,
    the conclusion follows easily.
\end{proof}

Naturally,
the following statement holds with an identical proof.

\begin{theorem}
    Assume that $1 \geq \rho > \delta \geq 0$ and fix $m \in \R$.
    A symbol $\sigma$ is in $\SymbolClass m {\rho, \delta}$ if and only if
    \begin{align*}
        \sup_{g \in \Group} \esssup_{\lambda \in \VectorSpace}
        \norm [\Lin {\Lebesgue 2 \CompactGroup}] {%
            \Rep \lambda \BesselPotential {-m + \rho \abs \alpha - \delta \abs \beta}
            \LeftDifferentialOperator \beta
            \DifferenceOperatorOrder \alpha
            \sigma(g, \lambda)
        } < \infty.
    \end{align*}

    Moreover,
    the semi-norms
    \begin{align*}
        &\sigma \in \SymbolClass m {\rho, \delta} \mapsto \SymbolSemiNorm m {\rho, \delta} N \sigma\\
        &\sigma \in \SymbolClass {m} {\rho, \delta} \mapsto \SymbolSemiNorm {m, L} {\rho, \delta} N \sigma
    \end{align*}
    yield the same topology on $\SymbolClass m {\rho, \delta}$.
\end{theorem}

\subsection{Pseudo-differential calculus}

Exactly like in~\cite{FischerRuzhansky16},
we can now use Theorem~\ref{theorem:generalized_Littlewood-Paley_decomposition} to extend
Propositions~\ref{proposition:composition_formula} and~\ref{proposition:adjoint_formula}
to our symbol classes.

\begin{theorem}[Composition formula]
\label{theorem:composition_formula}
    Assume that $1 \geq \rho > \delta \geq 0$.
    Given $m_1, m_2 \in \R$,
    we let
    $\sigma_1 \in \SymbolClass {m_1} {\rho, \delta}$,
    $\sigma_2 \in \SymbolClass {m_2} {\rho, \delta}$.

    There exists $\sigma \in \SymbolClass {m_1 + m_2} {\rho, \delta}$ such that
    \begin{align*}
        \Op (\sigma) = \Op(\sigma_1) \circ \Op(\sigma_2)
    \end{align*}
    Moreover,
    $\sigma$ is given modulo $\SmoothingSymbols$ by the asymptotic sum
    \begin{align*}
        \sigma \sim
        \sum_{\alpha \in \N^{\dimDifferenceOperators}} \DifferenceOperatorOrder \alpha \sigma_1 \ \TaylorLeftDifferentialOperator \alpha \sigma_2.
    \end{align*}
    More precisely,
    we have
    \begin{align*}
        \sigma
        - \sum_{\abs \alpha \leq N} \DifferenceOperatorOrder \alpha \sigma_1 \ \TaylorLeftDifferentialOperator \alpha \sigma_2 \in \SymbolClass {m - (\rho - \delta) N} {\rho, \delta}
    \end{align*}
    for each $N \in \N$.
\end{theorem}

\begin{theorem}[Adjunction formula]
\label{theorem:adjunction_formula}
    Assume that $1 \geq \rho > \delta \geq 0$.
    Let
    $\sigma \in \SymbolClass m {\rho, \delta}$ for some $m \in \R$

    There exists $\tilde \sigma \in \SymbolClass m {\rho, \delta}$ such that
    \begin{align*}
        \Op (\tilde \sigma) = \adj {\Op(\sigma)}
    \end{align*}
    Moreover,
    $\tilde \sigma$ is given modulo $\SmoothingSymbols$ by the asymptotic sum
    \begin{align*}
        \tilde \sigma \sim
        \sum_{\alpha \in \N^{\dimDifferenceOperators}} \frac 1 {\alpha!} \DifferenceOperatorOrder \alpha \TaylorLeftDifferentialOperator \alpha \sigma.
    \end{align*}
    More precisely,
    we have
    \begin{align*}
        \tilde \sigma
        - \sum_{\abs \alpha \leq N} \frac 1 {\alpha!} \DifferenceOperatorOrder \alpha \TaylorLeftDifferentialOperator \alpha \sigma \in \SymbolClass {m - (\rho - \delta) N} {\rho, \delta}
    \end{align*}
    for each $N \in \N$.
\end{theorem}

\section{\texorpdfstring{$L^p$}{Lp} boundedness}

\subsection{\texorpdfstring{$L^2$}{L2} boundedness}

% TODO: Place this proposition
\begin{proposition}
    Let $\sigma \in \SymbolClass m {\rho, \delta}$,
    where $m < -\dim \Group / 2$ and $\rho, \delta \in [0, 1]$.
    The operator associated with $\sigma$, $\Op(\sigma)$, has a continuous extension
    \begin{align*}
        \Op(\sigma) : \Lebesgue 2 \Group \to \Lebesgue 2 \Group.
    \end{align*}
    Moreover,
    \begin{align*}
        \norm [\Lin {\Lebesgue 2 \Group}] {\Op(\sigma)}
        \leq C \SymbolSemiNorm m {\rho, \delta} N \sigma.
    \end{align*}
\end{proposition}
\begin{proof}
    First, let us observe that for each $g_0 \in \Group$, we have
    \begin{align*}
        \sup_{g \in \Group} \abs {T f(g_0 g)}
        &\leq \int_\Group \abs{f(g_0 g h^{-1}) \kappa_{g_0 g}(h)} \dd h\\
        &\leq \norm [\Lebesgue 2 \Group] {(1 + \norm [\Group] \dummy^2)^{-N} f(g_0 \dummy)} \norm [\Lebesgue 2 \Group] {(1 + \norm [\Group] \dummy^2)^N \kappa_{g_0 g}},
    \end{align*}
    where the last line was obtained by the Cauchy-Schwartz inequality.

    Integrating the above with respect to $g$ over $\Ball [\Group] {g_0} 1$,
    we obtain
    \begin{align}
        \int_{\Ball [\Group] {g_0} 1} \abs {T f(g)}^2 \dd g
        &= \int_{\Ball [\Group] e 1} \abs {T f(g_0 g)}^2 \dd g\notag\\
        &\leq C \SymbolSemiNorm m {\rho, \sigma} ? \sigma^2
        \norm [\Lebesgue 2 \Group] {(1 + \norm [\Group] \dummy^2)^{-N} f(g_0 \dummy)}^2.
        \label{eq:integral_of_Tf_on_ball_of_radius_1}
    \end{align}

    To conclude the proof,
    we shall integrate each side of the above with respect to $g_0 \in \Group$.

    For the left-hand side,
    a simple application of the Fubini-Tonnelli Theorem yields
    \begin{align*}
        \int_\Group \int_{\Ball [\Group] {g_0} 1} \abs {T f(g)}^2 \dd g \dd g_0
        &= \int_\Group \int_\Group 1_{\norm [\Group] {g_0^{-1} g} \leq 1} \abs {T f(g)}^2 \dd g_0 \dd g\\
        &= \int_\Group \int_\Group 1_{\norm [\Group] {g_0^{-1} g} \leq 1} \abs {T f(g)}^2 \dd g_0 \dd g,
    \end{align*}
    so that the change of variable $h = g_0^{-1} g$ yields
    \begin{align}
        \int_\Group \int_{\Ball [\Group] {g_0} 1} \abs {T f(g)}^2 \dd g \dd g_0
        = C \norm [\Lebesgue 2 \Group] {T f}^2.
        \label{eq:left_hand_side_of_ball_integral_for_L2_boundedness}
    \end{align}

    Now, integrating the right-hand side of~\eqref{eq:integral_of_Tf_on_ball_of_radius_1},
    we obtain
    \begin{align*}
        \int_\Group &\norm [\Lebesgue 2 \Group] {(1 + \norm [\Group] \dummy^2)^{-N} f(g_0 \dummy)}^2 \dd g_0\\
        &\quad = \int_\Group \int_\Group \abs{(1 + \norm [\Group] g^2)^{-N} f(g_0 g)}^2 \dd g \dd g_0\\
        &\quad = \norm [\Lebesgue 2 \Group] f^2 \int_\Group (1 + \norm [\Group] g^2)^{-2 N} \dd g.
    \end{align*}

    Choosing $N$ sufficiently large,
    we therefore get that
    \begin{align}
        \int_\Group &\norm [\Lebesgue 2 \Group] {(1 + \norm [\Group] \dummy^2)^{-N} f(g_0 \dummy)}^2 \dd g_0
        \leq C \norm [\Lebesgue 2 \Group] f^2
        \label{eq:right_hand_side_of_ball_integral_for_L2_boundedness}
    \end{align}

    Therefore,
    using~\eqref{eq:right_hand_side_of_ball_integral_for_L2_boundedness}
    and~\eqref{eq:left_hand_side_of_ball_integral_for_L2_boundedness}
    in~\eqref{eq:integral_of_Tf_on_ball_of_radius_1},
    we obtain
    \begin{align*}
        \norm [\Lebesgue 2 \Group] {T f}^2
        &\leq C \SymbolSemiNorm m {\rho, \sigma} ? \sigma^2
        \norm [\Lebesgue 2 \Group] {(1 + \norm [\Group] \dummy^2)^{-N} f(g_0 \dummy)}^2,
    \end{align*}
    which concludes the proof.
\end{proof}

The aim of this subsection is to prove
that symbols of order $0$ induce bounded operators in $\Lebesgue 2 \Group$
when $\rho > \delta$.

These results would naturally generalize to symbols of order $m$ as follows:
if $\sigma \in \SymbolClass m {\rho, \delta}$,
where $\rho, \delta$ satisfy either of the conditions above,
then $\Op(\sigma)$ extends continuously to a continuous operator
\begin{align*}
    \Op(\sigma) : \Sobolev s \to \Sobolev {s - m}
\end{align*}
for every $s \in \R$.

Suppose that $\sigma_T \in \SymbolClass 0 {\rho, \delta}$ for $0 \leq \delta < \rho \leq 1$.
One way of showing that $T \defeq \Op(\sigma_T)$ is bounded would be to find $S \in \OperatorClass 0 {\rho, \delta}$ such that
\begin{align}
    \adj T T = C \Id {\Schwartz \Group} - \adj S S + R,
    \label{eq:L2_boundedness_decomposition}
\end{align}
where $R \in \OperatorClass m {\rho, \delta}$ for some $m < 0$.

It would then follow that
\begin{align*}
    \norm [\Lebesgue 2 \Group] {T \phi}^2
    &= \ip [\Lebesgue 2 \Group] {\adj T T \phi} \phi\\
    &= C \norm [\Lebesgue 2 \Group] {\phi}^2 - \norm [\Lebesgue 2 \Group] {S \phi}^2 + \ip [\Lebesgue 2 \Group] {R \phi} \phi\\
    &\leq C \norm [\Lebesgue 2 \Group] {\phi}^2 + \norm [\Lebesgue 2 \Group] {R \phi} \norm [\Lebesgue 2 \Group] \phi,
\end{align*}
reducing the boundedness of $T$ to that of $R$,
which is much easier to prove.

A sufficient condition to have \eqref{eq:L2_boundedness_decomposition} would be to have
\begin{align*}
    \adj {\sigma_T} \sigma_T = C \Id {\Lebesgue 2 \CompactGroup} - \adj {\sigma_S} \sigma_S,
\end{align*}
on the symbol side,
with $\sigma_S \defeq \Op^{-1}(S)$.
A good candidate for $\sigma_S$ would therefore be
\begin{align}
    \sigma_S \defeq \sqrt{C \Id {\Lebesgue 2 \CompactGroup} - \adj {\sigma_T} \sigma_T}.
    \label{eq:symbol_to_prove_L2_boundedness}
\end{align}

The condition that $S \in \OperatorClass 0 {\rho, \delta}$ is equivalent to showing
that $\sigma_S \in \SymbolClass 0 {\rho, \delta}$.
The crucial part of the proof is therefore to show that~\eqref{eq:symbol_to_prove_L2_boundedness} is a symbol of order $0$.

\begin{lemma}
\label{lemma:square_root_of_a_symbol_of_order_zero}
    Let $\rho, \delta \in \R$ be such that $1 \geq \rho > \delta \geq 0$.
    If $\sigma \in \SymbolClass 0 {\rho, \delta}$ is \emph{positive definite},
    invertible,
    and its inverse satisfies
    \begin{align*}
        \sup_{g \in \Group} \esssup_{\lambda \in \VectorSpace} \norm [\Lin {\Lebesgue 2 \Group}] {\sigma(g, \lambda)^{-1}} < \infty.
    \end{align*}
    then its \emph{square root}
    \begin{align*}
        (x, k; \lambda) \in \Group \times \VectorSpace \mapsto \sqrt{\sigma(x, k; \lambda)}
    \end{align*}
    also belongs to $\SymbolClass 0 {\rho, \delta}$.
\end{lemma}
\begin{proof}
    It is clear that the spectrum of $\sigma$ is contained in $[c, c^{-1}] \subset \R$ for some $c > 0$.
    Therefore, for each $z \in \R^{-}$,
    \begin{align*}
        \norm [\Lin {\Lebesgue 2 \CompactGroup}] {(\sigma(g, \lambda) - z \Id {\Lebesgue 2 \CompactGroup})^{-1}}
        \leq (c + \abs z)^{-1}
        \leq C(1 + \abs z)^{-1}.
    \end{align*}

    By the composition formula,
    it follows that for each $\gamma \in \R$,
    \begin{align*}
        &\norm [\Lin {\Lebesgue 2 \CompactGroup}] {
            \Rep \lambda \BesselPotential \gamma
            (\sigma(g, \lambda) - z \Id {\Lebesgue 2 \CompactGroup})^{-1}
            \Rep \lambda \BesselPotential {-\gamma}
        }\\
        &\qquad \leq C(1 + \abs z)^{-1}
    \end{align*}
    which means that $\sigma$ is parameter-elliptic with order $0$.

    Since $\sigma$ is parameter-elliptic with respect to $\R^-$,
    we can apply Theorem~\ref{theorem:functional_calculus} with $F = z^{-\frac 1 2}$,
    which yields that $F(\sigma) \in \SymbolClass {0} {\rho, \delta}$.
    By the calculus,
    we conclude that
    \begin{align*}
        \sqrt \sigma = F(\sigma) \sigma \in \SymbolClass 0 {\rho, \delta}.
    \end{align*}
\end{proof}

\begin{proposition}[$L^2$ boundedness]
\label{proposition:L2_boundedness}
    Let $\rho, \delta \in \R$ be such that $1 \geq \rho > \delta \geq 0$.
    If $\sigma \in \SymbolClass 0 {\rho, \delta}$,
    then its associated operator $T \defeq \Op(\sigma)$ is bounded in $\Lebesgue 2 \Group$,
    i.e.\ we have
    \begin{align*}
        \norm [\Lebesgue 2 \Group] {T \phi} \leq C \norm [\Lebesgue 2 \Group] \phi.
    \end{align*}
    for every $\phi \in \Schwartz \Group$.
\end{proposition}
\begin{proof}
    \begin{description}
        \item[Step 1.] If $\sigma \in \SymbolClass m {\rho, \delta}$ for $m < -1$, then
            \begin{align*}
                \norm [\Lin{\Lebesgue 2 \Group}] {\Op(\sigma)} < \infty.
            \end{align*}
        \item[Step 2.] If $\sigma \in \SymbolClass m {\rho, \delta}$ for $m < 0$, then
            \begin{align*}
                \norm [\Lin{\Lebesgue 2 \Group}] {\Op(\sigma)} < \infty.
            \end{align*}

            Suppose by contradiction that the claim does not hold.
            Therefore, there exists $m < 0$ and $\sigma \in \SymbolClass m {\rho, \delta}$ such that
            $\Op(\sigma)$ is not bounded.
            In particular, for each $n \in \N$,
            \begin{align*}
                (\Op(\sigma) \adj {\Op(\sigma)})^n
            \end{align*}
            is in $\OperatorClass {2 m n} {\rho, \delta}$ and unbounded.
            When $n$ is such that $-2 m n < -1$, this contradicts Step 1.
        \item[Step 3.] Conclusion

            Let $C \geq 0$ be such that
            \begin{align*}
                \sup_{(x, k) \in \Group} \esssup_{\lambda \in \VectorSpace} \norm [\Lebesgue 2 \CompactGroup] {\sigma(x, k; \lambda)} \leq C.
            \end{align*}

            It follows that
            \begin{align*}
                4 C^2 \Id {\Lebesgue 2 \CompactGroup} - \adj \sigma \sigma
            \end{align*}
            is an operator of order $0$,
            and so by Lemma~\ref{lemma:square_root_of_a_symbol_of_order_zero}, the symbol
            \begin{align*}
                \sigma_S \defeq \sqrt{4 C^2 \Id {\Lebesgue 2 \CompactGroup} - \adj \sigma \sigma}
            \end{align*}
            is also in $\SymbolClass 0 {\rho, \delta}$.
            By definition, we have
            \begin{align}
                \adj \sigma \sigma = 4 C^2 \Id {\Lebesgue 2 \CompactGroup} - \adj {\sigma_S} \sigma_S.
                \label{eq:decomposition_of_unity_in_terms_of_symbols_squared}
            \end{align}

            By the adjoint and composition formulas,
            we have
            \begin{align*}
                \Op(\adj \sigma \sigma) = \adj T T + R_1\\
                \Op(\adj {\sigma_S} \sigma_S) = \adj S S +  R_2,
            \end{align*}
            with $R_1, R_2 \in \OperatorClass {\rho - \delta} {\rho, \delta}$.
            Therefore, applying $\Op$ on both sides of~\eqref{eq:decomposition_of_unity_in_terms_of_symbols_squared} yields
            \begin{align*}
                \adj T T = 4 C^2 \Id {\Schwartz \Group} - \adj S S + R,
                \quad R \defeq (R_2 - R_1) \in \OperatorClass {\rho - \delta} {\rho, \delta}.
            \end{align*}

            Now, fix $\phi \in \Lebesgue 2 \Group$.
            Since Step 2 implies that $R$ is bounded,
            we get
            \begin{align*}
                \norm [\Lebesgue 2 \Group] {T \phi}^2
                &= \ip [\Lebesgue 2 \Group] {\adj T T \phi} \phi\\
                &= 4 C^2 \norm [\Lebesgue 2 \Group] \phi^2 - \norm [\Lebesgue 2 \Group] {S \phi}^2 + \ip [\Lebesgue 2 \Group] {R \phi} {\phi}\\
                &\leq (4 C^2 + \norm [\Lin {\Lebesgue 2 \Group}] R) \norm [\Lebesgue 2 \Group] \phi^2,
            \end{align*}
            concluding the proof.
    \end{description}
\end{proof}

\begin{theorem}[Boundedness on Sobolev spaces]
\label{theorem:L2_boundedness}
    Let $\rho, \delta \in \R$ be such that $1 \geq \rho > \delta \geq 0$.
    If $\sigma \in \SymbolClass m {\rho, \delta}$,
    then its associated operator $T \defeq \Op(\sigma)$ extends to a bounded map
    between $\Sobolev s$ and $\Sobolev {s - m}$,
    i.e.\ there exists $C \geq 0$ such that
    \begin{align*}
        \norm [\Sobolev {s - m}] {T \phi} \leq C \norm [\Sobolev s] \phi.
    \end{align*}
    for every $\phi \in \Schwartz \Group$.
\end{theorem}

\subsubsection{Kernel estimates when \texorpdfstring{\rho = 1}{rho = 1}}
\label{subsubsection:kernel_estimates_revisited}

In order to show $\Lebesgue p \Group$,
we need to improve the estimates in Theorem~\ref{theorem:kernel_estimates} when $\rho = 1$.

The following lemma is obtained by very simple modification of~\cite[Lemma A.6]{Fischer2015},
which relies mainly on classical heat kernel estimates valid for Lie group with polynomial growth of the volume,
and are thus valid on the motion group.

The arguments in~\cite[Lemma A.6]{Fischer2015} are themselves based on~\cite{FurioliMelziVeneruso06, VaropoulosSaloffCosteCoulhon92}.

\begin{lemma}
\label{lemma:technical_lemma}
    Let $f \in \SmoothFunctions {\R^+}$ be such that $f$ vanishes outside of $[C^{-1}, C]$ for some $C > 1$.
    For each $\alpha \in \N^{\dimDifferenceOperators}$ and each $m \in \R$,
    we have
    \begin{align*}
        \norm [\Lebesgue 2 \Group] {
        \LeftDifferentialOperator \beta \{q^\alpha f(t \Laplacian) \delta_{e_\Group}\}
        }
        \leq C \sqrt t^{\abs \alpha - \abs \beta - \frac {\dim \Group} 2}.
    \end{align*}
\end{lemma}

From there, we can deduce the following corollary.

\begin{corollary}
    Let $f \in \SmoothFunctions {\R^+}$ be such that $f$ vanishes outside of $[C^{-1}, C]$ for some $C > 1$.
    For each $\alpha \in \N^{\dimDifferenceOperators}$ and each $m \in \R$,
    we have
    \begin{align*}
        \norm [\Sobolev m] {
            q^\alpha f(t \Laplacian) \delta_{e_\Group}
        }
        \leq C \sqrt t^{\abs \alpha - m - \frac {\dim \Group} 2}.
    \end{align*}
\end{corollary}
\begin{proof}
    Clearly, the result is true when $m \in 2\N$ by Lemma~\ref{lemma:technical_lemma}.
    The result on $\R^+$ can easily be deduced by interpolation.

    Suppose that $n \in \N$.
    We let
    \begin{align*}
        f_1(\mu) \defeq
        \begin{cases}
            \frac {f(\mu)}{\mu^n} & \text{if } \mu \neq 0\\
            0 & \text{otherwise},
        \end{cases}
        \quad \mu \in \R^+.
    \end{align*}

    Suppose now $m < 0$ and pick $n \in \N$
    so that $2n - \abs \alpha + m \geq 0$.
    Clearly,
    \begin{align*}
        \norm [\Sobolev m] {
            q^\alpha f(t \Laplacian) \delta_{e_\Group}
        }
        =
        t^n 
        \norm [\Sobolev m] {
            q^\alpha (\Laplacian^n f_1(t \Laplacian) \delta_{e_\Group})
        }
    \end{align*}

    Applying the Leibniz rule, we obtain that the right-hand side is bounded by
    \begin{align*}
        &C \sum_{(\alpha_1, \alpha_2) \in A}
        t^n
        \norm [\Lin {\Sobolev {2 n - \abs {\alpha_1} + m}, \Sobolev m}] {
            q^{\alpha_1}
            \Laplacian^n
        }
        \norm [\Sobolev {2 n - \abs {\alpha_1} + m}] {
            q^{\alpha_2} (f_1(t \Laplacian) \delta_{e_\Group})
        }\\
        &\leq C
        \sum_{(\alpha_1, \alpha_2) \in A}
        t^n t^{\frac {\abs {\alpha_2} - 2 n + \abs {\alpha_1} - m - \dim \Group/2} 2}
        = C \sqrt t^{\abs \alpha - m - \frac {\dim \Group} 2}
    \end{align*}
    where in the above
    $A \defeq \{(\alpha_1, \alpha_2) \abs \alpha \leq \abs {\alpha_1} + \abs {\alpha_2} \leq 2 \abs \alpha\}$.

    This concludes the proof.
\end{proof}

\begin{theorem}[Kernel estimates when $\rho = 1$]
    Let $\sigma \in \SymbolClass m {1, \delta}$.
    If $m > -\dim \Group$,
    then its associated kernel $\kappa$ satisfies
    \begin{align*}
        \abs {\kappa_g(h)}
        \leq C \norm [\Group] h^{-m - \dim \Group}
    \end{align*}
    for every $h \in \Group \setminus \{e_\Group\}$.
\end{theorem}

\subsection{Calder\'on-Zygmund theory}

\begin{definition}[Calder\'on-Zygmund kernel]
    We shall say that a measurable map
    \begin{align*}
        \kappa : (\Group \times \Group) \setminus \{(g, g) : g \in \Group\} \to \C
    \end{align*}
    is a \emph{Calder\'on-Zygmund kernel}
    if there exists $\gamma \in (0, 1]$,
    $C \geq 0$ and $A \geq 0$ such that the estimates
    \begin{align*}
        \abs {\kappa(g, h)} &\leq A \norm [\Group] {h^{-1} g}^{-\dim \Group} &\\
        \abs {\kappa(g, h) - \kappa(g', h)} &\leq A \frac {\norm [\Group] {g^{-1} g'}^{\gamma}} {\norm [\Group] {h^{-1} g}^{\dim \Group + \gamma}}
        &\text{ if } \norm [\Group] {g^{-1} g'} \leq \frac {\norm [\Group] {h^{-1} g}} 2\\
        \abs {\kappa(g, h) - \kappa(g, h')} &\leq A \frac {\norm [\Group] {h^{-1} h'}^{\gamma}} {\norm [\Group] {h^{-1} g}^{\dim \Group + \gamma}}
        &\text{ if } \norm [\Group] {h^{-1} h'} \leq \frac {\norm [\Group] {h^{-1} g}} 2
    \end{align*}
    hold for every $g, g', h, h' \in \Group$ satisfying
    \begin{align*}
        g \neq h, \quad
        g' \neq h, \quad
        g \neq h'.
    \end{align*}

    If $T$ is the operator given by
    \begin{align*}
        T \phi(g) = \int_\Group \phi(h) \kappa(g, h),
        \quad g \in \Group, \phi \in \Schwartz \Group,
    \end{align*}
    in the sense of distributions,
    we shall say that $T$ is a \emph{Calder\'on-Zygmund operator}.
\end{definition}

\begin{lemma}
\label{lemma:Calderon-Zygmund_criteria}
    If the map
    \begin{align*}
        \kappa : (\Group \times \Group) \setminus \{(g, g) : g \in \Group\} \to \C
    \end{align*}
    is continuously differentiable on its domain and satisfies
    \begin{align*}
        \abs {\kappa(g, h)} &\leq A \norm [\Group] {h^{-1} g}^{-\dim \Group}\\
        \abs {\LeftDifferentialOperatorFirstOrder {X_j}_g \kappa(g, h)} &\leq A \norm [\Group] {h^{-1} g}^{-\dim \Group - 1}\\
        \abs {\LeftDifferentialOperatorFirstOrder {X_j}_h \kappa(g, h)} &\leq A \norm [\Group] {h^{-1} g}^{-\dim \Group - 1}
    \end{align*}
    for some $A \geq 0$,
    then $\kappa$ is a Calder\'on-Zygmund.
\end{lemma}
\begin{proof}
    Clearly, the first inequality is satisfied.

    Using the second inequality in our assumption,
    \begin{align*}
        \sup_{\norm [\Group] z \leq \norm [\Group] {g^{-1} g'}} \abs {(X_j)_{g_1 = g z} \kappa(g_1, h)}
        \leq A
        \sup_{\norm [\Group] z \leq \norm [\Group] {g^{-1} g'}} \abs {h^{-1} g z}^{-\dim \Group - 1}.
    \end{align*}

    Assume now that $2 \norm [\Group] {g^{-1} g'} \leq \norm [\Group] {h^{-1} g}$.
    It follows that
    \begin{align*}
        \norm [\Group] z \leq \frac 1 2 \norm [\Group] {h^{-1} g}
    \end{align*}
    Since $\norm [\Group] \dummy$ satisfies a triangle inequality,
    it also satisfies a reverse triangle inequality,
    \begin{align*}
        \norm [\Group] {h^{-1} g z}
        \geq
        \norm [\Group] {h^{-1} g}
        -
        \norm [\Group] {z}
        \geq
        \frac 1 2 \norm [\Group] {h^{-1} g}.
    \end{align*}

    Using the second inequality in our assumption,
    \begin{align*}
        \sup_{\norm [\Group] z \leq \norm [\Group] {g^{-1} g'}} \abs {(X_j)_{g_1 = g z} \kappa(g_1, h)}
        \leq C \norm [\Group] {h^{-1} g}^{-\dim \Group - 1}
    \end{align*}

    By the Taylor Remainder theorem,
    we conclude that
    \begin{align*}
        \abs {\kappa(g', h) - \kappa(g, h)}
        \leq C \norm [\Group] {g^{-1} g'}
        \norm [\Group] {h^{-1} g}^{-\dim \Group - 1}.
    \end{align*}

    The proof of the third inequality is proved similarly.
\end{proof}

\begin{proposition}
    Assume that $T \in \OperatorClass 0 {1, 0}$.
    The operator $T$ is Calder\'on-Zygmund.
    In particular, for each $1 < p \leq 2$,
    the map $T$ extends to a bounded map
    \begin{align*}
        T : \Lebesgue p \Group \to \Lebesgue p \Group.
    \end{align*}
\end{proposition}
\begin{proof}
    Let $\tilde \kappa(g, h) \defeq \kappa_g(h^{-1} g)$.
    It follows that for each $\phi \in \Schwartz \Group$
    \begin{align*}
        T \phi(g) = \int_{\Group} \phi(h) \tilde \kappa(g, h) \dd h,
    \end{align*}
    for each $g \in \Group$,
    where the right-hand side is interpreted in the sense of distributions.

    By the kernel estimates,
    we have
    \begin{align*}
        \abs {\tilde \kappa(g, h)} \leq \abs {\kappa_g(h^{-1} g)} \leq C \norm [\Group] {h^{-1} g}^{-\dim \Group}
    \end{align*}

    Fix $j \in \{1, \dots, \dim \Group\}$.
    Using the kernel estimates (Theorem~\ref{theorem:kernel_estimates}),
    it follows that
    \begin{align*}
        &\abs {(\LeftDifferentialOperatorFirstOrder {X_j})_{g} \tilde \kappa(g, h)}\\
        &\quad \leq
        \abs {(X_j)_{g_1 = g} \kappa_{g_1}(h^{-1} g)}
        + \abs {(X_j)_{g_2 = g} \kappa_{g}(h^{-1} g_2)}\\
        &\quad \leq
        C \norm [\Group] {h^{-1} g}^{-\dim \Group - 1}
    \end{align*}
    and similarly
    \begin{align*}
        \abs {(\LeftDifferentialOperatorFirstOrder {X_j})_{h} \tilde \kappa(g, h)}
        \leq \abs {(X_j)_{g} \kappa_{g}(h^{-1} g)}
        \leq C \norm [\Group] {h^{-1} g}^{-\dim \Group - 1}.
    \end{align*}

    We therefore obtain that $T$ is Calder\'on-Zygmund by applying Lemma~\ref{lemma:Calderon-Zygmund_criteria}.
    For the rest,
    we check easily (see for example~\cite[Proposition 3.2.17]{FischerRuzhansky16})
    that being Calderon-Zygmund means $\tilde \kappa$ satisfies the assumptions of~\cite[Theorem A.4.4]{FischerRuzhansky16}.
\end{proof}

\section{Construction of parametrices}

Given $\Lambda \geq 0$,
we let
\begin{align*}
    E_\lambda(\Lambda)
    \defeq
    \begin{cases}
        \Id {\Lebesgue 2 \CompactGroup} & \text{if } \lambda \geq \Lambda\\
        0 & \text{otherwise}
    \end{cases}
\end{align*}

\begin{definition}[Ellipticity]
\label{definition:ellipticity}
    Let $\sigma \in \SymbolClass m {\rho, \delta}$
    We shall say that that $\sigma$ is \emph{elliptic} and of \emph{elliptic order} $m$
    if there exists $\Lambda \geq 0$ such that the following property holds:
    for each $\gamma \in \R$,
    there exists $C \geq 0$ such that
    \begin{align}
        \norm [\Lebesgue 2 \CompactGroup] {\Rep \lambda \BesselPotential \gamma \sigma(g, \lambda) F}
        \geq C
        \norm [\Lebesgue 2 \CompactGroup] {\Rep \lambda \BesselPotential {\gamma + m} F}
        \label{eq:definition_of_ellipticity}
    \end{align}
    holds for every $F \in E_\lambda(\Lambda) \SmoothFunctions \CompactGroup$
    and every $(g, \lambda) \in \Group \times \VectorSpace$.
\end{definition}

\begin{lemma}[Inverse of an elliptic symbol]
\label{lemma:inverse_of_elliptic_symbol}
    Let $\sigma \in \SymbolClass m {\rho, \delta}$ be an elliptic symbol of elliptic order $m$,
    with $\Lambda \geq 0$ given by Definition~\ref{definition:ellipticity}.

    For any $F \in E_\lambda(\Lambda) \SmoothFunctions \CompactGroup$,
    let
    \begin{align*}
        E_\lambda(\Lambda) \sigma(g, \lambda)^{-1} \left(\sigma(g, \lambda) F\right) \defeq F.
    \end{align*}
    and consider the unique extension of $E_\lambda(\Lambda) \sigma(g, \lambda)^{-1}$ onto $\SmoothFunctions \CompactGroup$ which satisfies
    \begin{align*}
        \eval {%
            E_\lambda(\Lambda) \sigma(g, \lambda)^{-1}
            } {(\sigma(g, \lambda) E_\lambda(\Lambda))^\perp} = 0.
    \end{align*}

    The map $E_\lambda(\Lambda) \sigma(g, \lambda)^{-1}$ is well-defined.
    Moreover,
    for each $\lambda \in \R$,
    we have
    \begin{align}
        \norm [\Lin {\Lebesgue 2 \CompactGroup}] {%
            \Rep \lambda \BesselPotential {m + \gamma}
            E_\lambda(\Lambda) \sigma(g, \lambda)^{-1}
            \Rep \lambda \BesselPotential {-\gamma}
        }
        < \infty
        \label{eq:boundedness_of_E_lambda_Lambda_sigma_inverse}
    \end{align}
\end{lemma}
\begin{proof}
    Suppose that $F_1, F_2 \in E_\lambda(\Lambda) \SmoothFunctions \CompactGroup$ are such that
    \begin{align*}
        \sigma(g, \lambda) F_1
        = \sigma(g, \lambda) F_2.
    \end{align*}
    By definition of ellipticity with $\gamma \defeq - m$,
    it follows that
    \begin{align*}
        \norm [\Lebesgue 2 \CompactGroup] {F_1 - F_2}
        &\leq C
        \norm [\Lebesgue 2 \CompactGroup] {\Rep \lambda \BesselPotential {-m} \sigma(g, \lambda) (F_1 - F_2)}\\
        &= 0,
    \end{align*}
    so that the map is indeed well-defined.

    Now, given $\gamma \in \R$,
    we easily check by ellipticity that
    \begin{align*}
        &\norm [\Lebesgue 2 \CompactGroup] {\Rep \lambda \BesselPotential {m + \gamma} E_\lambda(\Lambda) \sigma(g, \lambda)^{-1} F}\\
        &\quad \leq C
        \norm [\Lebesgue 2 \CompactGroup] {\Rep \lambda \BesselPotential {\gamma} \sigma(g, \lambda) E_\lambda(\Lambda) \sigma(g, \lambda)^{-1} F}\\
        &\quad \leq C
        \norm [\Lebesgue 2 \CompactGroup] {\Rep \lambda \BesselPotential {\gamma} F},
    \end{align*}
    which shows~\eqref{eq:boundedness_of_E_lambda_Lambda_sigma_inverse}.
\end{proof}

\begin{proposition}[Inverse of an elliptic symbol]
\label{proposition:inverse_of_elliptic_symbol}
    Assume that $1 \geq \rho > \delta \geq 0$.
    Suppose that $\sigma \in \SymbolClass m {\rho, \delta}$ is a symbol which is $(\Lambda, m)$-elliptic.

    Let $\chi \in \SmoothFunctions {\R^+, [0, 1]}$ be such that
    \begin{align*}
        \chi_\Lambda(r) =
        \begin{cases}
            1 & \text{if } r \geq \Lambda_2\\
            0 & \text{if } r \leq \Lambda_1,
        \end{cases}
    \end{align*}
    for some $\Lambda < \Lambda_1 < \Lambda_2$,
    and define the symbol
    \begin{align*}
        \psi_\Lambda(\lambda)
        \defeq \sum_{\tau \in \dualGroup \CompactGroup}
        \chi_\Lambda(\JapaneseBracket \VectorSpace \lambda + \JapaneseBracket \CompactGroup \lambda) \Id {\Span \{\tau_{i j} : 1 \leq i, j \leq \dimRep \tau\}}.
    \end{align*}

    The map
    \begin{align*}
        \sigma_\Lambda^{-1}(g, \lambda)
        \defeq \psi_\Lambda E_\lambda(\Lambda_1) \sigma(g, \lambda)^{-1}
    \end{align*}
    defines a symbol of $\SymbolClass {-m} {\rho, \delta}$.
\end{proposition}
\begin{proof}
    Let us first observe that
    \begin{align}
        \psi_\Lambda = \sigma^{-1}_\Lambda(g, \lambda) \sigma(g, \lambda).
        \label{eq:identity_satisfied_by_inverse_of_symbol}
    \end{align}

    Since $\psi_\Lambda$ commutes with the powers of $\Rep \lambda \BesselPotentialSquared {}$,
    \begin{align*}
        &\norm [\Lin {\Lebesgue 2 \CompactGroup}] {\Rep \lambda \BesselPotential m \sigma_\Lambda(g, \lambda)^{-1}}\\
        &\quad \leq
        \norm [\Lin {\Lebesgue 2 \CompactGroup}] {\psi_\Lambda}
        \norm [\Lin {\Lebesgue 2 \CompactGroup}] {\Rep \lambda \BesselPotential m E_\lambda(\Lambda) \sigma(g, \lambda)^{-1}}
        < \infty
    \end{align*}
    where the finiteness is given by Lemma~\ref{lemma:inverse_of_elliptic_symbol}.

    We have thus shown that
    \begin{align*}
        \sup_{g \in \Group}
        \esssup_{\lambda \in \VectorSpace}
        \norm [\Lin {\Lebesgue 2 \CompactGroup}] {\Rep \lambda \BesselPotential {m - \delta \abs {\beta_0}} \LeftDifferentialOperator {\beta_0} \sigma_\Lambda(g, \lambda)^{-1}}
        < \infty,
    \end{align*}
    for $\beta_0 = 0$.
    Let us show it also holds for $\beta_0$ of higher order.

    By the Leibniz rule,
    we have
    \begin{align*}
        0 =
        \LeftDifferentialOperator {\beta_0} \psi_\Lambda
        =
        \sum_{\beta_0 = \beta_1 + \beta_2}
        \left(
        \LeftDifferentialOperator {\beta_1} \sigma_\Lambda(g, \lambda)^{-1}
        \LeftDifferentialOperator {\beta_2} \sigma(g, \lambda)\right),
    \end{align*}
    which implies that
    \begin{align*}
        \LeftDifferentialOperator {\beta_0} \sigma_{\Lambda}(g, \lambda)^{-1} \sigma(g, \lambda)
        = -
        \sum_{\substack{
            \beta_0 = \beta_1 + \beta_2\\
            \abs {\beta_1} < \abs {\beta_0}}
        }
        \left(
        \LeftDifferentialOperator {\beta_1} \sigma_\Lambda(g, \lambda)^{-1}
        \LeftDifferentialOperator {\beta_2} \sigma(g, \lambda) \right).
    \end{align*}
    Since $\sigma(g, \lambda)$ is invertible on $E_\lambda(\Lambda_1) \SmoothFunctions \CompactGroup$,
    we obtain
    \begin{align*}
        &\LeftDifferentialOperator {\beta_0} \sigma_{\Lambda}(g, \lambda)^{-1}\\
        &\quad
        = -
        \sum_{\substack{
            \beta_0 = \beta_1 + \beta_2\\
            \abs {\beta_1} < \abs {\beta_0}}
        }
        \left(
        \LeftDifferentialOperator {\beta_1} \sigma_\Lambda(g, \lambda)^{-1}
        \LeftDifferentialOperator {\beta_2} \sigma(g, \lambda) \right)
        E(\Lambda_1) \sigma^{-1}(g, \lambda),
    \end{align*}
    which allows us to conclude by induction and Lemma~\ref{lemma:inverse_of_elliptic_symbol}.

    Let us now work with difference operators.
    The ideas are the same,
    but the proof is slightly trickier
    because we have a \emph{Leibniz-like} rule instead of the classical Leibniz rule.

    Applying the Leibniz-like rule to~\eqref{eq:identity_satisfied_by_inverse_of_symbol},
    we obtain
    \begin{align*}
        \DifferenceOperator j \psi_\Lambda(\lambda)
        =
        &\DifferenceOperator j \sigma_\Lambda(g, \lambda)^{-1} \sigma(g, \lambda)
        + \sigma_\Lambda(g, \lambda)^{-1} \DifferenceOperator j \sigma(g, \lambda) \\
        &+ \sum_{1 \leq k, l \leq \dimDifferenceOperators} c_j^{k l} \DifferenceOperator k \sigma_\Lambda(g, \lambda)^{-1} \DifferenceOperator l \sigma(g, \lambda).
    \end{align*}
    Reorganising the terms above,
    and using the fact that $\sigma$ is invertible on $E_\lambda(\Lambda_1) \SmoothFunctions \CompactGroup$,
    we obtain
    \begin{align}
        &\DifferenceOperator j \sigma_\Lambda(g, \lambda)^{-1}
        + \sum_{1 \leq k, l \leq \dimDifferenceOperators} c_j^{k l} \DifferenceOperator k \sigma_\Lambda(g, \lambda)^{-1} \DifferenceOperator l \sigma(g, \lambda) E_\lambda(\Lambda_1) \sigma^{-1}(g, \lambda) \notag\\
        &=
        \DifferenceOperator j \psi_\Lambda(\lambda) E_\lambda(\Lambda_1) \sigma^{-1}(g, \lambda)
        - \sigma_\Lambda(g, \lambda)^{-1} \DifferenceOperator j \sigma(g, \lambda) E_\lambda(\Lambda_1) \sigma^{-1}(g, \lambda).
        \label{eq:system_of_equations_of_difference_operators}
    \end{align}

    If $R(g, \lambda)$ is the second line of the above,
    we check easily that
    \begin{align*}
        \norm [\Lin {\Lebesgue 2 \CompactGroup}] {%
            \Rep \lambda \BesselPotential {m + \rho + \gamma}
            R(g, \lambda)
            \Rep \lambda \BesselPotential {-\gamma}
        } < \infty,
    \end{align*}
    we can therefore deduce that
    \begin{align*}
        \norm [\Lin {\Lebesgue 2 \CompactGroup}] {%
            \Rep \lambda \BesselPotential {m + \rho + \gamma}
            \DifferenceOperator j \sigma_\Lambda(g, \lambda)^{-1}
            \Rep \lambda \BesselPotential {-\gamma}
        } < \infty,
    \end{align*}
    by considering the equations~\eqref{eq:system_of_equations_of_difference_operators} for all $j$ simultaneously.
    Applying $\DifferenceOperatorOrder \alpha$ to~\eqref{eq:identity_satisfied_by_inverse_of_symbol},
    we can deduce inductively by arguing like above that
    \begin{align*}
        \norm [\Lin {\Lebesgue 2 \CompactGroup}] {%
            \Rep \lambda \BesselPotential {m + \rho \abs \alpha + \gamma}
            \DifferenceOperatorOrder \alpha \sigma_\Lambda(g, \lambda)^{-1}
            \Rep \lambda \BesselPotential {-\gamma}
        } < \infty.
    \end{align*}

    The general case can be deduced similarly by applying $\LeftDifferentialOperator \beta \DifferenceOperatorOrder \alpha$ to~\eqref{eq:identity_satisfied_by_inverse_of_symbol}.
\end{proof}

\begin{theorem}[Existence of left parametrices]
\label{theorem:construction_of_parametrices}
    Let $A \in \OperatorClass m {\rho, \delta}$ be an $m$-elliptic operator of order $m$ with $1 \geq \rho > \delta \geq 0$.
    The exists an operator $B \in \OperatorClass {-m} {\rho, \delta}$ which satisfies
    \begin{align*}
        B A = \Id {\Schwartz \Group} \qquad \text{mod} \quad \SmoothingOperators
    \end{align*}
\end{theorem}
\begin{proof}
    Since $A = \Op(\sigma)$ is elliptic,
    we know that $\sigma_\Lambda(g, \lambda)^{-1} \in \SymbolClass {-m} {\rho, \delta}$ and
    \begin{align*}
        \sigma_\Lambda(g, \lambda)^{-1} \sigma(g, \lambda)
        &= \psi_\Lambda - \sigma_\Lambda(g, \lambda)^{-1} \sigma(g, \lambda) (\Id {\Lebesgue 2 \CompactGroup} - \psi_\Lambda)\\
        &= \psi_\Lambda \quad \text{mod} \quad \SmoothingSymbols,\\
        &= \Id {\Lebesgue 2 \CompactGroup} \quad \text{mod} \quad \SmoothingSymbols,
    \end{align*}
    since $\Id {\Lebesgue 2 \CompactGroup} - \psi_\Lambda$ is smoothing.

    Therefore,
    letting $B_0 \defeq \Op(\sigma_\Lambda(g, \lambda)^{-1})$ yields
    \begin{align*}
        B_0 A = \Id {\Schwartz \Group} - E_0 \quad \text{where } E_0 = \Op(e_0) \in \OperatorClass {-(\rho - \delta)} {\rho, \delta}
    \end{align*}
    by the composition formula.
    Suppose by induction that we have defined $B_j$ and $E_j = \Op(e_j)$ for $j = 0, \dots, k$ such that
    \begin{align*}
        (B_0 + \dots + B_k) A = I - E_k \quad \text{where } E_k = \Op(e_k) \in \OperatorClass {-(k + 1)(\rho - \delta)} {\rho, \delta}
    \end{align*}

    Letting $B_{k + 1} \defeq \Op(E_k \sigma_\Lambda(g, \lambda)^{-1})$,
    we obtain
    \begin{align*}
        (B_0 + \dots + B_{k + 1}) A = I - E_k + B_{k + 1} A = I - E_{k + 1}
    \end{align*}
    where $E_{k + 1} \defeq E_k - B_{k + 1} A$ is an operator in $\OperatorClass {-(k + 2)(\rho - \delta)} {\rho - \delta}$,
    again by the composition formula.

    Since the order of $B_k$ strictly decreases as $k$ strictly increases,
    it follows that
    \begin{align*}
        B \sim \sum_{k = 0}^{+\infty} B_k
    \end{align*}
    defines an operator in $\OperatorClass {-m} {\rho, \delta}$.
    Moreover,
    for each $N \in \N$ we have
    \begin{align*}
        B A - I + E_{N}
        =
        (B - \sum_{k = 0}^N B_k) A \in \OperatorClass {-(N + 1) (\rho - \delta)  + m} {\rho, \delta},
    \end{align*}
    with $E_N \in \OperatorClass {-(N + 1)(\rho - \delta)} {\rho, \delta}$.
    Letting $N \to \infty$ on both sides of the above,
    we obtain that
    \begin{align*}
        B A - I \in \SmoothingOperators,
    \end{align*}
    concluding the proof.
\end{proof}
