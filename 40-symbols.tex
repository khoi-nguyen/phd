\chapter{Symbolic calculus}
\label{chapter:symbolic_calculus}

\section{Difference operators}

The abelian case shows us that the \emph{order} of a symbol
must decrease appropriately when we apply certain linear operators to it.

\begin{definition}
\label{definition:difference_operators}
    Let $q \in \SmoothFunctions{\Group}$.
    The \emph{difference operator} associated with $q$, $\DifferenceOperator{q}$ is defined via
    \begin{align*}
        \DifferenceOperator{q} \Fourier f \defeq \Fourier\{q f\},
    \end{align*}
    where $f \in \Schwartz{\Group}$.

    Moreover, if $q$ vanishes at order $k \in \N$,
    we shall say that $\DifferenceOperator{q}$ is a \emph{difference operator of order $k$}.
\end{definition}

Observe that difference operators decrease the order of characteristic polynomials.

\begin{lemma}[Difference operators on characteristic polynomials]
\label{lemma:difference_operators_on_characteristic_polynomials}
    Let $q \in \SmoothFunctions \Group$.
    For every $\alpha \in \N^{\dim \Group}$,
    we have the formula
    \begin{align*}
        \DifferenceOperator q \Rep \lambda(\LeftDifferentialOperator \alpha)
        =
        \sum_{\beta \leq \alpha} \binom \alpha \beta
        (-1)^{\abs \beta}
        \LeftDifferentialOperator \beta q(e_\Group)
        \Rep \lambda(\LeftDifferentialOperator {\alpha - \beta}).
    \end{align*}

    In particular,
    if $\DifferenceOperator q$ is a difference operator of order $k$,
    then $\DifferenceOperator q \Rep \lambda(\LeftDifferentialOperator \alpha)$ is the characteristic polynomial of a differential operator with order $\abs \alpha - k$.
\end{lemma}
\begin{proof}
    By definition of difference operator,
    we have
    \begin{align*}
        \DifferenceOperator q \Rep \lambda(\LeftDifferentialOperator \alpha)
        = (-1)^\alpha \Fourier \{q \LeftDifferentialOperator \alpha \delta_{e_\Group}\}
    \end{align*}

    Let $H \in \Schwartz {\dualGroup \Group}$ and write
    \begin{align*}
        h \defeq \iota \circ \InverseFourier H.
    \end{align*}
    Using the definition of Fourier transform on distributions,
    we know that
    \begin{align}
        \dualBracket [\dualGroup \Group] {%
            \Fourier \{ q \LeftDifferentialOperator \alpha \delta_{e_\Group} \}
        } H
        =
        \dualBracket [\Group] {%
            q \LeftDifferentialOperator \alpha \delta_{e_\Group}
        } h
        =
        (-1)^{\abs \alpha}
        \dualBracket [\Group] {\delta_{e_\Group}} {\LeftDifferentialOperator \alpha (qh)}
        \label{eq:difference_operator_of_X_alpha}
    \end{align}

    Using the Leibniz rule,
    we know that
    \begin{align*}
        \dualBracket [\Group] {\delta_{e_\Group}} {\LeftDifferentialOperator \alpha (qh)}
        &=
        \sum_{\beta \leq \alpha} \binom \alpha \beta
        \dualBracket [\Group] {\delta_{e_\Group}} {\LeftDifferentialOperator \beta q \LeftDifferentialOperator {\alpha - \beta} h}\\
        &=
        \sum_{\beta \leq \alpha} \binom \alpha \beta
        \LeftDifferentialOperator \beta q(e_\Group)
        \dualBracket [\Group] {\delta_{e_\Group}} {\LeftDifferentialOperator {\alpha - \beta} h},
    \end{align*}
    which, after using the definition of distributional derivative,
    becomes
    \begin{align*}
        \dualBracket [\Group] {\delta_{e_\Group}} {\LeftDifferentialOperator \alpha (qh)}
        &=
        \sum_{\beta \leq \alpha} \binom \alpha \beta
        (-1)^{\abs {\alpha - \beta}}
        \LeftDifferentialOperator \beta q(e_\Group)
        \dualBracket [\Group] {\LeftDifferentialOperator {\alpha - \beta} \delta_{e_\Group}} {h}.
    \end{align*}

    Recognising the definition of distributional Fourier transform again,
    we obtain
    \begin{align*}
        \dualBracket [\Group] {\delta_{e_\Group}} {\LeftDifferentialOperator \alpha (qh)}
        &=
        \sum_{\beta \leq \alpha} \binom \alpha \beta
        (-1)^{\abs {\alpha - \beta}}
        \LeftDifferentialOperator \beta q(e_\Group)
        \dualBracket [\dualGroup \Group] {\Fourier\{\LeftDifferentialOperator {\alpha - \beta} \delta_{e_\Group}\}} {H}\\
        &=
        \sum_{\beta \leq \alpha} \binom \alpha \beta
        (-1)^{\abs {\alpha - \beta}}
        \LeftDifferentialOperator \beta q(e_\Group)
        \dualBracket [\dualGroup \Group] {\Rep \lambda(\LeftDifferentialOperator {\alpha - \beta})} {H}.
    \end{align*}

    Combining the above with~\eqref{eq:difference_operator_of_X_alpha},
    we obtain that
    \begin{align*}
        \dualBracket [\dualGroup \Group] {\DifferenceOperator q \Rep \lambda (\LeftDifferentialOperator \alpha)} {H}
        &=
        \sum_{\beta \leq \alpha} \binom \alpha \beta
        (-1)^{\abs \beta}
        \LeftDifferentialOperator \beta q(e_\Group)
        \dualBracket [\dualGroup \Group] {\Rep \lambda(\LeftDifferentialOperator {\alpha - \beta})} {H}.
    \end{align*}

    Since $H$ is arbitrary,
    we obtain the desired formula.
\end{proof}

We can provide an explicit formula for a suitably chosen family of difference operators.

\begin{lemma}
    Let $f \in \Schwartz \Group$.
    Suppose that for each $j \in \N$,
    we let
    \begin{align*}
        q_j((x, k)^{-1}) = x_j,
        \quad (x, k) \in \Group,
    \end{align*}
    and assume that $q \in \SmoothFunctions \Group$ is a function which does not depend on $x \in \VectorSpace$ but only on $k \in \CompactGroup$.

    We have the following formulas.
    \begin{enumerate}
        \item For each $j \in \{1, \cdots, \dim \VectorSpace\}$,
            and each $F \in \Lebesgue 2 \CompactGroup$,
            we have
            \begin{align*}
                \DifferenceOperator {q_j} \Fourier \phi(\lambda) F(u) = \frac 1 {i \turn} \eval {\D* 1 t} {t = 0} \Fourier \phi(\lambda + t u e_j) F(u)
            \end{align*}
        \item
    \end{enumerate}
\end{lemma}
\begin{proof}
    By
    \begin{align*}
        \Fourier \{q_j f\}(\lambda)
    \end{align*}
\end{proof}

\begin{definition}
\label{definition:admissibility_of_difference_operators}
\index{difference operators!admissibility}
    A finite collection $q_1$, \dots, $q_M \in \SmoothFunctions{\Group}$ of smooth functions is said to be \emph{admissible}
    if $\dd q_j(e) \neq 0$ for each $j \in \{1, \cdots, M\}$
    and if
    \begin{align*}
        \rank(\dd q_1(e), \cdots, \dd q_m(e)) = \dim \Group.
    \end{align*}

    Moreover, if
    \begin{align*}
        \bigcap_{j = 1}^M \{ q_j = 0 \} = \{e\},
    \end{align*}
    we shall say that the collection is \emph{strongly admissible}.

    A collection of \emph{difference operators} is called \emph{(strongly) admissible}
    if the associated smooth functions form a \emph{(strongly) admissible} collection.
\end{definition}

\begin{definition}
\label{definition:Leibniz-like_property_for_smooth_functions}
    We shall say that an admissible collection
    \begin{align*}
        q_1, \cdots q_{\dimDifferenceOperators} \in \SmoothFunctions \CompactGroup
    \end{align*}
    satisfies the \emph{Leibniz-like} property
    if for each $j = 1, \cdots, \dimDifferenceOperators$,
    \begin{align*}
        q_j(g h) = q_j(g) + q_j(h) + \sum_{1 \leq k, l \leq \dimDifferenceOperators} c^j_{k, l} q_k(g) q_l(h)
    \end{align*}
    holds for every $g, h \in \Group$.
\end{definition}

Using \cite[Lemma 4.4]{RuzhanskyTurunenWirth10}, we can show

\begin{lemma}
    There exists a strongly admissible family $q_1$, \dots, $q_M \in \SmoothFunctions{\Group}$ on $\Group$ which satisfies the Leibniz-like property.
\end{lemma}
\begin{proof}
    Denote by $F$ the set of all fundamental representations of $\CompactGroup$,
    % TODO: add reference for fundamental representations
    i.e. a finite collection such that for any $\tau \in \dualGroup \CompactGroup$,
    there exists $\tau_1, \cdots, \tau_n \in F$ such that
    \begin{align*}
        \tau = \tau_1 \otimes \cdots \otimes \tau_n.
    \end{align*}
    % Ask Veronique if it's necessary
    We also assume $F$ contains the identity representation.

    Now,
    let us define the following smooth functions
    \begin{align*}
        q_j(x, k) &\defeq \ip {x} {e_j}, &j = 1, \cdots, \dim \VectorSpace\\
        q^\tau_{m n}(x, k) &\defeq {\left(\tau - \Id {H_\tau}\right)}_{m n},
        &\tau \in F, \ 1 \leq m, n \leq \dimRep \tau.
    \end{align*}
    Now we let
    \begin{align*}
        \Delta = \{q_j : 1 \leq j \leq \dim \VectorSpace\}
        \cup \{q^\tau_{m n} : \tau \in F, \ 1 \leq m, n \leq \dimRep \tau\}
    \end{align*}

    \begin{description}
        \item [Strong admissibility]
            Clearly, every $q \in \Delta$ satisfies $q_j(0) = 0$.

            By \cite[Lemma 5.11]{Fischer2015},
            we know that
            \begin{align*}
                \rank \{\dd q^\tau_{m n}(e) : \tau \in F, \ 1 \leq m, n \leq \dimRep \tau\} = \dim \CompactGroup,
            \end{align*}
            so we easily check that
            \begin{align*}
                \rank \Delta = \dim \Group.
            \end{align*}

            By \cite[Lemma 5.11]{Fischer2015},
            if all $q^\tau_{m n}(x, k)$ vanish, then $k = \Id \VectorSpace$,
            while if all $q_j(x, k)$ vanish, this means $x = 0_\VectorSpace$.
            Therefore,
            \begin{align*}
                \bigcap_{q \in \Delta} \{q = 0\} = (0_\VectorSpace, \Id \VectorSpace)
            \end{align*}
        \item [Leibniz-like formula]
            Using \cite[Corollary 5.13]{Fischer2015},
            we only need to show that $q_j$, $j = 1, \cdots, \dim \VectorSpace$ satisfy the Leibniz-like preperty.
            For each $j \in \N$,
            \begin{align*}
                q_j((x, k) (y, l))
                &= \ip {x + k y} {e_j}\\
                &= q_j(x, k) + q_j(y, l) + \ip {(k - \Id \VectorSpace) y} {e_j}\\
                &= q_j(x, k) + q_j(y, l) + \ip y {{(k - \Id \VectorSpace)}^{-1} e_j}
            \end{align*}

            Observing that
            \begin{align*}
                \transpose {(k - \Id \VectorSpace)} e_j
                = \transpose {(k - \Id \VectorSpace)}_{i j} e_i
                = {(k - \Id \VectorSpace)}_{j i} e_i,
            \end{align*}
            we obtain that
            \begin{align*}
                q_j((x, k) (y, l))
                &= q_j(x, k) + q_j(y, l) + \sum_{i = 1}^{\dim \VectorSpace} (k - \Id \VectorSpace)_{j i} \ip y {e_i}\\
                &= q_j(x, k) + q_j(y, l) + \sum_{i = 1}^{\dim \VectorSpace} (k - \Id \VectorSpace)_{j i} q_i(y, l)
            \end{align*}

            Defining
            \begin{align*}
                \tau(k) \defeq k
            \end{align*}
            we observe that $\tau \in F$ and so the above becomes
            \begin{align*}
                q_j((x, k) (y, l))
                &= q_j(x, k) + q_j(y, l) + \sum_{i = 1}^{\dim \VectorSpace} q^{\tau}_{j i}(x, k) q_i(y, l).
            \end{align*}

            We have thus shown that each $q \in \Delta$ satisfies the Leibniz-like formula.
    \end{description}
\end{proof}

\begin{remark}
    From now on, we fix an admissible family $q_1, \cdots, q_{\dimDifferenceOperators}$ on $\Group$.
    Given $\alpha \in \N^{\dimDifferenceOperators}$, we let
    \begin{align*}
        q^\alpha = \prod_{j = 1}^{\dimDifferenceOperators} q_j^{\alpha_j}.
    \end{align*}
    Moreover, we let $\DifferenceOperatorOrder{\alpha}$ be the difference operator associated with the smooth function
    \begin{align*}
        \Group \to \C : g \mapsto q^\alpha(g^{-1}).
    \end{align*}
\end{remark}

\begin{definition}[Taylor remainder]
\label{definition:Taylor_remainder}
    Let $f \in \Schwartz \Group$, $g \in \Group$
    and fix a strongly admissible collection of smooth functions
    \begin{align*}
        \Delta = \{q_1, \cdots q_{\dimDifferenceOperators} \in \SmoothFunctions \Group \}
    \end{align*}
    containing $\dim \Group$ elements.
    Also, define a basis $X_j \in \VectorFields$, $j = 1, \cdots, \dim \Group$ of left-invariant vector fields such that
    \begin{align*}
        X'_j \{q_k(\dummy^{-1})\}(0_\VectorSpace, \Id \VectorSpace) = \Kronecker j k
    \end{align*}
    for every $j, k \in \{1, \cdots, \dim \Group\}$.

    We define the \emph{Taylor remainder} of $f$ of order $N$ at $g \in \Group$ via
    \begin{align*}
        \TaylorRemainder f g N(h) \defeq
        \begin{cases}
            f(g h) - \sum_{\abs \alpha \leq N} q^\alpha(h^{-1}) \TaylorLeftDifferentialOperator \alpha f(g) & \text{if } N \geq 0\\
            f(g h) & \text{if } N < 0,
        \end{cases}
    \end{align*}
    where in the above
    \begin{align*}
        \TaylorLeftDifferentialOperator \alpha \defeq X_1^{\prime \alpha_1} \cdots X_{\dimDifferenceOperators}^{\prime \alpha_{\dimDifferenceOperators}}
    \end{align*}
\end{definition}

\begin{lemma}[Taylor Theorem]
    We use the notation of Definition~\ref{definition:Taylor_remainder}.
    For each $N \in \N$,
    we can find $C \geq 0$ such that
    for each $f \in \SmoothFunctions \Group$ and each $g \in \Group$,
    \begin{align*}
        \abs {\TaylorRemainder f g N (h)}
        \leq C \sup_{\abs \alpha \leq N + 1} \abs {\TaylorLeftDifferentialOperator \alpha f(g)} \norm [\Group] h^{N + 1}
    \end{align*}
    holds for every $h \in \Group$.
\end{lemma}

\section{Symbol and operators classes}

\begin{definition}[Symbol classes]
\label{definition:symbol_classes}
    Let $m \in \R$ and fix $\rho, \delta \in \R$ such that $0 \leq \rho \leq \delta \leq 1$.
    We shall say that a map
    \begin{align*}
        \sigma : \Group \times \VectorSpace \mapsto \End(\SmoothFunctions \CompactGroup)
    \end{align*}
    is a \emph{symbol of order $m$ and of type $(\rho, \delta)$} if the following conditions are satisfied.
    \begin{enumerate}
        \item
            For each $F \in \SmoothFunctions \CompactGroup$ and each $k \in \CompactGroup$,
            the map
            \begin{align*}
                (g, \lambda) \mapsto \sigma(g, \lambda) F(k)
            \end{align*}
            is smooth.
        \item
            For each $\beta \in \N^{\dim \Group}$,
            $\LeftDifferentialOperator \beta \sigma(g, \dummy) \in \TemperedDistributions {\dualGroup \Group}$
            for each $g \in \Group$ and the map
            \begin{align*}
                g \in \Group \mapsto \LeftDifferentialOperator \beta \sigma(g, \dummy) \in \TemperedDistributions {\dualGroup \Group}
            \end{align*}
            is continuous.
        \item \label{item:symbol_bound_condition}
            For each $\alpha \in \N^{\dim \Group}$, $\beta \in \N^m$, and each $\gamma \in \R$,
            the operator
            \begin{align*}
                \Rep{\lambda} \BesselPotential{\rho \abs\alpha - m - \delta \abs\beta + \gamma} \LeftDifferentialOperator{\beta} \DifferenceOperatorOrder{\alpha} \sigma(g, \lambda) \Rep{\lambda} \BesselPotential{-\gamma}
            \end{align*}
            is bounded in $\Lebesgue 2 \CompactGroup$ by a finite constant that does not depend on $g \in \Group$ or $\lambda \in \VectorSpace$.
    \end{enumerate}

    The set $\SymbolClass{m}{\rho, \delta}$ will be used to denote the set of all symbols of order $m$ and type $(\rho, \delta)$.
\end{definition}

\begin{definition}[Symbol semi-norms]
    Let $m \in \R$ and fix $\rho, \delta \in \R$ such that $0 \leq \rho \leq \delta \leq 1$.
    If $\sigma \in \SymbolClass m {\rho, \delta}$,
    then for each $N \in \N$,
    we let
    \begin{align*}
        &\SymbolSemiNorm m {\rho, \delta} N {\sigma(g; \lambda)}
        \defeq
        \sup_{\abs \alpha, \abs \beta, \abs \gamma \leq N}
        \\
        &\qquad
        \norm [\Lin{\Lebesgue 2 \CompactGroup}] {%
            \Rep{\lambda} \BesselPotential{\rho \abs\alpha - m - \delta \abs\beta + \gamma} \LeftDifferentialOperator{\beta} \DifferenceOperatorOrder{\alpha} \sigma(g, \lambda) \Rep{\lambda} \BesselPotential{-\gamma}
        }.
    \end{align*}

    Moreover, we also let
    \begin{align*}
        \SymbolSemiNorm m {\rho, \delta} N \sigma
        \defeq \sup_{g \in \Group} \sup_{\lambda \in \VectorSpace}
        \SymbolSemiNorm m {\rho, \delta} N {\sigma(g; \lambda)}
    \end{align*}
    for each $N \in \N$.
\end{definition}

\begin{example}[Characteristic polynomials]
    Given $m \in \N$,
    the map
    \begin{align*}
        \sigma(g, \lambda) \defeq \sum_{\abs \alpha \leq m} c_\alpha(g) \Rep \lambda(X)^\alpha
    \end{align*}
    defines a symbol in $\SymbolClass m {1, 0}$.
\end{example}

\begin{lemma}[Inclusion of symbol classes]
    Suppose that $m_1, m_2 \in \R$ and $\rho_1, \rho_2, \delta_1, \delta_2 \in [0, 1]$.
    If the following inequalities hold
    \begin{align*}
        m_1 \leq m_2, \quad \delta_1 \leq \delta_2, \quad \rho_1 \geq \rho_2,
    \end{align*}
    then $\SymbolClass {m_1} {\rho_1, \delta_1} \subset \SymbolClass {m_2} {\rho_2, \delta_2}$,
    and the inclusion is continuous.
\end{lemma}
\begin{proof}
    Let $\sigma \in \SymbolClass {m_1} {\rho_1, \delta_1}$,
    and fix $\alpha \in \N^{\dimDifferenceOperators}$, $\beta \in \N^{\dim \Group}$ and $\gamma \in \R$.

    It is clear that
    \begin{align*}
        \Rep{\lambda} \BesselPotential{\rho_2 \abs\alpha - m_2 - \delta_2 \abs\beta + \gamma}
        \LeftDifferentialOperator{\beta} \DifferenceOperatorOrder{\alpha} \sigma(g, \lambda)
        \Rep{\lambda} \BesselPotential{-\gamma}
        = I_1 I_2,
    \end{align*}
    where
    \begin{align*}
        I_1 &\defeq \Rep \lambda \BesselPotential {m_1 - m_2 + (\rho_2 - \rho_1) \abs \alpha + (\delta_1 - \delta_2) \abs \beta}\\
        I_2 &\defeq \Rep{\lambda} \BesselPotential{\rho_1 \abs\alpha - m_1 - \delta_1 \abs\beta + \gamma}
        \LeftDifferentialOperator{\beta} \DifferenceOperatorOrder{\alpha} \sigma(g, \lambda)
        \Rep{\lambda} \BesselPotential{-\gamma}
    \end{align*}

    Because of our assumption,
    it is clear that
    \begin{align*}
        m_1 - m_2 + (\rho_2 - \rho_1) \abs \alpha + (\delta_1 - \delta_2) \abs \beta \leq 0
    \end{align*}
    so that $I_1$ satisfies
    \begin{align*}
        \norm [\Lin {\Lebesgue 2 \CompactGroup}] {I_1}
        \leq 1.
    \end{align*}

    By our assumption on $\sigma$,
    it is clear that $I_2$ is bounded on $\Lebesgue 2 \Group$ uniformly in $g \in \Group$ and $\lambda \in \Group$,
    so that the same holds for $I_1 I_2$.
\end{proof}

\begin{definition}[Smoothing symbols]
\label{definition:smoothing_symbols}
    We let
    \begin{align*}
        \SmoothingSymbols \defeq \bigcap_{m \in \R} \SymbolClass{m}{1, 0}.
    \end{align*}
    The elements of $\SmoothingSymbols$ will be called \emph{smoothing symbols}.
\end{definition}

\begin{definition}[Operator classes]
\label{definition:operator_classes}
    Let $\sigma \in \SymbolClass{m}{\rho, \delta}$.
    We define the operator $\Op(\sigma)$ via
    \begin{align*}
        \Op(\sigma) \phi(g) \defeq
        \int_\VectorSpace
            \tr\left(\Rep\lambda(g) \sigma(g, \lambda) \Fourier \phi(\lambda)\right)
        \dd \lambda,
    \end{align*}
    where $\phi \in \Schwartz\Group$, and $g \in \Group$.


    If $T = \Op(\sigma)$ for a certain $\sigma \in \SymbolClass{m}{\rho, \delta}$,
    we shall say that $T$ is an \emph{operator of order $m$ and of type $(\rho, \delta)$}.

    The set of all such operators will be denoted by
    \begin{align*}
        \OperatorClass{m}{\rho, \delta} \defeq \Op(\SymbolClass{m}{\rho, \delta}).
    \end{align*}
    Naturally, an operator in
    \begin{align*}
        \SmoothingOperators \defeq \Op(\SmoothingSymbols)
    \end{align*}
    is called \emph{smoothing}.
\end{definition}

\subsection{First properties of symbol classes}
% TODO: Move because kernels are a prerequisites.

\begin{proposition}
    Suppose that $\rho, \delta \in \R$ satisfy $1 \geq \rho \geq \delta \geq 0$.
    Given $m, m_1, m_2 \in \R$,
    choose three symbols $\sigma \in \SymbolClass m {\rho, \delta}$,
    $\sigma_1 \in \SymbolClass {m_1} {\rho, \delta}$,
    $\sigma_2 \in \SymbolClass {m_2} {\rho, \delta}$.
    The kernels of the aforementioned symbols will be denoted by
    $\kappa$, $\kappa_1$ and $\kappa_2$ respectively.

    The following properties hold.
    \begin{enumerate}
        \item For each $\alpha \in \N^{\dimDifferenceOperators}$ and each $\beta \in \N^{\dim \Group}$,
            \begin{align*}
                (g, \lambda) \in \Group \times \VectorSpace \mapsto
                \LeftDifferentialOperator \beta \DifferenceOperator \alpha \sigma(g, \lambda)
            \end{align*}
            belongs to $\SymbolClass {m - \rho \abs \alpha + \delta \abs \beta} {\rho, \delta}$,
            and its kernel is given by
            \begin{align*}
                g \in \lambda \mapsto q^\alpha \LeftDifferentialOperator \beta \kappa_g.
            \end{align*}
        \item The pointwise adjunction of $\sigma$,
            \begin{align*}
                \adj \sigma(g, \lambda) \defeq \adj {\sigma(g, \lambda)},
            \end{align*}
            defines a symbol in $\SymbolClass m {\rho, \delta}$ whose kernel is given by
            \begin{align*}
                \adj \kappa_g(h) \defeq \conj {\kappa_g(h^{-1})},
            \end{align*}
            where the above is interpreted in the sense of distributions.
        \item The pointwise composition
            \begin{align*}
                (g, \lambda) \mapsto \sigma_1(g, \lambda) \sigma_2(g, \lambda)
            \end{align*}
            defines a symbol in $\SymbolClass {m_1 + m_2} {\rho, \delta}$,
            whose symbol is given by
            \begin{align*}
                g \in \Group \mapsto \conv {\kappa_{1, g}} {\kappa_{2, g}}
            \end{align*}
    \end{enumerate}
\end{proposition}

\section{Kernels and quantisation}

\begin{definition}[Kernel of a symbol]
\label{definition:kernel_of_symbol}
    Let $\sigma \in \SymbolClass{m}{\rho, \delta}$.
    For each $g \in \Group$, we let
    \begin{align*}
        \kappa_g \defeq \InverseFourier\{\sigma(g, \dummy)\} \in \TemperedDistributions\Group.
    \end{align*}
    The map
    \begin{align*}
        \kappa : \Group \to \TemperedDistributions\Group : g \mapsto \kappa_g
    \end{align*}
    is called the \emph{kernel} of $\sigma$.
\end{definition}

\begin{lemma}
    Let $\sigma \in \SymbolClass m {\rho, \delta}$,
    and denote by $\kappa$ its associated kernel.
    For each $g \in \Group$,
    $\kappa_g$ is a tempered distribution and
    \begin{align*}
        g \in \Group \mapsto \kappa_g \in \TemperedDistributions \Group
    \end{align*}
    is smooth,
    i.e.\ $\kappa \in \SmoothFunctions {\Group, \TemperedDistributions \Group}$.
\end{lemma}
\begin{proof}
    Let $g \in \Group$ and $\beta \in \N^{\dim \Group}$.
    By ???, $\kappa_g = \InverseFourier \{\LeftDifferentialOperator \beta \sigma(g, \dummy)\}$ is a tempered distribution.
    % TODO: Give reference
    Since the inverse Fourier transform is also continuous,
    the continuity of $\sigma$ in $g$ implies that
    \begin{align*}
        g \mapsto \kappa_g = \InverseFourier \{\LeftDifferentialOperator \beta \sigma(g, \dummy)\}
    \end{align*}
    is continuous.
    This concludes the proof.
\end{proof}

\begin{proposition}[Quantisation]
\label{proposition:quantisation}
    Let $\sigma \in \SymbolClass{m}{\rho, \delta}$,
    and denote by $\kappa$ its associated kernel.
    If $\phi \in \Schwartz\Group$, then for each $g \in \Group$, we have
    \begin{align*}
        \Op(\sigma) \phi(g) = \conv{\phi}{\kappa_g}.
    \end{align*}

    In other words, $\kappa$ is the right convolution kernel associated with $\Op(\sigma)$.
\end{proposition}
\begin{proof}
    Let $g \in \Group$ and fix $s < -\max \{\dim \Group/2, \abs m\}$.
    By definition, we know that $\conv \phi \kappa_g \in \Sobolev s$ if and only if
    \begin{align*}
        \Rep \dummy \BesselPotential s \Fourier \{\conv \phi {\kappa_g}\}
        = \Rep \dummy \BesselPotential s \sigma(g, \dummy) \Fourier \phi
    \end{align*}
    belongs to $\LebesgueDual 2 \Group$.
    To show this,
    observe that the above identity implies
    \begin{align*}
        \norm[\SchattenClasses 2 {\Lebesgue 2 \CompactGroup}] {\Rep \dummy \BesselPotential s \Fourier \{\conv \phi {\kappa_g}\}}^2
        \leq C_s \norm[\SchattenClasses 2 {\Lebesgue 2 \CompactGroup}] {\Fourier \phi}^2,
    \end{align*}
    which, since the right-hand side is integrable on $\VectorSpace$,
    means that $\conv \phi {\kappa_g}$ belongs to $\Sobolev s$.
    By Proposition~\ref{proposition:general_Fourier_inverse_formula},
    we get that
    \begin{align*}
        \conv \phi {\kappa_g}(g)
        &= \int_\VectorSpace \tr\left(\Rep \lambda(g) \Fourier \{\conv \phi {\kappa_g}\}\right) \dd \lambda\\
        &= \int_\VectorSpace \tr\left(\Rep \lambda(g) \sigma(g; \lambda) \Fourier \phi(\lambda)\right) \dd \lambda,
    \end{align*}
    which concludes the proof,
    as the right-hand side is exactly $\Op(\sigma) \phi(g)$.
\end{proof}

\section{Holomorphic functional calculus}

The aim of this section is to show two results concerning functions of symbols which will be essential hereafter.

First, we wish to show that for a well-behaved symbol $\sigma \in \SymbolClass m {\rho, \delta}$,
its powers $\sigma^s$, $s \in \R$ define symbols in $\SymbolClass {s m} {\rho, \delta}$.

Secondly, we would like to show that $\SmoothingSymbols$ is dense in $\SymbolClass m {\rho, \delta}$,
a result whose importance can be compared to that of other density results in analysis.
To this end, we want to create a family of smoothing symbols $\eta_t$, $t \in (0, 1]$, in the hope
that $\sigma \eta_t$ converges to $\sigma$ as $t$ goes to $0$ in a suitable symbol class.
The compact case~\cite{Fischer2015} suggests that the following
\begin{align}
    \eta_t(\lambda) \defeq \e^{t \Rep \lambda \Laplacian},
    \quad \lambda \in \VectorSpace
    \label{eq:candidate_to_approximate_identity}
\end{align}
is the best candidate.

The results presented herein would be significantly more general with the calculus at our disposal.
However, the proof of the composition and adjunction formulas rely on the fact that $\Rep \lambda \BesselPotential \gamma$ is a symbol of order $\gamma$
and on good estimates on~\eqref{eq:candidate_to_approximate_identity}.

The main idea of this section is to follow~\cite{RuzhanskyWirth14},
which uses the following version of the \emph{Cauchy integral formula}
\begin{align}
    F(\sigma) = \int_\Gamma F(z) (\sigma - z\Id{\Lebesgue 2 \CompactGroup})^{-1} \dd z.
    \label{eq:Cauchy_integral_formula_for_operators}
\end{align}
This allows us to carry out our computations on the resolvant.

In order to successfully apply~\eqref{eq:Cauchy_integral_formula_for_operators},
we need to identify a class of symbols whose resolvant might give us appropriate bounds.
We are thus led to the following definition.

\begin{definition}[Parameter-dependent ellipticity, \cite{RuzhanskyWirth14}]
\label{definition:parameter-ellipticity}
    Let $\sigma \in \SymbolClass m {\rho, \delta}$ with $m > 0$.
    Given a subset $\Lambda \subset \C$,
    we shall say that $\sigma$ is \emph{parameter-elliptic} with respect to $\Lambda$
    if the following properties hold.
    \begin{enumerate}
        \item For each $z \in \Lambda$ and each $(g, \lambda) \in \Group \times \VectorSpace$,
            the operator
            \begin{align*}
                \sigma(g, \lambda) - z \Id {\Lebesgue 2 \CompactGroup}
            \end{align*}
            is invertible.
        \item
            For each $\gamma_1, \gamma_2 \in \R$,
            the operator
            \begin{align*}
                I_1(m, m + \gamma_1)
                I_2(\gamma_2)
                (\sigma(g, \lambda) - z \Id {\Lebesgue 2 \CompactGroup})^{-1}
                I_2(-\gamma_2)
                I_1(m, -\gamma_1)
            \end{align*}
            is bounded on $\Lebesgue 2 \CompactGroup$ uniformly in $g \in \Group$, $\lambda \in \VectorSpace$ and $z \in \lambda$,
            where
            \begin{align}
                I_1(m, \gamma) &\defeq (\abs z^{\frac 1 m} + \Rep \lambda \BesselPotential 1)^\gamma,\\
                I_2(\gamma) &\defeq \Rep \lambda \BesselPotential \gamma.
                \label{eq:operators_for_parameter-ellipticity}
            \end{align}
    \end{enumerate}
\end{definition}

The definition above had to be adapted from the compact case
to take into account that our left-invariant Laplacian is \emph{not} right-invariant.
It makes it somehow difficult to check parameter-ellipticity,
but as we shall mainly be concerned with diagonal symbol,
this is a price we are willing to pay.

\begin{example}
    In this section,
    we shall mainly focus on the following examples.

    \begin{itemize}
        \item The symbol $\Rep \lambda \BesselPotential 2$ is parameter-elliptic of order $2$ with respect to $\R^-$.
        \item The symbol $\Rep \lambda (\Laplacian)$ is parameter-elliptic of order $2$ with respect to $\R^+$.
    \end{itemize}
\end{example}

\begin{lemma}[\cite{RuzhanskyWirth14, Theorem 3.1. (1)}]
    Let $\sigma \in \SymbolClass m {\rho, \delta}$ be a symbol which does not depend on $g \in \Group$,
    with $m > 0$ and $\rho > 0$.
    If $\sigma$ is parameter-elliptic with respect to $\lambda \in \Lambda$, then
    for each $\alpha \in \N^{\dimDifferenceOperators}$, $\gamma_1, \gamma_2 \in \R$,
    we have
    \begin{align*}
        I_1(m, m + \gamma_1)
        I_2(\gamma_2 + \rho \abs \alpha)
        \DifferenceOperatorOrder \alpha (\sigma(\lambda) - z \Id {\Lebesgue 2 \CompactGroup})^{-1}
        I_2(-\gamma_2)
        I_1(m, -\gamma_1)
    \end{align*}
    uniformly in $\lambda \in \VectorSpace$, and $z \in \C$.
    In the above, $I_1$ and $I_2$ are defined like in~\eqref{eq:operators_for_parameter-ellipticity}.
\end{lemma}
\begin{proof}[Sketch proof]
    The proof in the compact case (cf~\cite{RuzhanskyWirth14}) relies mainly on a \emph{Leibniz-like} rule.
    We apply a difference operator on
    \begin{align*}
        I = (\sigma(\lambda) - z \Id {\Lebesgue 2 \CompactGroup}) (\sigma(\lambda) - z \Id {\Lebesgue 2 \CompactGroup})^{-1}
    \end{align*}
    and apply the Leibniz-like rule on the right hand side.

    A similar Leibniz-like rule holds on the motion group.
    Moreover, our definition of parameter-ellipticity ensures that for the purposes of evaluating a norm $\norm [\Lin {\Lebesgue 2 \Group}] \dummy$,
    we can reorder a product of $I_1(m, \gamma_1)$, $I_2(\gamma_2)$ and the resolvant $(\sigma - \Id {\Lebesgue 2 \CompactGroup})^{-1}$ however we like,
    exactly like on the compact group.

    We proceed inductively in a very similar manner for difference operators of higher order.
\end{proof}

\begin{definition}[Sector]
    Let $\Lambda \subset \C$.
    We shall say that $\Lambda$ is a \emph{sector} if
    \begin{align*}
        \Lambda
        = \Lambda(\theta_1, \theta_2)
        \defeq \{r \e^{\i \theta} \in \C : r \geq 0, \theta_1 \leq \theta \leq \theta_2\}
    \end{align*}
    for some $\theta_1 \leq \theta_2$.
\end{definition}

It follows from elementary complex analysis that there exists a determination of $\log$ on the complement of a sector.

We are now ready to state our main result.
\begin{theorem}[\cite{RuzhanskyWirth14}]
\label{theorem:functional_calculus}
    Assume $0 \leq \delta < \delta \leq 1$.
    Let $\sigma \in \SymbolClass m {\rho, \delta}$ be a symbol of strictly positive order,
    parameter-elliptic with respect to a sector $\Lambda \subset \C$.
    If $F$ is analytic in $\C \setminus \Lambda_\epsilon$
    with $\Lambda_\epsilon \defeq (\Lambda \cup \{z \in \C : \abs z \leq \epsilon\})$ for some $\epsilon > 0$
    and satisfies
    \begin{align*}
        \abs {F(z)} \leq C \abs z^s, \quad z \in \Gamma \defeq \partial \Lambda_\epsilon.
    \end{align*}
    for some $s < 0$.

    In this case,
    \begin{align*}
        F(\sigma)(g, \lambda)
        = \frac 1 {\i \turn} \oint_{\Gamma} F(z) (\sigma(g, \lambda) - z \Id {\Lebesgue 2 \CompactGroup})^{-1} \dd z
    \end{align*}
    and $F(\sigma)$ defines a symbol in $\SymbolClass {s m} {\rho, \delta}$.

    Moreover,
    for each $n \in \N$,
    there exists $C \geq 0$ which does \emph{not} depend on $F$ such that
    \begin{align}
        \SymbolSemiNorm {s m} {\rho, \delta} N {F(\sigma)} \leq C \sup_{z \in \Gamma} \frac {\abs {F(z)}} {\abs z^s}.
        \label{eq:functional_calculus:bound_on_seminorm}
    \end{align}

    If we have not shown the composition formula,
    we can only show the result for a symbol $\sigma$ which does not depend on $g \in \Group$.
\end{theorem}
\begin{proof}
    Let us first assume that $-1 < s < 0$ and fix $\gamma \in \R$.
    By the Helffer-Sj\"ostrand formula,
    \begin{align*}
        &\abs {%
            \LeftDifferentialOperator \beta \DifferenceOperator \alpha
            F(\sigma)(g, \lambda)_{\mu_{m n}, \nu_{p q}}
        }\\
        &\ \leq C \oint_{\partial \Lambda} \abs {F(z)}
        \abs {%
            \LeftDifferentialOperator \beta \DifferenceOperator \alpha
            (\sigma(g, \lambda) - \Id {\Lebesgue 2 \CompactGroup})^{-1}_{\mu_{m n}, \nu_{p q}}
        } \abs {\dd z}.
    \end{align*}

    Using parameter-ellipticity,
    we obtain
    \begin{align*}
        \abs {%
            \LeftDifferentialOperator \beta \DifferenceOperator \alpha
            (\sigma(g, \lambda) - \Id {\Lebesgue 2 \CompactGroup})^{-1}_{\mu_{m n}, \nu_{p q}}
        }
        \leq
        C
        (z^{\frac 1 m} + \norm [\VectorSpace] \lambda + \JapaneseBracket \CompactGroup \mu)^{-m}
        L(\alpha, \beta, \gamma)
    \end{align*}
    where
    \begin{align*}
        L(\alpha, \beta, \gamma) \defeq
        (\norm [\VectorSpace] \lambda + \JapaneseBracket \CompactGroup \mu)^{-\rho \abs \alpha + \delta \abs \beta + \gamma}
        (\norm [\VectorSpace] \lambda + \JapaneseBracket \CompactGroup \nu)^{-\gamma}.
    \end{align*}

    Therefore,
    \begin{align*}
        &\abs {%
            \LeftDifferentialOperator \beta \DifferenceOperator \alpha
            F(\sigma)(g, \lambda)_{\mu_{m n}, \nu_{p q}}
        }\\
        &\ \leq C \oint_{\partial \Lambda}
        \abs \lambda^s
        (\abs z^{\frac 1 m} + \norm [\VectorSpace] \lambda + \JapaneseBracket \CompactGroup \mu)^{-m} L(\alpha, \beta, \gamma) \abs {\dd z}.
    \end{align*}

    It is clear that the above can be estimated by
    \begin{align*}
        \int_{\R^+} r^s (r^{\frac 1 m} + \norm \lambda + \JapaneseBracket \CompactGroup \mu) \ddr
        &\leq \int_{\R^+} ((\norm \lambda + \JapaneseBracket \CompactGroup \mu)^m r)^s (1 + r^{\frac 1 m})^{-m} \dd r\\
        &\leq (\norm \lambda + \JapaneseBracket \CompactGroup \mu)^{m s},
    \end{align*}
    where the inequality on the first line was obtained by substituting $r$ for $(\norm \lambda + \JapaneseBracket \CompactGroup \mu)^m r$,
    and the integrability of $r^s$ is guaranteed by $-1 < s < 0$.

    Going back to our original calculation,
    we then obtain that
    \begin{align*}
        &\abs {%
            \LeftDifferentialOperator \beta \DifferenceOperator \alpha
            F(\sigma)(g, \lambda)_{\mu_{m n}, \nu_{p q}}
        }\\
        &\ \leq C
        (\norm \lambda + \JapaneseBracket \CompactGroup \mu)^{m s}
        L(\alpha, \beta, \gamma),
    \end{align*}
    which by definition means that $F(\sigma) \in \SymbolClass {m s} {\rho, \delta}$.

    Naturally, if $s \leq -1$, the decay of $F$ is even better, so naturally the integral converges.
    We are thus only concerned with the symbol class estimates.
    Note that we have a determination of the logarithm on our contour,
    so we can define
    \begin{align*}
        G(z) \defeq F(z)^{\frac 1 {\Floor{-s} + 1}}
    \end{align*}
    and observe that
    \begin{align*}
        \abs {G(z)} \leq C \abs z^{\frac s {\Floor {-s} + 1}},
        \quad
        -1 < \frac s {\Floor {-s} + 1} < 0.
    \end{align*}

    By the first part of the proof,
    $G(\sigma) \in \SymbolClass {\frac {m s} {\Floor {-s} +1}} {\rho, \delta}$.
    We can now conclude by observing that
    \begin{align*}
        F(\sigma) = G(\sigma)^{\Floor {-s} + 1} \in \SymbolClass {m s} {\rho, \delta},
    \end{align*}
    where the inclusion in the symbol class above can only be obtained
    if the symbol is independent on $g$.
    When we have obtained the composition formula,
    note that this will hold for any symbol $\sigma$ satisfying the assumptions of the proof.
\end{proof}

\begin{corollary}
\label{corollary:powers_of_the_Laplacian}
    Let $\gamma \in \R$.
    The maps
    \begin{align*}
        &\lambda \in \VectorSpace \mapsto \Rep \lambda \BesselPotential \gamma\\
        &\lambda \in \VectorSpace \mapsto \Rep \lambda (\Laplacian)^\frac \gamma 2
    \end{align*}
    define symbols in $\SymbolClass \gamma {\rho, \delta}$.
\end{corollary}

The following result is central in our analysis

\begin{theorem}
    For each $t \in (0, 1]$,
    we let
    \begin{align*}
        \eta_t(\lambda) \defeq \e^{t \Rep \lambda (\Laplacian)}
    \end{align*}
    for each $\lambda \in \VectorSpace$.
    This defines a smoothing symbol in $\SmoothingSymbols$.
    Moreover, for each $m < 0$ and each $N \in \N$,
    there exists $C \geq 0$ such that
    \begin{align*}
        \SymbolSemiNorm m {\rho, \delta} N {\eta_t} \leq C t^\frac m 2
    \end{align*}

    If $0 < m \leq 4$,
    then for each $N \in \N$
    there exists $C \geq 0$ such that
    \begin{align*}
        \SymbolSemiNorm m {\rho, \delta} N {\Id {\Lebesgue 2 \CompactGroup} - \eta_t} \leq C t^\frac m 2
    \end{align*}
\end{theorem}
\begin{proof}
    In this proof, we consider the sector $\Lambda \defeq \R^-$,
    and observe that $\Rep \Lambda \Laplacian$ is parameter elliptic with respect to $\Lambda$.
    We also let $\Gamma$ be the boundary of $\Lambda \cup \{z \in \C : \abs z \leq \epsilon\}$.

    Let $m < 0$ and write $F_t(z) = {\e^{t z}}$.
    We observe that since
    \begin{align*}
        \abs {F_t(z)} \leq C \abs {t z}^\frac m 2,
        \quad z \in \Gamma.
    \end{align*}
    where $C$ does not depend on $t$.
    Theorem~\ref{theorem:functional_calculus} with~\eqref{eq:functional_calculus:bound_on_seminorm} imply that
    \begin{align*}
        \SymbolSemiNorm {m} {\rho, \delta} N {\eta_t}
        \leq C_{N, n, s} t^{\frac m 2}.
    \end{align*}

    Now let $0 < m \leq 4$ and let us check the second symbolic estimate.
    To this end,
    we let
    \begin{align*}
        G_t(z) \defeq (t z)^{-\frac m 2} (1 - \e^{t z})
    \end{align*}
    and observe that $\abs {G_t(z)} \leq C \abs {t z}^{-m/4}$ on $\Gamma$ where $C$ does not depend on $t \in (0, 1]$,
    because
    \begin{align*}
        \lim_{z \to 0} \frac {G_1(z)}{z^{-m / 4}}
        = \lim_{z \to 0} \frac {1 - \e^{t z}} {z^{m / 4}}
    \end{align*}
    exists and is finite by our condition on $m$.
    Using Theorem~\ref{theorem:functional_calculus} with~\eqref{eq:functional_calculus:bound_on_seminorm},
    we obtain
    \begin{align*}
        \SymbolSemiNorm {-m/2} {\rho, \delta} N {G_t(\Rep \lambda (\Laplacian))}
        \leq t^{-m/4}
    \end{align*}

    We can now conclude by Corollary~\ref{corollary:powers_of_the_Laplacian} that
    \begin{align*}
        \SymbolSemiNorm {m} {\rho, \delta } N {\Id {\Lebesgue 2 \CompactGroup} - \eta_t}
        &\leq
        \SymbolSemiNorm {-m/2} {\rho, \delta} {N'} {G_t(\Rep \lambda (\Laplacian))}
        \SymbolSemiNorm {m} {\rho, \delta} {N'} {\left(t \Rep \lambda (\Laplacian)\right)^{m/2}}\\
        &\leq C t^{-\frac m 4 + \frac m 2} = C t^\frac m 2.
    \end{align*}
\end{proof}

\section{Independence on the family of difference operators}

Note that in Definition~\ref{definition:symbol_classes},
we fixed a strongly admissible family of difference operators.
We now need to show that,
had we chosen a different family,
the resulting symbol classes would be identical.

\begin{proposition}
    Assume that $1 \geq \rho > \delta \geq 0$.
    Let $q' \in \SmoothFunctions \Group$ be a function which vanishes up to order $a$ at $e_\Group$.
    If $\sigma \in \SymbolClass m {\rho, \delta}$,
    then $\DifferenceOperator {q'} \sigma$ belongs to $\SymbolClass {m - \rho \abs \alpha} {\rho, \delta}$.
\end{proposition}
\begin{proof}
    Using a Taylor development at the origin,
    we know that for each $N \geq a$
    \begin{align*}
        q'(g) = \sum_{a \leq \abs \alpha \leq N} \TaylorLeftDifferentialOperator \alpha q'(e_\Group) q^\alpha(g) + \TaylorRemainder {q'} N {e_\Group}(g),
    \end{align*}
    where we used the fact that $q'$ vanishes up to order $a$.

    Using the Taylor remainder theorem,
    it follows that $\TaylorRemainder {q'} N {e_\Group}$ has a zero of order $N + 1$ at the origin $e_\Group$.
    % TODO Ask Michael how to conclude
\end{proof}

\begin{lemma}
    Let $q, q' \in \SmoothFunctions \Group$ be two smooth functions such that $q / q'$ extends smoothly to a function in $\SmoothFunctions \Group$.
    It follows that if
    \begin{align*}
        \norm [\Lin {\Lebesgue 2 \Group}] {\Rep \lambda \BesselPotential s \DifferenceOperator q \sigma(\lambda)}
        < \infty
    \end{align*}
    for a certain $s \in \R$ and a map $\sigma \in \Fourier(\TemperedDistributions \Group)$,
    then there exists $C = C_{q, q', s} \geq 0$ such that
    \begin{align*}
        \norm [\Lin {\Lebesgue 2 \Group}] {\Rep \lambda \BesselPotential s \DifferenceOperator {q'} \sigma(\lambda)}
        \leq C
        \norm [\Lin {\Lebesgue 2 \Group}] {\Rep \lambda \BesselPotential s \DifferenceOperator q \sigma(\lambda)}.
    \end{align*}
\end{lemma}
\begin{proof}
    Let $T$ and $T'$ be the operators defined via
    \begin{align*}
        T \phi(g) \defeq \int_\Group \phi(h) (q \kappa)(h^{-1} g) \dd h,\\
        T' \phi(g) \defeq \int_\Group \phi(h) (q' \kappa)(h^{-1} g) \dd h,
    \end{align*}
    where the integrals are interpreted distributionaly,
    $\phi \in \Schwartz \Group$ and $g \in \Group$.

    Using our assumption,
    it follows that after letting
    \begin{align*}
        \psi_g(h) = \frac {q'} q(h^{-1} g),
    \end{align*}
    we obtain
    \begin{align*}
        T' \phi(g) = \int_\Group \phi(h) \psi_g(h) (q \kappa)(h^{-1} g) \dd h = T(\phi \psi_g)(g).
    \end{align*}

    \begin{align*}
        \norm [\Lebesgue 2 \Group] {T' \phi}^2
        &\leq \int_\Group \sup_{g_1 \in \Group} \abs{T (\phi \psi_{g_1})(g)}^2 \dd g\\
        &\leq \int_\Group \int_\Group \abs{T (\phi \BesselPotential \gamma_{g_1} \psi_{g_1})(g)}^2 \dd g_1 \dd g
    \end{align*}

    Using Fubini's theorem
    and the fact that $T \in \Lin{\Lebesgue 2 \Group, \Sobolev s}$,
    we obtain
    \begin{align*}
        \norm [\Lebesgue 2 \Group] {T' \phi}^2
        &\leq \int_\Group \int_\Group \abs{T (\phi \BesselPotential \gamma_{g_1} \psi_{g_1})(g)}^2 \dd g \dd g_1\\
        &\leq \norm [\Lin {\Lebesgue 2 \Group, \Sobolev s}] {T} \int_\Group \norm [\Sobolev s] {\phi \BesselPotential \gamma_{g_1} \psi_{g_1}}^2 \dd g_1
    \end{align*}
    % TODO Conclude
\end{proof}

%\section{Link with the H\"ormander classes}
%
%\begin{definition}[Rotation of symbols]
%    Let $\tilde \sigma \in \SymbolClass[\GroupDirect]{m}{\rho, \delta}$.
%    We define the operator
%    \begin{align*}
%        \Rotation {\tilde \sigma} : \SmoothFunctions \CompactGroup \to \SmoothFunctions \CompactGroup
%    \end{align*}
%    via the formula
%    \begin{align*}
%        \Rotation {\tilde \sigma}(x, k; \lambda) F(u) \defeq \tilde \sigma(x, k; k u^{-1} \lambda) F(u),
%    \end{align*}
%    where $x, \lambda \in \VectorSpace$, $k, u \in \CompactGroup$, and $F \in \SmoothFunctions \CompactGroup$.
%
%    Similarly, given $\sigma \in \SymbolClass m {\rho, \delta}$,
%    we define the operator
%    \begin{align*}
%        \InverseRotation \sigma : \SmoothFunctions \CompactGroup \to \SmoothFunctions \CompactGroup
%    \end{align*}
%    via the formula
%    \begin{align*}
%        \InverseRotation \sigma (x, k; \lambda) F(u) \defeq \sigma(x, k; u k^{-1} \lambda) F(u),
%    \end{align*}
%    where again $x, \lambda \in \VectorSpace$, $k, u \in \CompactGroup$, and $F \in \SmoothFunctions \CompactGroup$.
%\end{definition}
%
%\begin{lemma}
%\label{lemma:Y_derivative_on_lambda_variable_of_symbols}
%    Let $Y \in \LieAlgebraCompactGroup$, $\sigma \in \SymbolClass m {\rho, \delta}$, $\tilde \sigma \in \SymbolClass[\GroupDirect] m {\rho, \delta}$.
%    We have the following expression
%    \begin{align*}
%        \LeftDifferentialOperatorFirstOrder Y_l \sigma(x, k; l \lambda)
%        &= \sum_{j = 1}^{\dim \VectorSpace} \DifferenceOperator{j} \sigma(x, k; l \lambda) \Rep {l Y \lambda} (X_j)\\
%        \LeftDifferentialOperatorFirstOrder Y_l \tilde \sigma(x, k; l \lambda)
%        &= \sum_{j = 1}^{\dim \VectorSpace} \DifferenceOperator[\VectorSpace]{j} \tilde \sigma(x, k; l \lambda) \Rep[\GroupDirect] {l Y \lambda} (\partial_j),
%    \end{align*}
%    where $(x, k) \in \GroupDirect$, $\lambda \in \VectorSpace$ and $l \in \CompactGroup$.
%\end{lemma}
%\begin{proof}
%    By definition, we know that
%    \begin{align*}
%        \LeftDifferentialOperatorFirstOrder Y_l \sigma(x, k; l \lambda)
%        &= \eval{\D*{1}{t}}{t = 0} \sigma(x, k; l \exp_\CompactGroup (t Y) \lambda),
%    \end{align*}
%    which after applying the chain rule, becomes
%    \begin{align}
%        &\LeftDifferentialOperatorFirstOrder Y_l \sigma(x, k; l \lambda) \notag\\
%        &\quad = \sum_{j = 1}^{\dim \VectorSpace} \eval{\D*{1}{s}}{s = 0} \sigma(x, k; l \lambda + s u e_j) \eval{\D*{1}{t}}{t = 0} \ip {l \exp_\CompactGroup (t Y) \lambda} {u e_j}.
%        \label{eq:k_differentiation_of_lambda_variable_in_symbol}
%    \end{align}
%
%    Now, we observe that
%    \begin{align*}
%        \eval{\D*{1}{t}}{t = 0} \ip {l \exp_\CompactGroup (t Y) \lambda} {u e_j}
%        = \ip {l Y \lambda} {u e_j} = \frac{1}{\i \turn} \Rep {l Y \lambda} (X_j),
%    \end{align*}
%    while at the same time
%    \begin{align*}
%        \eval{\D*{1}{s}}{s = 0} \sigma(x, k; l \lambda + s u e_j)
%        = \i \turn \DifferenceOperator{j} \sigma(x, k; l \lambda).
%    \end{align*}
%
%    Therefore, it follows that~\eqref{eq:k_differentiation_of_lambda_variable_in_symbol} becomes
%    \begin{align*}
%        \LeftDifferentialOperatorFirstOrder Y_l \sigma(x, k; l \lambda)
%        = \sum_{j = 1}^{\dim \VectorSpace} \DifferenceOperator{j} \sigma(x, k; l \lambda) \Rep {l Y \lambda} (X_j).
%    \end{align*}
%
%    Now, we turn to the case of symbols on the direct product.
%    Again, we start with
%    \begin{align*}
%        \LeftDifferentialOperatorFirstOrder Y_l \tilde \sigma(x, k; l \lambda)
%        &= \eval{\D*{1}{t}}{t = 0} \tilde \sigma(x, k; l \exp_\CompactGroup (t Y) \lambda).
%    \end{align*}
%    Applying the chain rule, we obtain
%    \begin{align}
%        \LeftDifferentialOperatorFirstOrder Y_l \tilde \sigma(x, k; l \lambda)
%        &= \sum_{j = 1}^{\dim \VectorSpace} \eval{\D*{1}{s}}{s = 0} \tilde \sigma(x, k; l \lambda + s e_j) \eval{\D*{1}{t}}{t = 0} \ip {l \exp_\CompactGroup (t Y) \lambda} {e_j}.
%        \label{eq:k_differentiation_of_lambda_variable_in_symbol_2}
%    \end{align}
%
%    By definition, it is clear that
%    \begin{align*}
%        \DifferenceOperator[\VectorSpace]{j} \tilde \sigma(x, k; l \lambda) = \frac 1 {\i \turn} \D{1}[\tilde \sigma]{{\lambda_j} } (x, k, l \lambda),
%    \end{align*}
%    while
%    \begin{align*}
%        \eval{\D*{1}{t}}{t = 0} \ip {l \exp_\CompactGroup (t Y) \lambda} {e_j}
%        &= \ip {l Y \lambda} {e_j}
%        = \frac{1}{\i \turn} \Rep[\GroupDirect] {l Y \lambda} (\partial_j).
%    \end{align*}
%
%    Therefore, it follows that \eqref{eq:k_differentiation_of_lambda_variable_in_symbol_2} becomes
%    \begin{align}
%        \LeftDifferentialOperatorFirstOrder Y_l \tilde \sigma(x, k; l \lambda)
%        &= \sum_{j = 1}^{\dim \VectorSpace} \DifferenceOperator[\VectorSpace]{j} \tilde \sigma(x, k; l \lambda) \Rep[\GroupDirect] {l Y \lambda} (\partial_j).
%    \end{align}
%\end{proof}
%
%\begin{lemma}
%\label{lemma:link_between_symbols}
%    Let $\sigma$ and $\tilde \sigma$ be symbols on $\Group$ and $\GroupDirect$ respectively be such that
%    \begin{align*}
%        \Op[\Group] (\sigma) = \Op[\GroupDirect] (\tilde \sigma).
%    \end{align*}
%    \begin{enumerate}
%        \item
%            \label{item:action_of_difference_operators}
%            If $q \in \SmoothFunctions \Group$,
%            then defining $\tilde q(y, l) = q(l y, l)$ yields
%            \begin{align*}
%                \DifferenceOperator{q} \sigma = \Rotation {\DifferenceOperator[\GroupDirect]{\tilde q} \tilde \sigma}
%                \quad \text{and} \quad
%                \DifferenceOperator[\GroupDirect]{\tilde q} \tilde \sigma = \InverseRotation {\DifferenceOperator{q} \sigma}.
%            \end{align*}
%            In particular, $\sigma = \Rotation {\tilde \sigma}$ and $\tilde \sigma = \InverseRotation \sigma$.
%        \item
%            \label{item:action_of_Euclidean_derivative}
%            If $X \in \LieAlgebra \cap \VectorSpace$, then
%            \begin{align*}
%                \LeftDifferentialOperatorFirstOrder{X} \sigma
%                = \Rotation {\LeftDifferentialOperatorFirstOrder{X} \tilde \sigma}
%                \quad \text{and} \quad
%                \LeftDifferentialOperatorFirstOrder{X} \tilde \sigma
%                = \InverseRotation {\LeftDifferentialOperatorFirstOrder{X} \sigma}.
%            \end{align*}
%        \item
%            \label{item:action_of_K-derivative}
%            If $Y \in \LieAlgebraCompactGroup$, we have
%            \begin{align*}
%                \LeftDifferentialOperatorFirstOrder{Y} \sigma(x, k; \lambda)
%                &= \Rotation {
%                    \LeftDifferentialOperatorFirstOrder{Y} \tilde \sigma
%                    + \sum_{j = 1}^{\dim \VectorSpace} (\DifferenceOperator[\VectorSpace]{j} \tilde \sigma) \Rep[\GroupDirect] {k Y k^{-1} \lambda} (\partial_j)
%                }(x, k; \lambda)\\
%                \LeftDifferentialOperatorFirstOrder Y \tilde \sigma(x, k; \lambda)
%                &= \InverseRotation {\LeftDifferentialOperatorFirstOrder Y \sigma
%                - \sum_{j = 1}^{\dim \VectorSpace} \DifferenceOperator{j} \sigma \ \Rep \lambda (Y^t X_j)
%                }(x, k; \lambda).
%            \end{align*}
%    \end{enumerate}
%\end{lemma}
%\begin{proof}
%    Let us write $T = \Op (\sigma)$.
%    It follows that by
%    % TODO: Reference both quantisations
%    \begin{align*}
%        T \phi(x, k)
%        &= \int_{\GroupDirect} \phi(y, l) {\tilde \kappa}_{x, k}(x - y, l^{-1} k) \dd (y, l)\\
%        &= \int_{\GroupDirect} \phi(y, l) {\kappa}_{x, k}({(y, l)}^{-1} (x, k)) \dd (y, l)
%    \end{align*}
%    in the sense of distributions.
%    Therefore, it follows that we have
%    \begin{align}
%        {\tilde \kappa}_{x, k}(x - y, l^{-1} k) =
%        {\kappa}_{x, k}({(y, l)}^{-1} (x, k)),
%        \label{eq:link_between_the_kernels}
%    \end{align}
%    again in the sense of distributions.
%
%    \begin{enumerate}
%        \item
%            Suppose first that $\sigma \in \SymbolClass m {\rho, \delta}$ for $m < -\dim \Group$
%            so that its kernel $\kappa_{x, k} \in \Schwartz \Group$ by Theorem~\ref{theorem:kernel_estimates}.
%
%            By definition, $\DifferenceOperator{q} \sigma(x, k; \lambda)$ is equal to
%            \begin{align*}
%                &\quad \int_\Group q((y, l)^{-1}) \kappa_{x, k}((y, l)^{-1}) \e^{\i \turn \ip {u^{-1} \lambda} y} \RightRegularRepresentation(l) \dd (y, l)\\
%                &= \int_\Group q((y, l)^{-1} (x, k)) \kappa_{x, k}((y, l)^{-1} (x, k))\\
%                &\qquad \qquad \e^{\i \turn \ip {u^{-1} \lambda} {k^{-1} (y - x)}} \RightRegularRepresentation(k^{-1} l) \dd (y, l)
%            \end{align*}
%            where we substituted $(y, l)$ for $(x, k)^{-1} (y, l)$ to obtain the last line.
%
%            Using
%            \begin{align*}
%                (y, l)^{-1} (x, k) = (l^{-1}(x - y), l^{-1} k)
%            \end{align*}
%            and~\eqref{eq:link_between_the_kernels},
%            if follows that $\DifferenceOperator{q} \sigma(x, k; \lambda)$ becomes
%            \begin{align*}
%                \int_\Group q(l^{-1}(x - y), l^{-1} k) \tilde \kappa_{x, k}(x - y, l^{-1} k) \e^{\i \turn \ip {k u^{-1} \lambda} {(y - x)}} \RightRegularRepresentation(k^{-1} l) \dd (y, l).
%            \end{align*}
%
%            We can now substitute $y$ for $y + x$ and $l$ for $k l$ to obtain that
%            \begin{align*}
%                &\DifferenceOperator{q} \sigma(x, k; \lambda) F(u) =\\
%                &\quad \int_\Group q(-l^{-1} y, l^{-1}) \tilde \kappa_{x, k}(-y, l^{-1}) \e^{\i \turn \ip {k u^{-1} \lambda} y} \RightRegularRepresentation(l) \dd (y, l) F(u)
%            \end{align*}
%            which we recognise to be exactly $\DifferenceOperator {\tilde q} \tilde \sigma(x, k, k u^{-1} \lambda) F(u)$.
%            Therefore, we have shown that
%            \begin{align*}
%                \DifferenceOperator{q} \sigma(x, k; \lambda) F(u)
%                = \DifferenceOperator {\tilde q} \tilde \sigma(x, k, k u^{-1} \lambda) F(u),
%            \end{align*}
%            or in other words $\DifferenceOperator q \sigma = \Rotation {\DifferenceOperator[\GroupDirect] {\tilde q} \tilde \sigma}$.
%
%            Now, suppose that $m \geq -\dim \Group$.
%            Setting
%            \begin{align*}
%                \gamma \defeq -\dim \Group - 1 - m.
%            \end{align*}
%            Since $\Rep \lambda \BesselPotential \gamma \sigma$ is a symbol of order $< -\dim \Group$,
%            then by the adove, we have
%            \begin{align*}
%                \Rep \lambda \BesselPotential \gamma \sigma
%                = \Rotation {\Rep \lambda \BesselPotential \gamma \tilde \sigma}
%                = \Rep \lambda \BesselPotential \gamma \Rotation {\tilde \sigma},
%            \end{align*}
%            or in other words $\sigma = \Rotation {\tilde \sigma}$.
%            % TODO Conclude for difference operators
%
%            The other identity is proven by observing that $\InverseRotation \dummy$ is the inverse of $\Rotation \dummy$.
%        \item
%            This identity follows easily from the previous point.
%        \item
%            Applying $\LeftDifferentialOperatorFirstOrder Y$ on both sides of $\sigma = \Rotation {\tilde \sigma}$,
%            we obtain
%            \begin{align}
%                \LeftDifferentialOperatorFirstOrder Y_k \sigma(x, k; \lambda)
%                &= \LeftDifferentialOperatorFirstOrder Y_{k' = k} \tilde \sigma(x, k'; k u^{-1} \lambda) + \LeftDifferentialOperatorFirstOrder Y_{k' = k} \tilde \sigma(x, k; k' u^{-1} \lambda)\\
%                &= \Rotation {\LeftDifferentialOperatorFirstOrder Y \tilde \sigma}(x, k; \lambda) + \LeftDifferentialOperatorFirstOrder Y_{k' = k} \tilde \sigma(x, k; k' u^{-1} \lambda).
%                \label{eq:Y_derivative_of_rotated_symbol_on_direct_product}
%            \end{align}
%
%            The second term on the right-hand side can be computed via Lemma \ref{lemma:Y_derivative_on_lambda_variable_of_symbols} to be
%            \begin{align*}
%                \LeftDifferentialOperatorFirstOrder Y_{k' = k} \tilde \sigma(x, k; k' u^{-1} \lambda)
%                &= \sum_{j = 1}^{\dim \VectorSpace} \DifferenceOperator[\VectorSpace]{j} \tilde \sigma(x, k; k u^{-1} \lambda) \Rep[\GroupDirect]{k Y u^{-1} \lambda} (\partial_j)\\
%                &= \sum_{j = 1}^{\dim \VectorSpace} \DifferenceOperator[\VectorSpace]{j} \tilde \sigma(x, k; k u^{-1} \lambda) \Rep[\GroupDirect]{k Y k^{-1} (k u^{-1} \lambda)} (\partial_j)\\
%                &= \sum_{j = 1}^{\dim \VectorSpace} \Rotation {\DifferenceOperator[\VectorSpace]{j} \tilde \sigma} (x, k; \lambda) \Rotation {\Rep[\GroupDirect]{k Y k^{-1} \lambda} (\partial_j)}.
%            \end{align*}
%
%            Plugging the above into \eqref{eq:Y_derivative_of_rotated_symbol_on_direct_product}, we obtain
%            \begin{align*}
%                \LeftDifferentialOperatorFirstOrder Y \sigma(x, k; \lambda)
%                &= \Rotation {\LeftDifferentialOperatorFirstOrder Y \tilde \sigma}(x, k; \lambda)
%                + \sum_{j = 1}^{\dim \VectorSpace} \Rotation {\DifferenceOperator[\VectorSpace]{j} \tilde \sigma \ \Rep[\GroupDirect]{k Y k^{-1} \lambda} (\partial_j)}(x, k; \lambda)\\
%                &= \Rotation {\LeftDifferentialOperatorFirstOrder Y \tilde \sigma
%                    + \sum_{j = 1}^{\dim \VectorSpace} \DifferenceOperator[\VectorSpace]{j} \tilde \sigma \ \Rep[\GroupDirect]{k Y k^{-1} \lambda} (\partial_j)
%                }(x, k; \lambda),
%            \end{align*}
%            which is what we wanted to show.
%
%            To show the second identity,
%            we apply $\LeftDifferentialOperatorFirstOrder Y$ on both sides of $\tilde \sigma = \InverseRotation {\sigma}$ to obtain
%            \begin{align*}
%                \LeftDifferentialOperatorFirstOrder Y_k \tilde \sigma(x, k; \lambda)
%                = \LeftDifferentialOperatorFirstOrder Y_{k' = k} \sigma(x, k'; u k^{-1} \lambda) + \LeftDifferentialOperatorFirstOrder Y_{k' = k} \sigma(x, k; u {k'}^{-1} \lambda) \notag\\
%                = \InverseRotation {\LeftDifferentialOperatorFirstOrder Y \sigma}(x, k; \lambda) - \LeftDifferentialOperatorFirstOrder Y_{u} \tilde \sigma(x, k; u k^{-1} \lambda).
%                \label{eq:Y_derivative_of_rotated_symbol_on_semi-direct_product}
%            \end{align*}
%
%            Using Lemma~\ref{lemma:Y_derivative_on_lambda_variable_of_symbols} again to compute the second term of the right-hand side,
%            \begin{align*}
%                \LeftDifferentialOperatorFirstOrder Y_u \tilde \sigma(x, k; u k^{-1} \lambda)
%                &= \sum_{j = 1}^{\dim \VectorSpace} \DifferenceOperator{j} \sigma (x, k; u k^{-1} \lambda) \Rep {u Y k \lambda} (X_j)\\
%                &= \sum_{j = 1}^{\dim \VectorSpace} \DifferenceOperator{j} \sigma (x, k; u k^{-1} \lambda) \Rep {u Y u^{-1} u k \lambda} (X_j)\\
%                &= \sum_{j = 1}^{\dim \VectorSpace} \InverseRotation {\DifferenceOperator{j} \sigma \Rep {u Y u^{-1} \lambda} (X_j)}.
%            \end{align*}
%
%            Observing that in the above,
%            \begin{align*}
%                \Rep {u Y u^{-1} \lambda} (X_j)
%                = \i \turn \ip {u Y u^{-1} \lambda} {u X_j}
%                = \i \turn \ip {\lambda} {u Y^t X_j}
%                = \Rep \lambda (Y^t X_j)
%            \end{align*}
%            so that \eqref{eq:Y_derivative_of_rotated_symbol_on_direct_product} becomes
%            \begin{align*}
%                \LeftDifferentialOperatorFirstOrder Y_k \tilde \sigma(x, k; \lambda)
%                = \InverseRotation {\LeftDifferentialOperatorFirstOrder Y \sigma
%                - \sum_{j = 1}^{\dim \VectorSpace} \DifferenceOperator{j} \sigma \ \Rep \lambda (Y^t X_j)
%                }(x, k; \lambda),
%            \end{align*}
%            concluding the proof.
%    \end{enumerate}
%\end{proof}
%
%\begin{lemma}
%\label{lemma:inclusion_in_zero_class}
%    Let $m \defeq \frac {-\dim \CompactGroup} 2 (1 - \rho)$.
%    % TODO: Can we prove the result for $m = 0$ or improve?
%    \begin{enumerate}
%        \item
%            If $\sigma \in \SymbolClass m {\rho, \delta}$,
%            then $\tilde \sigma = \InverseRotation \sigma$ satisfies
%            \begin{align*}
%                \sup_{(x, k) \in \Group} \esssup_{\lambda \in \VectorSpace}
%                \norm [\Lin {\Lebesgue 2 \CompactGroup}] {\tilde \sigma(x, k; \lambda)} < \infty.
%            \end{align*}
%        \item
%            If $\tilde \sigma \in \SymbolClass [\GroupDirect] m {\rho, \delta}$,
%            then $\sigma = \Rotation {\tilde \sigma}$ satisfies
%            \begin{align*}
%                \sup_{(x, k) \in \Group} \esssup_{\lambda \in \VectorSpace}
%                \norm [\Lin {\Lebesgue 2 \CompactGroup}] {\sigma(x, k; \lambda)} < \infty.
%            \end{align*}
%    \end{enumerate}
%\end{lemma}
%\begin{proof}
%    Let $F \in \Lebesgue 2 \CompactGroup$ and $u \in \CompactGroup$.
%    By the Sobolev Inequality,
%    we know that
%    \begin{align*}
%        \int_\CompactGroup \sup_{v \in \CompactGroup} \abs {\sigma(x, k; v \lambda) F(u)}^2 \dd u
%        \leq C \sum_{\beta} \int_\CompactGroup \int_\CompactGroup \abs{Y^\beta_v \sigma(x, k; v \lambda) F(u)}^2 \dd v \dd u
%    \end{align*}
%    Using Lemma~\ref{lemma:Y_derivative_on_lambda_variable_of_symbols},
%    we know that each $Y^\beta_v \sigma \in \SymbolClass {m + \abs \beta (1 - \rho)} {\rho, \delta} \subset \SymbolClass 0 {\rho, \delta}$ so that the above becomes
%    \begin{align*}
%        \sup_{(x, k) \in \Group} \esssup_{\lambda \in \VectorSpace}
%        \int_\CompactGroup \sup_{v \in \CompactGroup} \abs {\sigma(x, k; v \lambda) F(u)}^2 \dd u
%        \leq C \norm [\Lebesgue 2 \CompactGroup] {F}^2.
%    \end{align*}
%
%    From the above inequality, we easily derive that
%    \begin{align*}
%        \sup_{(x, k) \in \Group}& \esssup_{\lambda \in \VectorSpace} \norm [\Lebesgue 2 \CompactGroup] {\tilde \sigma(x, k; \lambda) F}^2\\
%        &= \sup_{(x, k) \in \Group} \esssup_{\lambda \in \VectorSpace} \int_\CompactGroup \abs {\sigma(x, k; u k^{-1} \lambda) F(u)}^2 \dd u\\
%        &\leq \sup_{(x, k) \in \Group} \esssup_{\lambda \in \VectorSpace} \int_\CompactGroup \sup_{v \in \CompactGroup} \abs {\sigma(x, k; v \lambda) F(u)}^2 \dd u\\
%        &\leq C \norm [\Lebesgue 2 \CompactGroup] {F}^2,
%    \end{align*}
%    which concludes the proof.
%
%    The second bound is obtained with an identical argument.
%\end{proof}
%
%\begin{theorem}
%    Let $\delta' = \max \{\delta, 1 - \rho\}$ and $m' = m + \frac {\dim \CompactGroup} 2 (1 - \rho)$.
%
%    \begin{enumerate}
%        \item
%            For each $\sigma \in \SymbolClass m {\rho, \delta}$,
%            the symbol $\tilde \sigma = \InverseRotation \sigma$ belongs to $\SymbolClass [\GroupDirect] {m'} {\rho, \delta'}$
%            and satisfies
%            \begin{align*}
%                \Op[\Group] (\sigma) = \Op[\GroupDirect] (\tilde \sigma).
%            \end{align*}
%        \item
%            Reciprocally, for each $\tilde \sigma \in \SymbolClass [\GroupDirect] m {\rho, \delta}$,
%            the symbol $\sigma = \Rotation {\tilde \sigma}$ belongs to $\SymbolClass {m'} {\rho, \delta'}$
%            and satisfies
%            \begin{align*}
%                \Op[\GroupDirect] (\tilde \sigma) = \Op[\Group] (\sigma).
%            \end{align*}
%    \end{enumerate}
%
%    In particular, if $\rho = 1$, the symbol classes coincide
%    \begin{align*}
%        \SymbolClass m {1, \delta} = \SymbolClass [\GroupDirect] m {1, \delta}.
%    \end{align*}
%\end{theorem}
%\begin{proof}
%    Let us prove the first claim,
%    as the proof of the second uses an identical argument.
%
%    Let $\sigma \in \SymbolClass m {\rho, \delta}$,
%    and write $\tilde \sigma \defeq \InverseRotation \sigma$.
%
%    \begin{claim}
%        Given $\tilde{q} \in \CompactGroup$ and $\beta \in \N^{\dim \Group}$,
%        there exists a symbol $\tau \in \SymbolClass {m - \rho \order(q) + \delta' \abs \beta} {\rho, \delta'}$ such that
%        \begin{align*}
%            \DifferenceOperator [\GroupDirect] {\tilde q} X^\beta \tilde \sigma = \InverseRotation \tau.
%        \end{align*}
%    \end{claim}
%    \begin{proof}[Proof of the claim]
%        Let us prove the claim by induction on $\abs \beta$.
%        The initial case $\beta = 0$ follows easily from Lemma~\ref{lemma:link_between_symbols} (\ref{item:action_of_difference_operators})
%        and the inclusion
%        \begin{align*}
%            \SymbolClass {m - \rho \order(q)} {\rho, \delta} \subset \SymbolClass {m - \rho \order(q)} {\rho, \delta'}.
%        \end{align*}
%
%        Now, let us assume the claim holds for a certain $\beta$,
%        so that there exists $\tau \in \SymbolClass {m - \rho \order(q) + \delta' \abs \beta} {\rho, \delta'}$ such that
%        \begin{align*}
%            \DifferenceOperator [\GroupDirect] {\tilde q} X^\beta \tilde \sigma = \InverseRotation \tau.
%        \end{align*}
%
%        If $X \in \LieAlgebra \cap \VectorSpace$,
%        then by (\ref{item:action_of_Euclidean_derivative}) of Lemma~\ref{lemma:link_between_symbols} we have
%        \begin{align*}
%            \DifferenceOperator [\GroupDirect] {\tilde q} X X^\beta \tilde \sigma = \InverseRotation {X \tau},
%        \end{align*}
%        where $X \tau \in \SymbolClass {m - \rho \order(q) + \delta' (\abs \beta + 1)} {\rho, \delta'}$.
%
%        If $X \in \LieAlgebraCompactGroup$,
%        then by (\ref{item:action_of_K-derivative}) of Lemma~\ref{lemma:link_between_symbols} we have
%        \begin{align*}
%            \DifferenceOperator [\GroupDirect] {\tilde q} X X^\beta \tilde \sigma = \InverseRotation {X \tau - \sum_{j = 1}^{\dim \VectorSpace} \DifferenceOperator{j} \tau \ \Rep {\lambda} (X^t X_j) }
%        \end{align*}
%        where $X \tau - \sum_{j = 1}^{\dim \VectorSpace} \DifferenceOperator{j} \tau \ \Rep {\lambda} (X^t X_j) \in \SymbolClass {m - \rho \order(q) + \delta' (\abs \beta + 1)} {\rho, \delta'}$.
%        To see this,
%        we observe the condition $\delta' \geq 1 - \rho$ implies that $X \tau$ is the term with higher order.
%
%        Either way, this concludes the induction, and thus the proof of the claim.
%    \end{proof}
%
%    By our claim,
%    there exists a symbol $\tau \in \SymbolClass {m - \rho \order(q) + \delta' \abs \beta} {\rho, \delta'}$ such that
%    \begin{align*}
%        \DifferenceOperator [\GroupDirect] {\tilde q} X^\beta \tilde \sigma = \InverseRotation \tau.
%    \end{align*}
%
%    Note that the above implies that
%    \begin{align*}
%        \Rep[\GroupDirect] \lambda \BesselPotential{-m' + \rho \order(q) - \delta' \abs \beta + \gamma} \DifferenceOperator [\GroupDirect] {\tilde q} X^\beta \tilde \sigma(x, k; \lambda) \Rep [\GroupDirect] \lambda \BesselPotential{-\gamma}\\
%        = \InverseRotation {\Rep \lambda \BesselPotential{-m' + \rho \order(q) - \delta' \abs \beta + \gamma} \tau \Rep \lambda \BesselPotential{-\gamma}} (x, k; \lambda).
%    \end{align*}
%
%    Since the operator inside $\InverseRotation \dummy$ on the second line belongs to
%    \begin{align*}
%        \SymbolClass {-\frac {\dim \CompactGroup} 2 (1 - \rho) } {\rho, \delta'},
%    \end{align*}
%    then Lemma~\ref{lemma:inclusion_in_zero_class} implies that
%    \begin{align*}
%        &\sup_{g \in \GroupDirect} \esssup_{\lambda \in \VectorSpace}\\
%        &\quad
%        \norm [\Lin {\Lebesgue 2 \CompactGroup}] {%
%            \Rep[\GroupDirect] \lambda \BesselPotential{-m' + \rho \abs \alpha  - \delta' \abs \beta} \DifferenceOperator [\GroupDirect] {\tilde q} X^\beta \tilde \sigma(x, k; \lambda) \Rep [\GroupDirect] \lambda
%        }
%        % TODO: show the direct product doesn't require the gamma trick
%    \end{align*}
%    is finite,
%    which by definition means that $\tilde \sigma \in \SymbolClass [\GroupDirect] {m'} {\rho, \delta'}$.
%\end{proof}

%\section{Littlewood-Paley decomposition}
%
%\begin{lemma}
%\label{lemma:derivatives_of_radial_functions}
%    Let $\alpha \in \N^n$,
%    and fix a radial function $\chi \in \SmoothFunctions{\R^n}$.
%    If $\alpha \in \N^n$, then
%    \begin{align}
%        \D{\abs \alpha}[\chi]{x^\alpha}(x)
%        = \sum_{r = 1}^{C_\alpha} f_r(\norm[\R^n]{x}) P_r(x),
%    \end{align}
%    where $P_r$ is a polynomial depending only on $\alpha$.
%
%    Moreover, if $\supp \chi$ is compact
%    and if there exists $\delta > 0$ such that the radial derivative $\D{\abs \alpha}[\chi]{\lambda}$ vanishes on on $\Ball[\R^n]{0}{\delta}$,
%    then we have
%    \begin{align*}
%        \sup_r \sup_{\lambda \in \R^+} \abs{f_r} < \infty
%    \end{align*}
%\end{lemma}
%\begin{proof}
%    Using the chain rule, we know that for a purely radial function $f$
%    \begin{align}
%        \D{1}[f]{{x_i} } = \D{1}[\lambda]{{x_i} } \D{1}[f]{\lambda} = \frac{\D{1}[f]{\lambda}}{\norm[\R^n]{x}} x_i.
%    \end{align}
%
%    We know proceed to show the claim by induction on $\alpha$.
%    The result is clearly true when $\abs{\alpha} = 0$.
%    If we assume it is true for some $\alpha \in \N^n$, then by the above,
%    \begin{align}
%        \D{\abs \alpha + 1}[\chi]{{x_i} , x^\alpha}(x)
%        &= \D{1}{{x_i} } \sum_{r = 1}^{C_\alpha} f_r(\norm[\R^n]{x}) P_r(x)\\
%        &= \sum_{r = 1}^{C_\alpha} \frac{\D{1}[f_r]{\lambda}}{\norm[\R^n]{x}}(\norm[\R^n]{x}) x_i P_r(x)
%        + \sum_{r = 1}^{C_\alpha} f_r(\norm[\R^n]{x}) \D{1}[P_r]{{x_i} }(x),
%    \end{align}
%    which concludes the proof.
%\end{proof}
%
%\begin{lemma}
%\label{lemma:left_regular_representation_of_polynomials}
%    Let $P \in \SmoothFunctions{\dualGroup{\VectorSpace}}$ be a polynomial.
%    We can find functions $q_i \in \Polynomials{\CompactGroup}$, $f_i \in \Lebesgue{2}{\dualGroup{\VectorSpace}}$, $i = 1, \cdots, N$ such that
%    \begin{align*}
%        P(k \lambda) = \sum_{i = 1}^N q_i(k) f_i(\lambda)
%    \end{align*}
%    for each $k \in \CompactGroup$ and each $\lambda \in \dualGroup{\VectorSpace}$.
%
%    Moreover, the $q_i$ satisfy the bound
%    \begin{align*}
%        \sup_i \sup_\CompactGroup \abs{q_i} < \infty.
%    \end{align*}
%\end{lemma}
%
%The singularities of the kernel associated with a smooth symbol
%arise from the behaviour of the latter at high frequencies,
%as illustrated by the Euclidean or compact case.
%Therefore, an idea would be to cut off those high frequencies.
%
%\begin{theorem}
%\label{theorem:generalised_Littlewood-Paley_decomposition}
%    Let $\chi \in \SmoothFunctions {\R^+}$ be a positive bounded smooth function.
%
%    For each $\epsilon \in (0, 1]$,
%    we let
%    \begin{align*}
%        \eta_\epsilon(\lambda)
%        \defeq
%        \bigoplus_{\tau \in \dualGroup \CompactGroup} \chi(\epsilon(\JapaneseBracket \CompactGroup \tau^2 + \norm {\turn \lambda}^2)^{\frac 1 2}) \Id {V_\tau},
%    \end{align*}
%    where $V_\tau \defeq \Span \{\tau_{i j} \in \Lebesgue 2 \CompactGroup : 1 \leq i, j \leq \dimRep \tau\}$.
%
%    For each $\epsilon \in (0, 1]$,
%    $\eta_\epsilon$ is a symbol in $\SymbolClass 0 {1, 0}$,
%    and the following properties hold.
%
%    \begin{enumerate}
%        \item \label{item:generalised_Littlewood-Paley_decomposition:negative_m}
%            If $\chi$ has compact support, then $\eta_\epsilon \in \SmoothingSymbols$ for each $\epsilon \in (0, 1]$.
%            Moreover, for each $m \leq 0$ and each $N \in \N$,
%            there exists $C_{m, N} \geq 0$ such that
%            \begin{align*}
%                \SymbolSemiNorm m {\rho, \delta} N {\eta_\epsilon} \leq C_{m, N} \epsilon^m
%            \end{align*}
%            for every $\epsilon \in (0, 1]$.
%        \item \label{item:generalised_Littlewood-Paley_decomposition:positive_m}
%            If there exists $c > 0$ such that $\chi$ vanishes on $[0, c]$,
%            then for each $m \geq 0$ and each $N \in \N$,
%            there exists $C_{c, m, N} \geq 0$ such that
%            \begin{align*}
%                \SymbolSemiNorm m {\rho, \delta} N {\eta_\epsilon} \leq C_{c, m, N} \epsilon^m
%            \end{align*}
%            for every $\epsilon \in (0, 1]$.
%    \end{enumerate}
%\end{theorem}
%\begin{proof}
%    First, let us find a smooth real function $\chi \in \SmoothFunctions \R$ such that
%    \begin{align*}
%        \chi(r) = 1 \  \text{if}\  \abs r \leq 1, \quad \text{and} \quad
%        \chi(r) = 0 \ \text{if}\  \abs r \geq 2.
%    \end{align*}
%
%    For every $\tau \in \dualGroup \CompactGroup$ and every $\epsilon \in (0, 1]$,
%    we let
%    \begin{align*}
%        \chi_{\epsilon, \tau}(\lambda)
%        \defeq \chi(\epsilon(\JapaneseBracket \CompactGroup \tau^2 + \norm \lambda^2)^{\frac 1 2})
%    \end{align*}
%
%    Then, for each $\epsilon \in (0, 1]$,
%    we define
%    \begin{align*}
%        \eta_\epsilon(\lambda)
%        \defeq \sum_{\tau \in \dualGroup \CompactGroup} \chi_{\epsilon, \tau}(\lambda) \Id {V_\tau},
%    \end{align*}
%    where in the above $V_\tau \defeq \Span \{\tau_{ij} : 1 \leq i, j \leq \dimRep \tau\}$.
%
%    We check that
%    \begin{align*}
%        \lim_{\epsilon \to 0} \eta_\epsilon(\lambda)
%        &= \lim_{\epsilon \to 0} \sum_{\tau \in \dualGroup \CompactGroup} \chi_{\epsilon, \tau} (\lambda) \Id {V_\tau}\\
%        &= \sum_{\tau \in \dualGroup \CompactGroup} \Id {V_\tau}
%        = \Id {\Lebesgue 2 \CompactGroup}
%    \end{align*}
%
%    \begin{description}
%        \item [Step 1] Computing the associated kernel $\kappa_\epsilon$.
%
%            By applying the inverse Fourier Transform (Proposition~\ref{proposition:inverse_Fourier_Transform}),
%            we know that the kernel is given by
%            \begin{align}
%                \kappa_\epsilon(x, k)
%                = \sum_{\tau \in \dualGroup \CompactGroup}
%                \int_\VectorSpace
%                \tr \left(\chi_{\epsilon, \tau} (\lambda) \eval {\Rep \lambda(x, k)} {V_\tau}\right) \dd \lambda \notag\\
%                = \sum_{\tau \in \dualGroup \CompactGroup}
%                \tr \left(\int_\VectorSpace
%                \chi_{\epsilon, \tau} (\lambda) \eval {\Rep \lambda(x, k)} {V_\tau}\right) \dd \lambda,
%                \label{eq:Littlewood-Paley:computing_kernel}
%            \end{align}
%            where we are allowed to permutate integral and trace because the support of $\xi$ is compact
%            and the operator $\eval {\Rep \lambda(x, k)} {V_\tau}$ is finite-dimensional.
%
%            Using the invariance of $\chi$ under rotations,
%            we obtain that
%            for each $F \in \Lebesgue 2 \CompactGroup$ and each $u \in \CompactGroup$,
%            \begin{align*}
%                &\left(\int_\VectorSpace \chi_{\epsilon, \tau} (\lambda) \eval {\Rep \lambda(x, k)} {V_\tau} \dd \lambda\right) F(u)\\
%                &\quad = \int_\VectorSpace \chi_{\epsilon, \tau u} (\lambda) \eval {\Rep {u \lambda}(x, k)} {V_\tau} F(u) \dd \lambda\\
%                &\quad = \left(\int_\VectorSpace \chi_{\epsilon, \tau} (\lambda) \e^{\i \turn \ip \lambda x} \eval {\RightRegularRepresentation(k)} {V_\tau}\right) F(u)\\
%                &\quad = \InverseFourier [\R^n] \chi_{\epsilon, \tau}(x) \eval {\RightRegularRepresentation(k)} {V_\tau} F(u)
%            \end{align*}
%            Taking the trace on both sides of the above,
%            and keeping in mind that $\eval {\RightRegularRepresentation(k)} {V_\tau} \simeq \tau$,
%            we get
%            \begin{align*}
%                &\tr \left(\int_\VectorSpace \chi_{\epsilon, \tau} (\lambda) \eval {\Rep \lambda(x, k)} {V_\tau} \dd \lambda\right)\\
%                &\quad = \InverseFourier [\R^n] \chi_{\epsilon, \tau}(x) \chi_\tau(k),
%            \end{align*}
%            where $\chi_\tau \defeq \tr \tau$ is the character of $\tau$.
%
%            Injecting the above in~\eqref{eq:Littlewood-Paley:computing_kernel},
%            we obtain
%            \begin{align}
%                \kappa_\epsilon(x, k)
%                = \sum_{\tau \in \dualGroup \CompactGroup}
%                \InverseFourier [\R^n] \chi_{\epsilon, \tau}(x) \chi_\tau(k).
%                \label{eq:Littlewood-Paley:kernel}
%            \end{align}
%        \item [Step 2] Computing $\DifferenceOperatorOrder \alpha \eta_\epsilon$.
%
%            % Conditions on polynomials
%            First, select a strongly admissible family of operators such that
%            \begin{align*}
%                q_j((x, k)^{-1}) = x_j, \quad j = 1, \cdots, \dim \VectorSpace
%            \end{align*}
%            and $q_j$ does not depend on $x$ for $j > \dim \VectorSpace$.
%
%            Fix $\alpha = \alpha_1 + \alpha_2 \in \N^{\dimDifferenceOperators}$ with $\alpha_1 \in \N^{\dim \VectorSpace}$.
%            Using~\eqref{eq:Littlewood-Paley:kernel},
%            we can multiply by $q^\alpha$ and take the Fourier Transform to obtain
%            \begin{align*}
%                &\DifferenceOperatorOrder \alpha \eta_\epsilon(\lambda) F(u)\\
%                &= \sum_{\tau \in \dualGroup \CompactGroup} \int_\Group
%                q^{\alpha_1}((x, k)^{-1}) \InverseFourier [\R^n] \chi_{\epsilon, \tau}(x) \e^{\i \turn \ip \lambda {u x}}\\
%                & \qquad \qquad \qquad (q^{\alpha_2} \chi_\tau)(k^{-1}) F(u k) \dd (x, k)
%            \end{align*}
%            Note that to obtain the above,
%            we used the fact that $\InverseFourier [\R^n] \chi_{\epsilon, \tau}$ is invariant under rotations.
%
%            Using our choice of difference operators and grouping the terms depending on
%            wether they depend on $x$ or on $k$,
%            we obtain
%            \begin{align*}
%                \DifferenceOperatorOrder \alpha \eta_\epsilon(\lambda) F(u)
%                &= \sum_{\tau \in \dualGroup \CompactGroup}
%                \int_\VectorSpace x^{\alpha_1} \InverseFourier [\R^n] \chi_{\epsilon, \tau}(x) \e^{\i \turn \ip \lambda {u x}} \dd x\\
%                & \qquad \qquad \times \int_\CompactGroup (q^{\alpha_2} \chi_\tau)(k^{-1}) F(u k) \dd k.
%            \end{align*}
%
%            Recognising that the integral on $\CompactGroup$ can be seen as a Fourier Transform on $\CompactGroup$,
%            we get the formula
%            \begin{align*}
%                \DifferenceOperatorOrder \alpha \eta_\epsilon(\lambda) F(u)
%                &= \sum_{\tau \in \dualGroup \CompactGroup}
%                \iD {\lambda^{\alpha_1} } \chi_{\epsilon, \tau}(u^{-1} \lambda)
%                \DifferenceOperatorOrder [\CompactGroup] {\alpha_2} \Fourier [\CompactGroup] \chi_\tau F(u),
%            \end{align*}
%            which can be rewritten more elegantly as follows
%            \begin{align}
%                \DifferenceOperatorOrder \alpha \eta_\epsilon(\lambda) F(u)
%                = \bigoplus_{\tau \in \dualGroup \CompactGroup}
%                \iD {\lambda^{\alpha_1} } \chi_{\epsilon, \tau}(u^{-1} \lambda)
%                \DifferenceOperatorOrder [\CompactGroup] {\alpha_2} \Id {V_\tau} F(u).
%                \label{eq:Littlewood-Paley:difference_operators}
%            \end{align}
%
%        \item [Step 3a] If $F \in V_\tau$ for some $\tau \in \dualGroup \CompactGroup$,
%            then there exists $c_\alpha, C_\alpha \geq 0$ such that
%            \begin{align*}
%                \DifferenceOperatorOrder \alpha \eta_\epsilon(\lambda) F
%                \subset \bigoplus_{c_\alpha \leq \JapaneseBracket \CompactGroup \tau^{-1} \JapaneseBracket \CompactGroup \mu \leq C_\alpha} V_{\mu}
%            \end{align*}
%
%        \item [Step 3b] We show that there exists $C = C_{\alpha, \gamma} \geq 0$ which does \emph{not} depend on $\epsilon$ or $\lambda$ such that
%            \begin{align*}
%                \norm [\Lin {\Lebesgue 2 \CompactGroup}] {%
%                    \Rep \lambda \BesselPotential {\rho \abs \alpha + \gamma}
%                    \DifferenceOperatorOrder \alpha \eta_\epsilon(\lambda)
%                    \Rep \lambda \BesselPotential {-\gamma}
%                } \leq C_{\alpha, \gamma}.
%            \end{align*}
%
%            From~\eqref{eq:Littlewood-Paley:difference_operators},
%            we deduce that
%            \begin{align*}
%                \norm [\Lin {\Lebesgue 2 \CompactGroup}] {%
%                    \DifferenceOperatorOrder \alpha \eta_\epsilon(\lambda)
%                    \Rep \lambda \BesselPotential {\rho \abs \alpha}
%                }
%                \leq C_\alpha
%            \end{align*}
%            holds if and only if
%            \begin{align*}
%                \norm [\Lin {\Lebesgue 2 \CompactGroup}] {%
%                    \iD {\lambda^{\alpha_1} } \chi_{\epsilon, \tau}(u^{-1} \lambda)
%                    \DifferenceOperatorOrder {\alpha_2} \Id {V_\tau}
%                    } \leq C_\alpha (\JapaneseBracket \CompactGroup \tau + \norm {\turn \lambda})^{-\rho \abs {\alpha}}.
%            \end{align*}
%
%            By the chain rule,
%            we have
%            \begin{align*}
%                \iD {\lambda^{\alpha_1} } &\chi_{\epsilon, \tau}(u^{-1} \lambda)\\
%                &= \epsilon^{\alpha_1} \lcsum{n \leq \abs {\alpha_1}}
%                \D*{n}[\chi]{r^n}(\epsilon (\JapaneseBracket \CompactGroup \tau^2 + \norm {\turn \lambda}^2)^{\frac 1 2})
%                \iD {\lambda^{\alpha_1} } (\JapaneseBracket \CompactGroup \tau^2 + \norm {\turn \lambda}^2)^{\frac 1 2}.
%            \end{align*}
%
%            We now check that \cite[Lemma A.10]{Fischer2015} implies that
%            \begin{align*}
%                &\norm [\Lebesgue 2 \CompactGroup] {%
%                    \DifferenceOperatorOrder {\alpha_2} \left(%
%                        \D*{n}[\chi]{r^n}(\epsilon (\JapaneseBracket \CompactGroup \tau^2 + \norm {\turn \lambda}^2)^{\frac 1 2})
%                        \Id {V_\tau}
%                    \right)
%                }\\
%                &\qquad \leq
%                C (\JapaneseBracket \CompactGroup \tau + \norm {\turn \lambda}^2)^{-\rho \abs \alpha_2}.
%            \end{align*}
%
%            Combining the last two equations,
%            we get
%            \begin{align}
%                \norm [\Lin {\Lebesgue 2 \CompactGroup}] {%
%                    \iD {\lambda^{\alpha_1} } \chi_{\epsilon, \tau}(u^{-1} \lambda)
%                    \DifferenceOperatorOrder {\alpha_2} \Id {V_\tau}
%                    } \leq C_\alpha (\JapaneseBracket \CompactGroup \tau + \norm {\turn \lambda})^{-\rho \abs {\alpha}}.
%                \label{eq:eta_epsilon_symbol_norm_for_gamma_0}
%            \end{align}
%
%            To conclude,
%            observe first that
%            \begin{align*}
%                &\norm [\Lin {\Lebesgue 2 \CompactGroup}] {%
%                    \Rep \lambda \BesselPotential {\gamma + \rho \abs \alpha}
%                    \DifferenceOperatorOrder \alpha \eta_\epsilon
%                    \Rep \lambda \BesselPotential {-\gamma}
%                }\\
%                &\leq C
%                \sup_{\tau \in \dualGroup \CompactGroup}
%                \norm [\Lin {\Lebesgue 2 \CompactGroup}] {%
%                    \Rep \lambda \BesselPotential {\gamma + \rho \abs \alpha}
%                    \eval {\DifferenceOperatorOrder \alpha \eta_\epsilon (\lambda)} {V_\tau}
%                }
%                (1 + \JapaneseBracket \CompactGroup \tau + \norm \lambda)^{-\gamma}.
%            \end{align*}
%
%            By Step 3a,
%            \begin{align*}
%                \eval {%
%                    \Rep \lambda \BesselPotential {\gamma + \rho \abs \alpha}
%                    } {\DifferenceOperatorOrder \alpha \eta_\epsilon(V_\tau)}
%                    \asymp
%                    (1 + \JapaneseBracket \CompactGroup \tau + \norm \lambda)^{\gamma + \rho \alpha} \Id {\DifferenceOperatorOrder \alpha \eta_\epsilon(V_\tau)}
%            \end{align*}
%            which,
%            if injected into the above calculation, yields
%            \begin{align*}
%                &\norm [\Lin {\Lebesgue 2 \CompactGroup}] {%
%                    \Rep \lambda \BesselPotential {\gamma + \rho \abs \alpha}
%                    \DifferenceOperatorOrder \alpha \eta_\epsilon (\lambda)
%                    \Rep \lambda \BesselPotential {-\gamma}
%                }\\
%                &\leq C
%                \sup_{\tau \in \dualGroup \CompactGroup}
%                \norm [\Lin {\Lebesgue 2 \CompactGroup}] {%
%                    \DifferenceOperatorOrder \alpha \eta_\epsilon (\lambda)
%                }
%                (1 + \JapaneseBracket \CompactGroup \tau + \norm \lambda)^{\rho \abs \alpha}\\
%                &\leq C
%                \norm [\Lin {\Lebesgue 2 \CompactGroup}] {%
%                    \Rep \lambda \BesselPotential {\rho \abs \alpha}
%                    \DifferenceOperatorOrder \alpha \eta_\epsilon (\lambda)
%                }
%            \end{align*}
%
%            However,
%            the right-hand side of the above is bounded by $C_\alpha$
%            by~\eqref{eq:eta_epsilon_symbol_norm_for_gamma_0}.
%
%        \item [Step 4a] Prove~\ref{item:generalised_Littlewood-Paley_decomposition:negative_m}.
%
%            Let $m \leq 0$.
%
%            From~\eqref{eq:Littlewood-Paley:difference_operators} and Lemma~\ref{lemma:left_regular_representation_of_polynomials},
%            % TODO: Make lemmas more relevant
%            we know that the range of the operator
%            \begin{align}
%                \Rep \lambda \BesselPotential {\rho \abs \alpha + \gamma}
%                \DifferenceOperatorOrder \alpha \eta_\epsilon(\lambda)
%                \Rep \lambda \BesselPotential {-\gamma}
%                \label{eq:Littlewood-Paley:central_operator}
%            \end{align}
%            is finite-dimensional,
%            and is actually contained in
%            \begin{align*}
%                R_\epsilon(\lambda) =
%                \bigoplus \{V_\tau : \norm \lambda \leq C_\alpha \epsilon^{-1} \text{ and } \JapaneseBracket \CompactGroup \tau \leq C_\alpha \epsilon^{-1} \}
%            \end{align*}
%            for some $c_\alpha, C_\alpha \geq 0$ depending only on $\alpha$.
%            As a result,
%            we can define the operator
%            \begin{align*}
%                L_\epsilon(\lambda) \defeq
%                \eval {\Rep \lambda \BesselPotential 1} {R_\epsilon(\lambda)}
%            \end{align*}
%            and be certain that $L_\epsilon(\lambda)$ and $\Rep \lambda \BesselPotential 1$ coincide on the range of~\eqref{eq:Littlewood-Paley:central_operator}
%            for every $\lambda \in \VectorSpace$.
%
%            Moreover,
%            it is clear that from the way we constructed $L_\epsilon(\lambda)$ that
%            \begin{align*}
%                \norm [\Lin {\Lebesgue 2 \CompactGroup}] {L_\epsilon(\lambda)} \leq C_\alpha \epsilon^{-1}.
%            \end{align*}
%            Therefore,
%            \begin{align*}
%                &\norm [\Lin {\Lebesgue 2 \CompactGroup}] {%
%                    \Rep \lambda \BesselPotential {-m + \rho \abs\alpha + \gamma}
%                    \DifferenceOperatorOrder \alpha \eta_\epsilon(\lambda)
%                    \Rep \lambda \BesselPotential {-\gamma}
%                }\\
%                &\quad \leq \norm [\Lin {\Lebesgue 2 \CompactGroup}] {%
%                    L_\epsilon(\lambda)^{-m}
%                    \Rep \lambda \BesselPotential {\rho \abs \alpha + \gamma}
%                    \DifferenceOperatorOrder \alpha \eta_\epsilon(\lambda)
%                    \Rep \lambda \BesselPotential {-\gamma}
%                }\\
%                &\quad \leq C_{\alpha, \gamma, m} \epsilon^{m},
%            \end{align*}
%            which concludes the proof of~\ref{item:generalised_Littlewood-Paley_decomposition:negative_m}
%
%        \item [Step 4b] Prove~\ref{item:generalised_Littlewood-Paley_decomposition:positive_m}
%
%            Let $m \geq 0$.
%            Clearly,
%            \begin{align*}
%                \DifferenceOperatorOrder \alpha \eta_\epsilon(\lambda) F(u)
%                &= \sum_{\tau \in \dualGroup \CompactGroup}
%                \iD {\lambda^{\alpha_1} } (1 - \chi_{\epsilon, \tau})(u^{-1} \lambda)
%                \DifferenceOperatorOrder [\CompactGroup] {\alpha_2} \Fourier [\CompactGroup] \chi_\tau F(u),
%            \end{align*}
%
%            Since $1 - \chi_{\epsilon, \tau}$ vanishes only when $\JapaneseBracket \CompactGroup \tau \norm \lambda \geq c \epsilon^{-2}$,
%            we can deduce that the range of~\eqref{eq:Littlewood-Paley:central_operator} is contained in
%            \begin{align*}
%                R_\epsilon(\lambda) \defeq \bigoplus \{V_\tau : \JapaneseBracket \CompactGroup \tau \norm \lambda \geq c_\alpha \epsilon^{-2} \}.
%            \end{align*}
%
%            Now, if we define the operator
%            \begin{align*}
%                L_\epsilon(\lambda) \defeq \eval {\Rep \lambda \BesselPotential 1} {R_\epsilon(\lambda)} \bigoplus c_\alpha \epsilon^{-1} \Id {\R_\epsilon(\lambda)^\perp},
%            \end{align*}
%            then by construction our operator satisfies
%            \begin{align*}
%                \norm [\Lin {\Lebesgue 2 \CompactGroup}] {L_\epsilon(\lambda)} \geq \epsilon^{-1}.
%            \end{align*}
%
%            Therefore,
%            \begin{align*}
%                &\norm [\Lin {\Lebesgue 2 \CompactGroup}] {%
%                    \Rep \lambda \BesselPotential {-m + \rho \abs\alpha + \gamma}
%                    \DifferenceOperatorOrder \alpha \eta_\epsilon(\lambda)
%                    \Rep \lambda \BesselPotential {-\gamma}
%                }\\
%                &\quad \leq \norm [\Lin {\Lebesgue 2 \CompactGroup}] {%
%                    L_\epsilon(\lambda)^{-m}
%                    \Rep \lambda \BesselPotential {\rho \abs \alpha + \gamma}
%                    \DifferenceOperatorOrder \alpha \eta_\epsilon(\lambda)
%                    \Rep \lambda \BesselPotential {-\gamma}
%                }\\
%                &\quad \leq C_{\alpha, \gamma, m} \epsilon^{m},
%            \end{align*}
%            which concludes the proof of~\ref{item:generalised_Littlewood-Paley_decomposition:positive_m}
%    \end{description}
%\end{proof}
%
%\begin{corollary}[Littlewood-Paley decomposition]
%    Let $\sigma \in \SymbolClass m {\rho, \delta}$.
%    There exists a sequence $(\sigma_l)_{l \in \N} \subset \SmoothingSymbols$
%    such that
%    \begin{align*}
%        \sigma = \sum_{l = 0}^{+\infty} \sigma_l.
%    \end{align*}
%
%    Moreover, for each $m \in \R$,
%    there exists $C \geq 0$ such that
%    \begin{align*}
%        \SymbolSemiNorm m {\rho, \delta} N {\sigma_l} \leq C 2^{-l m}
%    \end{align*}
%    holds for each $l \in \N$.
%\end{corollary}
%
%\begin{corollary}
%    Let $\sigma \in \SymbolClass m {\rho, \delta}$ for $m \in \R$ and $0 \leq \rho, \delta \leq 1$.
%    Fix a cut-off function $\chi \in \SmoothFunctions \Group$ satisfying
%    \begin{align*}
%        \chi(x, k) =
%        \begin{cases}
%            1 & \text{if } \norm x \leq 1\\
%            0 & \text{if } \norm x \geq 2
%        \end{cases},
%    \end{align*}
%    which allows us, for each $\epsilon \in (0, 1]$ to define
%    \begin{align*}
%        \sigma_\epsilon(x, k; \lambda) \defeq \chi(\epsilon x, k) \sigma(x, k; \lambda) \eta_\epsilon(\lambda)
%    \end{align*}
%    for each $g \in \Group$ and each $\lambda \in \VectorSpace$.
%
%    The symbol $\sigma_\epsilon$ is smoothing,
%    and satisfies the following estimates.
%    \begin{enumerate}
%        \item For every $m_1 \leq m$ and each $N \in \N$,
%            there exists $C = C_{m, m_1, N, \sigma} \geq 0$ such that
%            \begin{align*}
%                \SymbolSemiNorm {m_1} {\rho, \delta} N {\sigma_\epsilon}
%                \leq C \epsilon^{m_1 - m}
%            \end{align*}
%            holds for every $\epsilon \in (0, 1]$.
%        \item For every $m_1 \geq m$ and each $N \in \N$
%            there exists $C = C_{m, m_1, N, \sigma} \geq 0$ such that
%            \begin{align*}
%                \SymbolSemiNorm {m_1} {\rho, \delta} N {\sigma - \sigma_\epsilon}
%                \leq C \epsilon^{m_1 - m}
%            \end{align*}
%            holds for every $\epsilon \in (0, 1]$.
%    \end{enumerate}
%\end{corollary}
%
%%\begin{corollary}[Littlewood-Paley decomposition]
%%    There exists a sequence $\eta_l \in \SmoothingSymbols$, $l \in \N$ of smoothing symbols satisfying the following properties
%%    \begin{enumerate}
%%        \item the semi-norms decay in the following way
%%            \begin{align}
%%                \SymbolSemiNorm{m}{\rho, \delta} N {\eta_l} \leq C 2^{-lm}
%%            \end{align}
%%        \item the associated kernels $\kappa_l$ satisfy
%%            \begin{align*}
%%                \sum_{l = 0}^\infty \kappa_l = \DiracDelta{e_\Group}
%%            \end{align*}
%%            in the sense of distributions.
%%    \end{enumerate}
%%\end{corollary}
%%\begin{proof}
%%    Let $\eta'_\epsilon$, $\epsilon \in (0, 1]$ be the family given by Theorem~\ref{theorem:generalised_Littlewood-Paley_decomposition}.
%%    For each $l \in \N$,
%%    we define
%%    \begin{align*}
%%        \begin{cases}
%%            \eta_0 \defeq \eta'_1\\
%%            \eta_l \defeq \eta'_{2^{-l}} - \eta'_{2^{-l + 1}}
%%        \end{cases}
%%    \end{align*}
%%    For $l \geq 1$,
%%    we have
%%    \begin{align*}
%%        &\norm [\Lin {\Lebesgue 2 \Group}] {%
%%        \Rep \lambda \BesselPotential {-m + \rho \abs \alpha + \gamma}
%%        \DifferenceOperatorOrder \alpha \left( \eta'_{2^{-l}} - \eta'_{2^{-l + 1}} \right)
%%        \Rep \lambda \BesselPotential {-\gamma}
%%        }\\
%%        & \qquad \leq C_{\alpha, \gamma, m} (1 + 2^{-m}) 2^{-l m}\\
%%        & \qquad \leq C_{\alpha, \gamma, m} 2^{-l m},
%%    \end{align*}
%%    while the case $l = 1$ follows directly from Theorem~\ref{theorem:generalised_Littlewood-Paley_decomposition}.
%%
%%    The second claim follows from the fact that
%%    \begin{align*}
%%        \sum_{l = 0}^{L} \eta_l
%%        &= \eta'_1 + \sum_{l = 1}^{L} \eta_l
%%        = \eta'_{2^{-1}} + \sum_{l = 2}^{L} \eta_l\\
%%        &= \eta'_{2^{-L + 1}} + \eta_L
%%        = \eta'_{2^{-L}}
%%    \end{align*}
%%    and Theorem~\ref{theorem:generalised_Littlewood-Paley_decomposition}.
%%\end{proof}

\section{Kernel estimates}

As we have seen so far,
a pseudo-differential operator is entirely determined by either its \emph{right-convolution kernel} or its \emph{symbol}.
Symbols have the distinctive advantage of being \emph{smooth},
which is why for \emph{abelian} Lie groups,
a pseudo-differential calculus can be developed by doing all the calculations on the symbolic side
(for this, see e.g.\ \cite{RuzhanskyTurunen10}).

For non-commutative groups such as the motion group,
the Fourier transform is \emph{operator valued} and therefore, so are symbols.
This unfortunately means that it will sometimes be impractical to work with symbols,
and that calculations will have to be carried out in terms of the kernels.
It is therefore crucial to study their properties,
such as their \emph{singularity} or their \emph{decay} away from the origin.

We shall see that the regularity of the kernel increases
as the order of the symbol decreases.
If $\rho > 1$, difference operators decrease the order of the symbol
or equivalently multiplying kernels by some suitable polynomial increases its regularity.
The reader should therefore expect smoothness and Schwartz decay away from the origin,
as the latter is the only point where we allow our polynomials to all vanish.

Before stating the main result of this section,
let us define the quantity
\begin{align*}
    \norm [\Group] {(x, k)} \defeq \norm {x} + d(k, \Id{\VectorSpace}), \quad (x, k) \in \Group,
\end{align*}
which represents the distance between $(x, k)$ and the origin.
The above is of course an abuse of notation, as $\norm [\Group] \dummy$ is not a norm.

\begin{theorem}[Kernel estimates]
\label{theorem:kernel_estimates}
    Let $\rho, \delta \in \R$ be such that $1 \geq \rho \geq \delta \geq 0$
    and assume further that $\rho > 0$.
    Suppose that $\sigma \in \SymbolClass{m}{\rho, \delta}$,
    and $\kappa \in \SmoothFunctions {\Group, \TemperedDistributions \Group}$ is its associated kernel.
    \begin{enumerate}
        \item \label{item:kernel_estimates:at_infinity}
            For every $d > 0$ and every $N \in \N$,
            there exists $C \geq 0$ such that for every $g, h = (y, l) \in \Group$ with $\norm {y} \geq d$, we have
            \begin{align*}
                \abs{\kappa_g(h)} \leq C \norm y^{-N}.
            \end{align*}
        \item \label{item:kernel_estimates:at_origin:positive}
            If $m > - \dim \Group$ and $\rho < 1$, there exists $C \geq 0$ such that for every $g, h \in \Group$ with $h \neq 0$, we have
            \begin{align*}
                \abs{\kappa_g(h)} \leq C \norm [\Group] h^{- \frac{\dim \Group + m}{\rho}}.
            \end{align*}
        \item \label{item:kernel_estimates:at_origin:zero}
            If $m \geq -\dim \Group$ or $\rho = 1$,
            then for every $\gamma < -(m + \dim \Group)/\rho$,
            there exists $C \geq 0$ such that for every $g, h \in \Group$ with $h \neq 0$, we have
            \begin{align*}
                \abs{\kappa_g(h)} \leq C \norm [\Group] h^\gamma.
            \end{align*}
        \item \label{item:kernel_estimates:at_origin:negative}
            If $m < -\dim \Group$, $\kappa_g$ is continuous on $\Group$ and is bounded
            \begin{align*}
                \sup_{g, h \in \Group} \abs{\kappa_g(h)} \leq C < \infty.
            \end{align*}
    \end{enumerate}
\end{theorem}

\subsection{\texorpdfstring{$L^2$}{L2} estimates for the kernel}

The first step towards establishing estimates on $\sup_{g, h \in \Group} \abs {\kappa_g(h)}$
is to provide $\Lebesgue 2 \Group$ estimates for derivatives of $\kappa_g$ that are not dependent on $g \in \Group$.
This is, of course, a consequence of the Sobolev inequality (Proposition~\ref{proposition:Sobolev_embedding}).

\begin{proposition}
\label{proposition:L2_bound_on_the_kernel}
    Let $\sigma \in \SymbolClass m {\rho, \delta}$ with $1 \geq \rho \geq \delta \geq 0$,
    and denote by $\kappa \in \SmoothFunctions {\Group, \TemperedDistributions \Group}$ its associated kernel.
    If $m < -\dim \Group / 2$,
    then $\kappa_g \in \Lebesgue 2 \Group$ for every $g \in \Group$,
    \begin{align*}
        \sup_{g \in \Group} \norm [\Lebesgue 2 \Group] {\kappa_g} < \infty.
    \end{align*}
\end{proposition}
\begin{proof}
    Let $g \in \Group$ and $\lambda \in \VectorSpace$.
    Clearly,
    \begin{align*}
        &\norm [\SchattenClasses 2 {\Lebesgue 2 \CompactGroup}] {\sigma(g, \lambda)}^2\\
        &\quad= \norm [\SchattenClasses 2 {\Lebesgue 2 \CompactGroup}] {\Rep \lambda \BesselPotential m \Rep \lambda \BesselPotential {-m} \sigma(g, \lambda)}^2\\
        &\quad\leq
        \norm [\SchattenClasses 2 {\Lebesgue 2 \CompactGroup}] {\Rep \lambda \BesselPotential {-m}}^2
        \norm [\Lin {\Lebesgue 2 \CompactGroup}] {\Rep \lambda \BesselPotential {-m} \sigma(g, \lambda)}^2.
    \end{align*}

    Using $\sigma \in \SymbolClass m {\rho, \delta}$,
    the above becomes
    \begin{align*}
        \norm [\SchattenClasses 2 {\Lebesgue 2 \CompactGroup}] {\sigma(g, \lambda)}^2
        \leq C \norm [\SchattenClasses 2 {\Lebesgue 2 \CompactGroup}] {\Rep \lambda \BesselPotential {-m}}^2.
    \end{align*}

    Integrating both sides of the above with respect to $\lambda \in \VectorSpace$
    and using the Plancherel formula (Proposition~\ref{proposition:Plancherel_formula}) on either sides,
    we get
    \begin{align*}
        \norm [\Lebesgue 2 \CompactGroup] {\kappa_g}^2 \leq C \norm [\Lebesgue 2 \CompactGroup] {\BesselPotentialKernel {-m}}^2.
    \end{align*}

    We conclude the proof by observing that the right-hand side is finite by assumption on $m$ and Proposition~\ref{proposition:Sobolev_embedding},
    but also that the right-hand side does not depend on $g$.
\end{proof}

\begin{corollary}
\label{corollary:Sobolev_estimates_on_the_kernel}
    Let $\sigma \in \SymbolClass m {\rho,\delta}$ with $1 \geq \rho \geq \delta \geq 0$,
    and denote by $\kappa \in \SmoothFunctions {\Group, \TemperedDistributions \Group}$ its associated kernel.

    For every $s \in \R$ satisfying
    \begin{align*}
        s < -\frac{\dim \Group} 2 - m,
    \end{align*}
    the kernel $\kappa_g$ belongs to $\Sobolev s$ for every $g \in \Group$.
    Moreover, for such an $s \in \R$, we have the estimate:
    \begin{align*}
        \sup_{g \in \Group} \norm [\Sobolev s] {\kappa_g} < \infty.
    \end{align*}
\end{corollary}
\begin{proof}
    The symbol
    \begin{align*}
        \Rep \lambda \BesselPotential s \sigma(g, \lambda)
    \end{align*}
    belongs to $\SymbolClass {m + s} {\rho, \delta}$,
    with $m + s \leq -\dim \Group/2$ by our assumption.

    Therefore, applying Proposition~\ref{proposition:L2_bound_on_the_kernel},
    we know that for every $g \in \Group$,
    \begin{align*}
        \BesselPotential s \kappa_g \in \Lebesgue 2 \Group,
    \end{align*}
    or in other words, $\kappa_g \in \Sobolev s$, and
    \begin{align*}
        \sup_{g \in \Group} \norm [\Sobolev s] {\kappa_g}
        = \sup_{g \in \Group} \norm [\Lebesgue 2 \Group] {\BesselPotential s \kappa_g}
        < \infty,
    \end{align*}
    concluding the proof.
\end{proof}

We can now prove Part~\ref{item:kernel_estimates:at_origin:negative} of Theorem~\ref{theorem:kernel_estimates}.

\begin{corollary}
\label{corollary:kernel_estimates:at_origin:negative}
    Let $\sigma \in \SymbolClass m {\rho,\delta}$ with $1 \geq \rho \geq \delta \geq 0$,
    and denote by $\kappa \in \SmoothFunctions {\Group, \TemperedDistributions \Group}$ its associated kernel.

    If $m < -\dim \Group$,
    then $\kappa_g \in \ContinuousFunctions \Group$ is continuous for every $g \in \Group$ and
    \begin{align*}
        \sup_{g \in \Group} \norm [\ContinuousFunctions \Group] {\kappa_g} < \infty.
    \end{align*}
\end{corollary}
\begin{proof}
    Choose $s \in \R$ such that
    \begin{align*}
        \frac {\dim \Group} 2 < s < -\frac {\dim \Group} 2 - m,
    \end{align*}
    which is possible since $m < -\dim \Group$.

    Since $m < -\dim \Group/2 - s$,
    Corollary~\ref{corollary:Sobolev_estimates_on_the_kernel} implies that
    $\kappa_g \in \Sobolev s$ for every $g \in \Group$,
    \begin{align*}
        \sup_{g \in \Group} \norm [\Sobolev s] {\kappa_g} < \infty.
    \end{align*}

    However,
    since $s > \dim \Group / 2$,
    the Sobolev inequality (Proposition~\ref{proposition:Sobolev_embedding})
    implies that
    \begin{align*}
        \sup_{g \in \Group} \norm [\ContinuousFunctions \Group] {\kappa_g}
        \leq C \sup_{g \in \Group} \norm [\Sobolev s] {\kappa_g} < \infty.
    \end{align*}
    This concludes the proof.
\end{proof}

\subsection{Estimates at infinity}

We start by proving Part \ref{item:kernel_estimates:at_infinity} of Theorem~\ref{theorem:kernel_estimates}.

\begin{proof}
    Let $M \in \R$ and choose $p \in 2 \N$ sufficiently large so that
    \begin{align*}
        g \geq M \quad \text{and} \quad
        m - \rho p + \Ceiling {\dim \Group / 2} < -\frac {\dim \Group} 2
    \end{align*}

    Fix $d > 0$,
    and let $\chi \in \SmoothFunctions \Group$ be a smooth radial function satisfying
    \begin{align*}
        \chi(y, l) =
        \begin{cases}
            0 & \text{if } \norm y \leq d/2\\
            1 & \text{if } \norm y \geq d
        \end{cases}
    \end{align*}

    From now on, we shall write $h = (y, l)$.

    By the Sobolev inequality (Proposition~\ref{proposition:Sobolev_embedding}),
    we have
    \begin{align}
        \sup_{\norm y \geq d} &\abs{\norm y^M \kappa_g(h)} \notag\\
        &\leq \sup_{h \in \Group} \abs{\norm y^M \kappa_g(h) \chi(h)} \notag\\
        &\leq C \sum_{\abs \beta \leq \Ceiling {\dim \Group / 2}} \norm [\Lebesgue 2 {\Group, \dd h}] {\LeftDifferentialOperator [h] \beta \{\norm y^M \kappa_g(h) \chi(h)\}}.
        \label{eq:Schwartz_decay_of_kernel:first_estimate}
    \end{align}

    Let us do some calculations on the right-hand side of the above.
    By the Leibniz formula, we have
    \begin{align}
        &\abs {\LeftDifferentialOperator [h] \beta \{\kappa_g(h) \chi(h)\}} \notag\\
        &\leq \lcsum {\beta' \leq \beta} \abs{\LeftDifferentialOperator [h] {\beta - \beta'} \{\norm y^{M - p} \chi(h)\} \LeftDifferentialOperator [h] {\beta'} \{\norm y^p \kappa_g(h)\}} \notag\\
        &\leq
        \left(\lcsum {\beta' \leq \beta} \abs{\LeftDifferentialOperator [h] {\beta'} \{\norm y^{M - p} \chi(h)\}}^2\right)^{\frac 1 2}
        \left(\lcsum {\beta' \leq \beta} \abs{\LeftDifferentialOperator [h] {\beta'} \{\norm y^p \kappa_g(h)\}}^2\right)^{\frac 1 2},
        \label{eq:Schwartz_decay_of_kernel:Leibniz}
    \end{align}
    where the last line was obtained by applying the Cauchy-Schwartz inequality to the sum.
    Since $p \geq M$ and $\chi$ vanishes around $\{0_\VectorSpace\} \times \CompactGroup$,
    it follows that
    \begin{align*}
        \sup_{h \in \Group} \lcsum {\beta' \leq \beta} \abs{\LeftDifferentialOperator [h] {\beta'} \{\norm y^{M - p} \chi(h)\}}^2 < \infty,
    \end{align*}
    which means that~\eqref{eq:Schwartz_decay_of_kernel:Leibniz} becomes
    \begin{align*}
        \abs {\LeftDifferentialOperator [h] \beta \{\kappa_g(h) \chi(h)\}}
        \leq C \left(\lcsum {\beta' \leq \beta} \abs{\LeftDifferentialOperator [h] {\beta'} \{\norm y^p \kappa_g(h)\}}^2\right)^{\frac 1 2}.
    \end{align*}

    Therefore, if we square both sides of the above and integrate with respect to $h$, we obtain
    \begin{align*}
        &\int_\Group \abs {\LeftDifferentialOperator [h] \beta \{\kappa_g(h) \chi(h)\}}^2 \dd h\\
        &\qquad \leq C \int_\Group \lcsum {\beta' \leq \beta} \abs{\LeftDifferentialOperator [h] {\beta'} \{\norm y^p \kappa_g(h)\}}^2 \dd h\\
        &\qquad \leq C \lcsum {\beta' \leq \beta} \sum_{\abs \alpha = p} \int_\Group \abs{\LeftDifferentialOperator {\beta'} \{q^\alpha \kappa_g\}}^2 \dd h,
    \end{align*}
    where the last line was obtained by using ??. % TODO: reference!
    Continuing the above calculation,
    we get
    \begin{align*}
        &\int_\Group \abs {\LeftDifferentialOperator [h] \beta \{\kappa_g(h) \chi(h)\}}^2 \dd h\\
        &\quad \leq C \sum_{\abs \alpha = p} \int_\Group \abs{\BesselPotential {\Ceiling {\dim \Group / 2}} \{q^\alpha \kappa_g\}}^2 \dd h.
    \end{align*}

    Combinig the above with~\eqref{eq:Schwartz_decay_of_kernel:first_estimate},
    this yields
    \begin{align}
        \sup_{\norm y \geq d} &\abs{\norm y^M \kappa_g(h)}
        \leq C \sum_{\abs \alpha = p} \norm [\Lebesgue 2 \Group] {\BesselPotential {\Ceiling {\dim \Group / 2}} \{q^\alpha \kappa_g\}}.
        \label{eq:Schwartz_decay_of_kernel:final_step}
    \end{align}
    In the above,
    each symbol $\Rep \lambda \BesselPotential {\Ceiling {\dim \Group / 2}} \DifferenceOperatorOrder \alpha \sigma(g, \lambda)$ is of order
    \begin{align*}
        m - \rho p + \Ceiling {\dim \Group / 2} < -\frac {\dim \Group} 2
    \end{align*}
    so that its kernel $\BesselPotential {\Ceiling {\dim \Group / 2}} \{q^\alpha \kappa_g\}$ belongs to $\Lebesgue 2 \Group$ uniformly in $g \in \Group$ by Proposition~\ref{proposition:L2_bound_on_the_kernel}.
    This implies that~\eqref{eq:Schwartz_decay_of_kernel:final_step} becomes
    \begin{align*}
        \sup_{g \in \Group} \sup_{\norm y \geq d} &\abs{\norm y^M \kappa_g(h)} < \infty,
    \end{align*}
    concluding the proof.
\end{proof}

\subsection{Estimates at the origin}

We have shown so far that the regularity of the kernel is linked to the order of its corresponding symbol in the following way:
the lower the order, the more regular the kernel is.
As applying difference operator strictly \emph{reduces the order} when $\rho > 0$,
the distribution
\begin{align*}
    q^\alpha \kappa_g \defeq \InverseFourier \{ \DifferenceOperatorOrder \alpha \sigma(g, \dummy) \}
\end{align*}
becomes more regular as $\abs \alpha$ increases.
This means that $\kappa_g$ can only have singularities at the common zeros
\begin{align*}
    \bigcap_{j = 1}^{\dimDifferenceOperators} \{ q_j = 0 \} = (0_\VectorSpace, \Id \VectorSpace),
\end{align*}
which happens to simply be the origin
as the family $\{q_j : j = 1, \cdots, \dimDifferenceOperators\}$ was chosen to be \emph{strongly admissible}.

The aim of this subsection is therefore to study the strength of the only singularity that a kernel can have,
which will lead to the proof of parts \ref{item:kernel_estimates:at_origin:positive} and \ref{item:kernel_estimates:at_origin:zero} of Theorem~\ref{theorem:kernel_estimates}.

\begin{theorem}[Kernel estimates at the origin]
\label{theorem:kernel_estimates:at_origin}
    Let $\rho, \delta \in \R$ be such that $1 \geq \rho \geq \delta \geq 0$
    and assume further that $\rho > 0$.
    Suppose that $\sigma \in \SymbolClass{m}{\rho, \delta}$,
    and $\kappa \in \SmoothFunctions {\Group, \TemperedDistributions \Group}$ denotes its associated kernel.
    \begin{enumerate}
        \item
            If $\rho < 1$ and $m > -\dim \Group$, there exists $C \geq 0$ such that for every $g, h \in \Group$ with $h \neq 0$, we have
            \begin{align*}
                \abs{\kappa_g(h)} \leq C \norm [\Group] h^{- \frac{\dim \Group + m}{\rho}}.
            \end{align*}
        \item
            If $\rho = 1$ or if $m = -\dim \Group$,
            then for every $\gamma < -(\dim \Group + m)/\rho$,
            there exists $C \geq 0$ such that for every $g, h \in \Group$ with $h \neq 0$, we have
            \begin{align*}
                \abs{\kappa_g(h)} \leq C \norm [\Group] h^\gamma.
            \end{align*}
    \end{enumerate}
\end{theorem}
\begin{proof}
    Fix $h \in \Group \setminus \{(0, \Id \VectorSpace)\}$ such that $\epsilon \defeq \norm [\Group] h \leq 1$.
    Define the symbol
    \begin{align*}
        \sigma_\epsilon(g, \lambda) \defeq \sigma(g, \lambda),
        \quad g \in \Group, \lambda \in \VectorSpace,
    \end{align*}
    and denote by $\kappa_\epsilon \defeq \InverseFourier \{\sigma(g, \dummy)\}$
    its associated kernel.

    Using
    \begin{align*}
        \abs {\kappa_g(h)} \leq \abs{\kappa_{\epsilon, g}(h)} + \abs{\kappa_g(h) - \kappa_{\epsilon, g}(h)},
    \end{align*}
    the idea of the proof is to estimate both terms of the right-hand side above separately.

    As we have shown earlier in Corollary~\ref{corollary:Sobolev_estimates_on_the_kernel}
    we can get a bound on the kernel provided the order of its associated symbol is strictly less than $-\dim \Group$.
    For $\kappa_\epsilon$, this will be easy since $\sigma_\epsilon$ is smoothing;
    for $\kappa_g - \kappa_{g, \epsilon}$, we will have to use difference operators.

    Note that the case $m = -\dim \Group$ is a simple consequences of the other estimates,
    and the inclusion $\SymbolClass m {\rho, \delta} \subset \SymbolClass {m'} {\rho, \delta}$ when $m \leq m'$.
    We can therefore assume without loss of generality that $m > -\dim \Group$.

    \begin{description}
        \item[Estimates on $\kappa_\epsilon$]
            We observe that for each $\gamma \in \R$,
            we have
            \begin{align*}
                \sigma_\epsilon(g, \lambda)
                &= \sigma(g, \lambda) \Rep \lambda \BesselPotential {-m}\\
                &\qquad \eta_\epsilon(\lambda) \Rep \lambda \BesselPotential {-\gamma}
                \Rep \lambda \BesselPotential {-m + \gamma}.
            \end{align*}

            Using the Holder inequality on Schatten classes,
            together with Theorem~\ref{theorem:generalised_Littlewood-Paley_decomposition},
            we obtain
            \begin{align}
                \norm [\SchattenClasses 1 {\Lebesgue 2 \CompactGroup}] {\sigma_\epsilon(g, \lambda)} \leq C
                \epsilon^{\gamma} \norm [\SchattenClasses 1 {\Lebesgue 2 \CompactGroup}] {\Rep \lambda \BesselPotential {m + \gamma}}
                \label{eq:estimate_on_the_schatten_norm_of_sigma_epsilon}
            \end{align}
            for every $\gamma \leq 0$.

            The idea is now to pick $\gamma < \min \{0, -(\dim \Group + m)\}$, so that
            \begin{align}
                \abs{\kappa_{\epsilon, g}(h)}
                \leq \int_\VectorSpace \norm [\SchattenClasses 1 {\Lebesgue 2 \CompactGroup}] {\sigma_\epsilon(g, \lambda)} \dd \lambda
                \leq C
                \epsilon^{\gamma},
                \label{eq:estimate_on_the_smoothened_kernel}
            \end{align}
            where the last inequality was obtained by the Sobolev inequality (Proposition~\ref{proposition:Sobolev_embedding}).

            The idea is now to pick a suitable $\gamma \leq 0$ and obtain an estimate on the kernel via~\eqref{eq:estimate_on_the_smoothened_kernel}.
            Keeping in mind that $\epsilon = \norm [\Group] h$,
            let us now treat the different cases separately.
            \begin{description}
                \item[$\rho = 1$ and $m > -\dim \Group$.] We pick $\gamma < -(\dim \Group + m)$ to obtain
                    \begin{align*}
                        \abs {\kappa_{\epsilon, g}(h)}
                        &\leq C \norm [\Group] h^\gamma.
                    \end{align*}
                \item[$\rho < 1$ and $m > -\dim \Group$.]
                    We pick
                    \begin{align*}
                        \gamma \defeq -\frac {\dim \Group + m} \rho,
                    \end{align*}
                    and check that $\gamma < 0$ by the condition on $m$ and
                    $\gamma < -(\dim \Group + m)$ by our condition on $\rho$.

                    Therefore, \eqref{eq:estimate_on_the_smoothened_kernel} yields
                    \begin{align*}
                        \abs {\kappa_{\epsilon, g}(h)}
                        \leq C \norm [\Group] h^{-\frac {\dim \Group + m} {\rho}}.
                    \end{align*}

                    Note that we could get a better estimate here,
                    but we choose not to do so,
                    because in this setting our choice of $\gamma$ will turn out to be appropriate when estimating $\kappa_g - \kappa_{g, \epsilon}$.
                \item[$m = -\dim \Group$]
                    Letting $\gamma = 0$ in \eqref{eq:estimate_on_the_smoothened_kernel} yields
                    \begin{align*}
                        \abs {\kappa_{\epsilon, g}(h)}
                        \leq C \log \norm [\Group] h.
                    \end{align*}
            \end{description}

        \item[Estimate on $\kappa_g - \kappa_{g, \epsilon}$].
            The strategy of the proof is the same,
            but slightly more delicate.
            As $\gamma$ needs to be positive to apply Theorem~\ref{theorem:generalised_Littlewood-Paley_decomposition},
            we will need to apply difference operators so that $m$ would be replaced by $m - \rho \abs \alpha$,
            thus making it possible for $\gamma + m - \rho \abs \alpha$ to be small enough.

            By the Leibniz rule,
            we have
            \begin{align*}
                \DifferenceOperator \alpha (\sigma - \sigma_\epsilon)
                &= \lcsum{\abs {\alpha_1} + \abs {\alpha_2} = \abs \alpha}
                \DifferenceOperator {\alpha_1} \sigma \DifferenceOperator {\alpha_2} \eta_\lambda\\
                &= \lcsum{\abs {\alpha_1} + \abs {\alpha_2} = \abs \alpha}
                I_{1, \alpha_1} I_{2, \alpha_2, \gamma} I_{3, \gamma},
            \end{align*}
            where
            \begin{align*}
                I_{1, \alpha_1} &\defeq \DifferenceOperator {\alpha_1} \sigma(g, \lambda) \Rep \lambda \BesselPotential {-m + \rho \abs {\alpha_1}}\\
                I_{2, \alpha_2, \gamma} &\defeq \Rep \lambda \BesselPotential {m - \rho \abs {\alpha_1}} \DifferenceOperatorOrder {\alpha_2} (\Id {\Lebesgue 2 \CompactGroup} - \eta_\epsilon(\lambda))\\
                &\qquad \qquad\Rep \lambda \BesselPotential {-\gamma + \rho \abs {\alpha_2} - m + \rho \abs {\alpha_1})}\\
                I_{3, \gamma} &\defeq \Rep \lambda \BesselPotential {\gamma + m - \rho \abs \alpha}
            \end{align*}

            Since $\sigma \in \SymbolClass m {\rho, \delta}$,
            $\norm [\Lin {\Lebesgue 2 \CompactGroup}] {I_{1, \alpha_1}}$ is bounded uniformly in $\alpha_1$,
            while
            \begin{align*}
                \norm [\Lin {\Lebesgue 2 \CompactGroup}] {I_{2, \alpha_2, \gamma}}
                \leq C \epsilon^\gamma
            \end{align*}
            holds for every $\gamma \geq 0$ by Theorem~\ref{theorem:generalised_Littlewood-Paley_decomposition}.
            Therefore, for every $\gamma \geq 0$, we have
            \begin{align*}
                &\norm [\SchattenClasses 1 {\Lebesgue 2 \CompactGroup}] {\DifferenceOperator \alpha (\sigma - \sigma_\epsilon)(g, \lambda)}\\
                & \qquad \leq C \epsilon^\gamma
                \norm [\SchattenClasses 1 {\Lebesgue 2 \CompactGroup}] {\Rep \lambda \BesselPotential {\gamma + m - \rho \abs \alpha}},
            \end{align*}
            where the Schatten norm on the right hand side is not necessarily finite.

            Integrating the above with respect to $\lambda \in \VectorSpace$,
            we obtain
            \begin{align*}
                \abs {(q^\alpha(\kappa_g - \kappa_{g, \epsilon}))(h)}
                \leq C \epsilon^\gamma
            \end{align*}
            provided that $\gamma \geq 0$ and $\gamma + m - \rho \abs \alpha < -\dim \Group$.
            Observe that those two conditions can be summarised by the inequality
            \begin{align*}
                0 \leq \gamma < \rho \abs \alpha - (\dim \Group + m).
            \end{align*}

            Since for every $r \in 2 \N$, we have
            \begin{align*}
                \norm [\Group] h^r \abs{(\kappa_g - \kappa_{g, \epsilon})(h)}
                &\leq C \sum_{\abs \alpha = r} \abs{q^\alpha(h) (\kappa_g - \kappa_{g, \epsilon})(h)},
            \end{align*}
            we have so far shown, keeping in mind that $\epsilon = \norm [\Group] h$ that
            \begin{align}
                \abs{(\kappa_g - \kappa_{g, \epsilon})(h)}
                &\leq C \norm [\Group] h^{\gamma - r}
                \label{eq:estimate_on_the_remainder}
            \end{align}
            provided $0 \leq \gamma < \rho r - (\dim \Group + m)$.

            We observe that the best estimate is achieved when
            \begin{align*}
                r \defeq \min \{n \in 2 \N : n > \frac{\dim \Group + m} \rho \}
            \end{align*}
            because it should be as small as possible,
            but also the condition on $\gamma$ must be possible.

            Let us now treat the different cases.
            \begin{description}
                \item[$\rho = 1$ and $m > -\dim \Group$]
                    Choose $\tilde \gamma \defeq \gamma - r$
                    so that $-r \leq \tilde \gamma < -(\dim \Group + m)$.
                    Clearly, we have
                    \begin{align*}
                        \abs{(\kappa_g - \kappa_{g, \epsilon})(h)}
                        \leq \norm [\Group] h^{\tilde \gamma}.
                    \end{align*}
                \item[$\rho < 1$ and $m > -\dim \Group$]
                    Pick $\gamma$ as follows:
                    \begin{align*}
                        \gamma - r = -\frac{\dim \Group + m} \rho.
                    \end{align*}
                    We check that
                    \begin{align*}
                        \gamma = r - \frac {\dim \Group + m} \rho > 0,
                    \end{align*}
                    and similarly,
                    \begin{align*}
                        \gamma - \rho r &= r(1 - \rho) - \frac {\dim \Group + m} \rho\\
                        &= -\rho r(1 - \frac 1 \rho) - (\dim \Group + m) \frac 1 \rho\\
                        &< -(\dim \Group + m)(1 - \frac 1 \rho + \frac 1 \rho),
                    \end{align*}
                    which can be rewritten as $\gamma < \rho r - (\dim \Group + m)$.
                    Note that we could not have obtained the strict inequality above
                    had we not assumed that $\rho < 1$.
                    We can thus apply~\eqref{eq:estimate_on_the_remainder} to obtain
                    \begin{align*}
                        \abs{(\kappa_g - \kappa_{g, \epsilon})(h)}
                        \leq \norm [\Group] h^{-\frac {\dim \Group + m} \rho}
                    \end{align*}
            \end{description}
    \end{description}
    The kernel estimates now follow from the triangle inequality.
\end{proof}

\begin{remark}[Kernel estimates when $m = -\dim \Group$]
    We might wonder whether it is possible to obtain better estimates for the case $m = -\dim \Group$
    than the ones they inherit from the symbol classes inclusion.

    Let $h \in \Group$ be such that $\epsilon \defeq \norm [\Group] h \in (0, 1]$
    Writing
    \begin{align*}
        \sigma_\epsilon(g, \lambda)
        = \sigma(g, \lambda) \Rep \lambda \BesselPotential {-m} \eta_\epsilon(\lambda) \Rep \lambda \BesselPotential {m},
    \end{align*}
    we see that
    \begin{align*}
        \abs {\kappa_{\epsilon, g}}
        &\leq C \int_\VectorSpace \norm [\SchattenClasses 1 {\Lebesgue 2 \CompactGroup}] {\eta_\epsilon(\lambda) \Rep \lambda \BesselPotential m}\\
        &\leq C \log \epsilon = C \log \norm [\Group] h,
    \end{align*}
    which is better than what Theorem~\ref{theorem:kernel_estimates:at_origin} gives us.

    Unfortunately,
    a similar estimate cannot be achieved for $\kappa_g - \kappa_{\epsilon, g}$.
    This can be seen by setting
    \begin{align*}
        \sigma(g, \lambda) \defeq \Rep \lambda \BesselPotential {-\dim \Group}
    \end{align*}
    and observing that
    $\abs {\kappa_g - \kappa_{\epsilon, g}}$ could not be bounded.
\end{remark}

\section{Adjoint and composition formulas}

\subsection{Asymptotic sums of symbols}

More complex operations on operators
like composition and adjunction
cannot be written in terms of symbols without using a Taylor development on the kernel side.
This yields an infinite sum of symbols,
and we need to find out whether it converges in a satisfactory sense for our purposes.

\begin{proposition}[Asymptotic sum]
\label{proposition:asymptotic_sum_of_symbols}
    Given $1 \geq \rho \geq \delta \geq 0$,
    let $(\sigma_j)_{j \in \N}$ be a sequence of symbols such that $\sigma_j \in \SymbolClass {m_j} {\rho, \delta}$,
    where $(m_j)_{j \in \N}$ is a \emph{strictly decreasing} sequence of real numbers.

    There exists a symbol $\sigma \in \SymbolClass {m_0} {\rho, \delta}$
    such that
    \begin{align}
        \sigma - \sum_{j = 0}^N \sigma_j \in \SymbolClass {m_{N + 1}} {\rho, \delta}
        \label{eq:asymptotic_sum_of_symbols}
    \end{align}
    for each $N \in \N$.
    Moreover, $\sigma$ is unique modulo $\SmoothingSymbols$.
\end{proposition}

\begin{definition}[Asymptotic sum]
    With the notation of Proposition~\ref{proposition:asymptotic_sum_of_symbols},
    we shall write
    \begin{align*}
        \sigma \sim \sum_{j = 0}^{+\infty} \sigma_j
    \end{align*}
    when~\eqref{eq:asymptotic_sum_of_symbols} holds for each $N \in \N$.
\end{definition}

\begin{proof}[Proof of Proposition~\ref{proposition:asymptotic_sum_of_symbols}]
    First, choose a cut-off function $\chi \in \SmoothFunctions {\R^+}$ such that
    \begin{align*}
        \chi(r) =
        \begin{cases}
            0 & \text{if } r \leq \frac 1 2\\
            1 & \text{if } r \geq 1
        \end{cases}
    \end{align*}
    Using Theorem~\ref{theorem:generalised_Littlewood-Paley_decomposition},
    for each $l \in \N$ we can find $C_l \geq 0$ and $N_l \in \N$ such that
    \begin{align*}
        \SymbolSemiNorm {m_0} {\rho, \delta} l {\sigma_j \eta^\chi_\epsilon}
        \leq C_l \SymbolSemiNorm {m_0} {\rho, \delta} {N_l} {\sigma_j}
        \epsilon^{m_0 - m_j}
    \end{align*}
    for each $0 < \epsilon \leq 1$ and each $j \in \N$.
    Without loss of generality,
    we assume that $N_l \geq l$.

    Choosing a decreasing sequence of sufficiently small $\epsilon_j > 0$, $j \in \N$
    so that the right-hand side of the above satisfies
    \begin{align*}
        C_j \SymbolSemiNorm {m_0} {\rho, \delta} {N_j} {\sigma_j} \epsilon_j^{m_0 - m_j}
        \leq 2^{-j},
    \end{align*}
    we now obtain that the symbols
    \begin{align*}
        \tilde \sigma_j \defeq \sigma_j \eta^\chi_{\epsilon_j}
    \end{align*}
    satisfy the estimate
    \begin{align}
        \SymbolSemiNorm {m_0} {\rho, \delta} j {\tilde \sigma_j}
        \leq 2^{-j}.
        \label{eq:dyadic_decay_in_asymptotic_sum_of_modified_symbols}
    \end{align}

    Fix $l \in \N$.
    we have
    \begin{align}
        \sum_{j = 0}^\infty \SymbolSemiNorm {m_0} {\rho, \delta} l {\tilde \sigma_j}
        &\leq \sum_{j = 0}^l \SymbolSemiNorm {m_0} {\rho, \delta} l {\tilde \sigma_j}
        + \sum_{j = l + 1}^{+\infty} \SymbolSemiNorm {m_0} {\rho, \delta} {j} {\tilde \sigma_j} \notag\\
        &\leq \sum_{j = 0}^l \SymbolSemiNorm {m_0} {\rho, \delta} l {\tilde \sigma_j}
        + \sum_{j = l + 1}^{+\infty} 2^{-j} < + \infty,
        \label{eq:convergence_of_asymptotic_sum_of_modified_symbols}
    \end{align}
    where the last line was obtained by applying~\eqref{eq:dyadic_decay_in_asymptotic_sum_of_modified_symbols}.
    As $\SymbolClass {m_0} {\rho, \delta}$ is a Fr\'echet space,
    it follows from REF that the sum
    \begin{align*}
        \sum_{j = 0}^{+\infty} \tilde \sigma_j
    \end{align*}
    converges to some $\sigma \in \SymbolClass {m_0} {\rho, \delta}$.

    For each $N \in \N$,
    applying~\eqref{eq:convergence_of_asymptotic_sum_of_modified_symbols} to the sequence $\tilde \sigma'_j \defeq \tilde \sigma_{j + N + 1}$,
    we have thus shown that
    \begin{align}
        \sum_{j = N + 1}^{+\infty} \tilde \sigma_j
        \in \SymbolClass {m_{N + 1}} {\rho, \delta}.
        \label{eq:remander_of_asymptotic_sum_of_modified_symbols}
    \end{align}

    By Theorem~\ref{theorem:generalised_Littlewood-Paley_decomposition},
    it follows that
    \begin{align}
        (\Id {\Lebesgue 2 \CompactGroup} - \eta^\chi_{\epsilon_j})
        = \eta^{1 - \chi}_{\epsilon_j} \in \SmoothingSymbols,
        \label{eq:smoothing_part_of_asymptotic_sum}
    \end{align}
    since $1 - \chi$ has compact support.
    Therefore,
    it follows that for each $N \in \N$,
    we have
    \begin{align*}
        \sigma - \sum_{j = 0}^N \sigma_j
        &= \sum_{j = 0}^{+\infty} \sigma_j \eta^\chi_{\epsilon_j} - \sum_{j = 0}^N \sigma_j\\
        &= \sum_{j = 0}^N \sigma_j (\eta^{\chi}_{\epsilon_j} - \Id {\Lebesgue 2 \CompactGroup}) + \sum_{j = N + 1}^{+\infty} \tilde \sigma_j,
    \end{align*}
    which, if combined with~\ref{eq:remander_of_asymptotic_sum_of_modified_symbols}
    and~\ref{eq:smoothing_part_of_asymptotic_sum},
    means that
    \begin{align*}
        \sigma - \sum_{j = 0}^N \sigma_j
        \in \SymbolClass {m_{N + 1}} {\rho, \delta}.
    \end{align*}
    We have thus shown~\eqref{eq:asymptotic_sum_of_symbols}.

    Let us now check the uniqueness of $\sigma$ modulo $\SmoothingSymbols$.
    To this end,
    assume that $\tau$ also satisfies~\eqref{eq:asymptotic_sum_of_symbols}
    and fix $N \in \N$.
    It is clear that
    \begin{align*}
        \sigma - \tau
        = \left(\sigma - \sum_{j = 0}^N \sigma_j\right) -
        \left(\tau - \sum_{j = 0}^N \sigma_j\right)
        \in \SymbolClass {m_{N + 1}} {\rho, \delta}.
    \end{align*}

    As $N$ is arbitrary
    and $m_{N + 1}$ decreases to $-\infty$ as $N \to +\infty$,
    it follows that $\sigma - \tau \in \SmoothingSymbols$.
\end{proof}

\subsection{Adjoint formula}

\subsection{Composition formula}

First, we show that $\SmoothingOperators$ is stable under composition.

\begin{lemma}
    Let $\sigma_1, \sigma_2 \in \SmoothingSymbols$
    and denote by $\kappa_1$ and $\kappa_2$ their respective associated kernels.
    We also set
    \begin{align*}
        \kappa_g(h) \defeq \int_\Group \kappa_{2, g l^{-1}}(h l^{-1}) \kappa_{1, g}(l) \dd l
    \end{align*}
    for each $g, h \in \Group$,
    and subsequently define the map
    \begin{align*}
        \sigma(g, \lambda) \defeq \Fourier \kappa_g(\lambda),
        \quad g \in \Group, \lambda \in \VectorSpace.
    \end{align*}

    The map $\sigma$ defined above is a smoothing symbol for which
    \begin{align}
        \sigma(g, \lambda) = \int_\Group \kappa_{1, g}(l) \adj {\Rep \lambda(l)} \sigma_2(g l^{-1}, \lambda) \dd l
        \label{eq:formal_expression_for_the_symbol_obtained_by_composition}
    \end{align}
    holds for all $g \in \Group$ and $\lambda \in \VectorSpace$.
\end{lemma}
\begin{proof}
    % Check it defines a symbol
    It should be clear that $\kappa$ is smooth on $\Group \times \Group$.
    To show that the Fourier transform of $\kappa_g$ is well defined,
    check that $\kappa_g \in \Lebesgue 1 \CompactGroup$.
    Indeed,
    \begin{align*}
        \int_\Group \abs{\kappa_g(h)} \dd h
        &\leq \int_\Group \int_\Group \abs {\kappa_{2, g l^{-1}}(h l^{-1}) \kappa_{1, g}(l)} \dd l \dd h\\
        &\leq \max_{g' \in \Group} \int_\Group \abs {\kappa_{2, g'}(h')} \dd h'
        \int_\Group \abs{\kappa_{1, g}(l)} \dd l
    \end{align*}

    Let us check that $\kappa_g$ is the kernel of $\Op(\sigma_1) \Op(\sigma_2)$.
    Applying the quantisation formula twice (Proposition~\ref{proposition:quantisation}),
    we obtain
    \begin{align*}
        \Op(\sigma_1) \Op(\sigma_2) \phi(g)
        &= \int_\Group \Op(\sigma_2) \phi(h) \kappa_1(g, h^{-1} g) \dd h\\
        &= \int_\Group \int_\Group \phi(l) \kappa_2(h, l^{-1} h) \kappa_1(g, h^{-1} g) \dd l \dd h.
    \end{align*}

    In the right hand side of the above,
    we can let $m = h^{-1} g$ to obtain
    \begin{align*}
        \Op(\sigma_1) \Op(\sigma_2) \phi(g)
        &= \int_\Group \phi(l) \int_\Group \kappa_2(g m^{-1}, l^{-1} x m^{-1}) \kappa_1(g, m) \dd m \dd l\\
        &= \int_\Group \phi(l) \kappa_g(l^{-1} g) \dd l
        = \conv \phi {\kappa_g}(g),
    \end{align*}
    which means that $\Op(\sigma_1) \Op(\sigma_2) = \Op(\sigma)$.

    From there, let us try to obtain a more explicit formula describing $\sigma$.
    Taking the Fourier Transform,
    we get
    \begin{align*}
        \sigma(g, \lambda)
        &= \int_\Group \kappa_g(h) \adj{\Rep \lambda(h)} \dd h\\
        &= \int_\Group \int_\Group \kappa_2(g m^{-1}, h m^{-1}) \kappa_1(x, m) \adj{\Rep \lambda(m)} \adj{\Rep \lambda(h m^{-1})} \dd h \dd m\\
        &= \int_\Group \kappa_1(g, m) \adj{\Rep \lambda(m)} \sigma_2(g m^{-1}, \lambda) \dd m,
    \end{align*}
    concluding the proof.
\end{proof}

\begin{lemma}
    Let $\sigma \in \SymbolClass m {\rho, \delta}$ with $1 \geq \rho \geq \delta \geq 0$ with $\rho \neq 0$,
    and denote by $\kappa$ its associated kernel.
    If $\gamma \in \R$ satisfies
    \begin{align*}
        \gamma > \max \left\{\frac {m + \dim \Group} \rho, 0\right\} - \dim \Group,
    \end{align*}
    then we can find $C \geq 0$ and $N \in \N$ such that
    \begin{align*}
        \int_\Group \norm [\Group] h^\gamma \abs {\kappa_g(h)} \dd h
        \leq C \SymbolSemiNorm m {\rho, \delta} N \sigma.
    \end{align*}
\end{lemma}
\begin{proof}
    We split the above integral like this
    \begin{align*}
        \int_\Group \dd h
        = \int_{\norm [\Group] h \leq 1} \dd h
        + \int_{\norm [\Group] h \geq 1} \dd h
    \end{align*}

    \begin{description}
        \item [Integral on] $\norm [\Group] h \geq 1$

            By Part~\eqref{item:kernel_estimates:at_infinity} of
            Theorem~\ref{theorem:kernel_estimates},
            for each $M \in \N$ we can find $N \in \N$ such that
            \begin{align*}
                \sup_{\norm [\Group] {h} \geq 1} \abs {\kappa_g(h)}
                \leq C \SymbolSemiNorm m {\rho, \delta} N \sigma \norm [\Group] h^{-M}.
            \end{align*}

            Taking $M$ sufficiently large, it implies that
            \begin{align*}
                \int_{\norm [\Group] h \geq 1} \norm [\Group] h^\gamma \abs {\kappa_g(h)} \dd h
                \leq C \SymbolSemiNorm m {\rho, \delta} N \sigma,
            \end{align*}
            as required.

        \item [Integral on] $\norm [\Group] h \leq 1$

            If $m \geq -\dim \CompactGroup$,
            then by Part~\eqref{item:kernel_estimates:at_origin:positive} of Theorem~\ref{theorem:kernel_estimates} implies
            that if we pick $\tilde \gamma$ satisfying
            \begin{align}
                \begin{cases}
                    \gamma + \dim \Group > \tilde \gamma > \frac {m + \dim \Group} \rho & \text{if } m \geq \dim \Group\\
                    \tilde \gamma = 0 & \text{if } m < -\dim \Group
                \end{cases},
                \label{eq:consequence_of_kernel_estimates:choice_of_tilde_gamma}
            \end{align}
            there exists $N \in \N$ such that
            \begin{align*}
                \sup_{0 < \norm [\Group] h \leq 1} \abs{\kappa_g(h)}
                \leq
                    C \SymbolSemiNorm m {\rho, \delta} N \sigma \norm [\Group] h^{\tilde \gamma}.
            \end{align*}

            From there, it follows that
            \begin{align*}
                \int_{\norm [\Group] h \leq 1} \norm [\Group] h^\gamma \abs {\kappa_g(h)} \dd h \leq
                C \SymbolSemiNorm m {\rho, \delta} N \sigma
                \int_{\norm [\Group] h \leq 1}
                \norm [\Group] h^{\gamma + \tilde \gamma}.
            \end{align*}

            We conclude the proof by observing that ~\eqref{eq:consequence_of_kernel_estimates:choice_of_tilde_gamma}
            implies
            \begin{align*}
                \gamma + \tilde \gamma > -\dim \Group.
            \end{align*}
            which means that the above integral is finite.
    \end{description}
\end{proof}

\begin{lemma}
    Let $m_1, m_2 \in \R$ and suppose $\rho, \delta \in \R$ are chosen such that $1 \geq \rho > \delta \geq 0$.
    % TODO: Add conditions on constants

    There exists $C \geq 0$ and an $N \in \N$ such that
    for any $\sigma_1, \sigma_2 \in \SmoothingSymbols$ and any $(g, \lambda) \in \Group \times \VectorSpace$,
    we have
    \begin{align*}
        &\norm [\Lin {\Lebesgue 2 \CompactGroup}] {%
            \LeftDifferentialOperator [g]  \beta \left(
                \sigma_1 \circ \sigma_2(g, \lambda)
                - \sum_{\abs \alpha \leq M} \sigma_1(g, \lambda) \LeftDifferentialOperator [g] \alpha \sigma_2(x, \lambda)
            \right)
        }\\
        &\qquad \leq C \SymbolSemiNorm {m_1, R} {\rho, \delta} N {\sigma_1} \SymbolSemiNorm {m_2} {\rho, \delta} N {\sigma_2}
    \end{align*}
\end{lemma}
\begin{proof}
    For each $N \in \N$,
    let us define
    \begin{align*}
        \tau_N(g, \lambda) \defeq
        \sigma(g, \lambda) - \sum_{\abs \alpha \leq N} \DifferenceOperatorOrder \alpha \sigma_1(g, \lambda) \TaylorLeftDifferentialOperator \alpha \sigma_2(g, \lambda)
    \end{align*}
    We want to estimate
    \begin{align}
        &\tau_N(g, \lambda) \notag\\
        &= \int_\Group \kappa_{1, g}(h) \adj{\Rep \lambda(h)}
        \left(\sigma_2(g h^{-1}, \lambda) - \sum_{\abs \alpha \leq N} q_\alpha(h^{-1}) \TaylorLeftDifferentialOperator \alpha \sigma_2(g, \lambda)\right) \dd h \notag\\
        &= \int_\Group \kappa_{1, g}(h) \adj {\Rep \lambda(h)} \TaylorRemainder {\sigma_2(g \dummy, \lambda)} {e_\Group} N (h^{-1}) \dd h.
        \label{eq:remainder_of_composition_formula}
    \end{align}

    Let $\alpha_0 \in \N^{\dimDifferenceOperators}$ and $\beta_0 \in \N^{\dim \Group}$.
    Applying the Leibniz-like rule for difference operators
    and the Leibniz rule for left-invariant differential operators,
    we obtain
    \begin{align*}
        &\LeftDifferentialOperator {\beta_0} \DifferenceOperatorOrder {\alpha_0} \tau_N(g, \lambda) =\\
        &\sum_{%
            \substack{%
                \abs{\alpha_0} \leq \abs{\alpha_{01}} + \abs{\alpha_{02}} \leq 2 \abs{\alpha_0}\\
                \beta_{01} + \beta_{02} = \beta_0
            }
        }
        \int_\Group q^{\alpha_{01}}(h) \LeftDifferentialOperator [g] {\beta_{01}} \kappa_{1, g}(h) \adj{\Rep \lambda(h)}
        \TaylorRemainder {\LeftDifferentialOperator [g_2 = g] {\beta_{02}} \DifferenceOperatorOrder {\alpha_{02}} \sigma_2(g_2 \dummy, \lambda)} {e_\Group} N (h^{-1}) \dd h.
    \end{align*}

    Now, we would like to introduce powers of $\Rep \lambda \BesselPotential 1$ near $\sigma_2$,
    which will allow to estimate the above in terms of the symbol semi-norms of $\sigma_2$.
    To this end,
    observe that if $M \in 2 \N$,
    \begin{align*}
        \adj{\Rep \lambda(h)}
        &= \adj{\Rep \lambda(h)} \Rep \lambda \BesselPotential M \Rep \lambda \BesselPotential {-M}\\
        &= \lcsum{\abs \beta \leq M} \adj{\Rep \lambda(h)} \Rep \lambda(X)^\beta \Rep \lambda \BesselPotential {-M},
    \end{align*}
    which, after using $\adj {\Rep \lambda(h)} \Rep \lambda (X)^\beta = (-1)^{\abs \beta} \adj {(\RightDifferentialOperator[h] \beta \Rep \lambda (h))}$, becomes
    \begin{align*}
        \adj{\Rep \lambda(h)}
        &= \lcsum{\abs \beta \leq M} \adj{(\RightDifferentialOperator \beta \Rep \lambda(h))} \Rep \lambda \BesselPotential {-M},
    \end{align*}

    Therefore,
    injecting the above into \eqref{eq:remainder_of_composition_formula} and using integration by parts yields
    \begin{align*}
        &\LeftDifferentialOperator {\beta_0} \DifferenceOperatorOrder {\alpha_0} \tau_N(g, \lambda) =\\
        &\quad \lcsum{%
            \substack{%
                \abs{\alpha_0} \leq \abs{\alpha_{01}} + \abs{\alpha_{02}} \leq 2 \abs{\alpha_0}\\
                \beta_{01} + \beta_{02} = \beta_0\\
                \abs {\beta_1} + \abs {\beta_2} \leq M
            }
        }
        \int_\Group \RightDifferentialOperator[h_1 = h] {\beta_1} (\LeftDifferentialOperator [g] {\beta_{01}} q^{\alpha_{01}} \kappa_{1, g})(h_1) \adj {\Rep \lambda(h)}\\
        &\quad \times
        \RightDifferentialOperator[h_2 = h] {\beta_2} \TaylorRemainder {\Rep \lambda \BesselPotential {-M} \LeftDifferentialOperator [g_2 = g] {\beta_{02}} \DifferenceOperatorOrder {\alpha_{02}} \sigma_2(g_2 \dummy, \lambda)} {e_\Group} N (h_2^{-1}) \dd h,
    \end{align*}
    Now, using REFERENCE, %TODO add reference
    the above becomes
    \begin{align*}
        &\LeftDifferentialOperator {\beta_0} \DifferenceOperatorOrder {\alpha_0} \tau_N(g, \lambda) =\\
        &\quad \lcsum{%
            \substack{%
                \abs{\alpha_0} \leq \abs{\alpha_{01}} + \abs{\alpha_{02}} \leq 2 \abs{\alpha_0}\\
                \beta_{01} + \beta_{02} = \beta_0\\
                \abs {\beta_1} + \abs {\beta_2} \leq M
            }
        }
        \int_\Group \RightDifferentialOperator[h_1 = h] {\beta_1} (\LeftDifferentialOperator [g] {\beta_{01}} q^{\alpha_{01}} \kappa_{1, g})(h_1) \adj {\Rep \lambda(h)}\\
        &\quad \times
        \TaylorRemainder {\Rep \lambda \BesselPotential {-M} \LeftDifferentialOperator [g_2 = g] {\beta_{02}} \LeftDifferentialOperator {\beta_2} \DifferenceOperatorOrder {\alpha_{02}} \sigma_2(g_2 \dummy, \lambda)} {e_\Group} {N - \abs {\beta_2}} (h_2^{-1}) \dd h.
    \end{align*}

    Therefore,
    if we take the operator norm,
    we obtain
    \begin{align*}
        &\norm [\Lin {\Lebesgue 2 \CompactGroup}] {\LeftDifferentialOperator {\beta_0} \DifferenceOperatorOrder {\alpha_0} \tau_n(g, \lambda)}\\
        &\quad \lcsum{%
            \substack{%
                \abs{\alpha_0} \leq \abs{\alpha_{01}} + \abs{\alpha_{02}} \leq 2 \abs{\alpha_0}\\
                \beta_{01} + \beta_{02} = \beta_0\\
                \abs {\beta_1} + \abs {\beta_2} \leq M
            }
        }
        \int_\Group \abs {\RightDifferentialOperator[h_1 = h] {\beta_1} (\LeftDifferentialOperator [g] {\beta_{01}} q^{\alpha_{01}} \kappa_{1, g})(h_1)}\\
        &\quad \times
        \norm [\Lin {\Lebesgue 2 \CompactGroup}] {%
            \TaylorRemainder {\Rep \lambda \BesselPotential {-M} \LeftDifferentialOperator [g_2 = g] {\beta_{02}} \LeftDifferentialOperator {\beta_2} \DifferenceOperatorOrder {\alpha_{02}} \sigma_2(g_2 \dummy, \lambda)} {e_\Group} {N - \abs {\beta_2}} (h_2^{-1})
        } \dd h.
    \end{align*}

    Applying the Taylor Remainder Theorem,
    we have
    % TODO: reference
    \begin{align*}
        &\norm [\Lin {\Lebesgue 2 \CompactGroup}] {\TaylorRemainder {\Rep \lambda \BesselPotential {-M} \LeftDifferentialOperator [g_2 = g] {\beta_{02}} \LeftDifferentialOperator {\beta_2} \DifferenceOperatorOrder {\alpha_{02}} \sigma_2(g_2 \dummy, \lambda)} g {N - \abs {\beta_2}} (h^{-1})}\\
        &\ \leq
        \sup_{\abs \gamma \leq N - \abs {\beta_2} + 1}
        \norm [\Group] h^{N - \abs {\beta_2} + 1}
        S(M, \gamma, \beta_{02}, \beta_2, \alpha_{02}),
    \end{align*}
    where
    \begin{align*}
        S(M, &\gamma, \beta_{02}, \beta_2, \alpha_{02}) \defeq
        \sup_{g_1 \in \Group}\\
        &\norm [\Lin {\Lebesgue 2 \CompactGroup}] {%
            \Rep \lambda \BesselPotential {-M}
            \LeftDifferentialOperator [g_1] {\gamma}
            \LeftDifferentialOperator [g_2 = g] {\beta_{02}}
            \LeftDifferentialOperator [g_1] {\beta_2}
            \DifferenceOperatorOrder {\alpha_{02}}
            \sigma_2(g_2 g_1, \lambda)
        }.
    \end{align*}

    We have thus shown so far that
    \begin{align*}
        &\norm [\Lin {\Lebesgue 2 \CompactGroup}] {\sigma(g, \lambda) - \sum_{\abs \alpha \leq N} \DifferenceOperatorOrder \alpha \sigma_1(g, \lambda) \TaylorLeftDifferentialOperator \alpha \sigma_2(g, \lambda)}\\
        &\leq
        \lcsum{\abs {\beta_1} + \abs {\beta_2} \leq 2M}
        \sup_{\abs \gamma \leq N - \abs {\beta_2} + 1}
        S(M, \gamma, \beta_{02}, \beta_2, \alpha_{02})\\
        &\qquad \qquad
        \int_\Group \abs {\RightDifferentialOperator[h_1 = h] {\beta_1} (\LeftDifferentialOperator [g] {\beta_{01}} q^{\alpha_{01}} \kappa_{1, g})(h_1)} \norm [\Group] h^{N - \abs {\beta_2} + 1} \dd h.
    \end{align*}

    \begin{align*}
        \begin{cases}
            m_1 - \rho \abs {\alpha_{01}} + \delta \abs {\beta_{01}} + \abs {\beta_1} + \dim \Group < \rho (\dim \Group + N - \abs {\beta_2} + 1)\\
            -M + \delta(\abs \gamma + \abs {\beta_{02}} + \abs {\beta_2}) - \rho \abs {\alpha_{02}} \leq -m_2.
        \end{cases}
    \end{align*}
    and for that it suffices that
    \begin{align*}
        \begin{cases}
            m_1 + \delta \abs {\beta_{0}} + 2 M + \dim \Group < \rho \dim \Group\\
            -2M + \delta(N + 1 + \abs {\beta_{0}}) \leq -m_2.
        \end{cases}
    \end{align*}

    Note that both conditions above can be rewritten
    \begin{align*}
        m_2 + \delta(N + 1 + \abs {\beta_0})
        \leq 2M <
        -\dim \Group - m_1 - \delta \abs {\beta_0} + \rho \dim \Group
    \end{align*}
\end{proof}

\section{\texorpdfstring{$L^p$}{Lp} boundedness}

\subsection{\texorpdfstring{$L^2$}{L2} boundedness}

% TODO: Place this proposition
\begin{proposition}
    Let $\sigma \in \SymbolClass m {\rho, \delta}$,
    where $m < -\dim \Group / 2$ and $\rho, \delta \in [0, 1]$.
    The operator associated with $\sigma$, $\Op(\sigma)$, has a continuous extension
    \begin{align*}
        \Op(\sigma) : \Lebesgue 2 \Group \to \Lebesgue 2 \Group.
    \end{align*}
    Moreover,
    \begin{align*}
        \norm [\Lin {\Lebesgue 2 \Group}] {\Op(\sigma)}
        \leq C \SymbolSemiNorm m {\rho, \delta} N \sigma.
    \end{align*}
\end{proposition}
\begin{proof}
    First, let us observe that for each $g_0 \in \Group$, we have
    \begin{align*}
        \sup_{g \in \Group} \abs {T f(g_0 g)}
        &\leq \int_\Group \abs{f(g_0 g h^{-1}) \kappa_{g_0 g}(h)} \dd h\\
        &\leq \norm [\Lebesgue 2 \Group] {(1 + \norm [\Group] \dummy^2)^{-N} f(g_0 \dummy)} \norm [\Lebesgue 2 \Group] {(1 + \norm [\Group] \dummy^2)^N \kappa_{g_0 g}},
    \end{align*}
    where the last line was obtained by the Cauchy-Schwartz inequality.

    Integrating the above with respect to $g$ over $\Ball [\Group] {g_0} 1$,
    we obtain
    \begin{align}
        \int_{\Ball [\Group] {g_0} 1} \abs {T f(g)}^2 \dd g
        &= \int_{\Ball [\Group] e 1} \abs {T f(g_0 g)}^2 \dd g\notag\\
        &\leq C \SymbolSemiNorm m {\rho, \sigma} ? \sigma^2
        \norm [\Lebesgue 2 \Group] {(1 + \norm [\Group] \dummy^2)^{-N} f(g_0 \dummy)}^2.
        \label{eq:integral_of_Tf_on_ball_of_radius_1}
    \end{align}

    To conclude the proof,
    we shall integrate each side of the above with respect to $g_0 \in \Group$.

    For the left-hand side,
    a simple application of the Fubini-Tonnelli Theorem yields
    \begin{align*}
        \int_\Group \int_{\Ball [\Group] {g_0} 1} \abs {T f(g)}^2 \dd g \dd g_0
        &= \int_\Group \int_\Group 1_{\norm [\Group] {g_0^{-1} g} \leq 1} \abs {T f(g)}^2 \dd g_0 \dd g\\
        &= \int_\Group \int_\Group 1_{\norm [\Group] {g_0^{-1} g} \leq 1} \abs {T f(g)}^2 \dd g_0 \dd g,
    \end{align*}
    so that the change of variable $h = g_0^{-1} g$ yields
    \begin{align}
        \int_\Group \int_{\Ball [\Group] {g_0} 1} \abs {T f(g)}^2 \dd g \dd g_0
        = C \norm [\Lebesgue 2 \Group] {T f}^2.
        \label{eq:left_hand_side_of_ball_integral_for_L2_boundedness}
    \end{align}

    Now, integrating the right-hand side of~\eqref{eq:integral_of_Tf_on_ball_of_radius_1},
    we obtain
    \begin{align*}
        \int_\Group &\norm [\Lebesgue 2 \Group] {(1 + \norm [\Group] \dummy^2)^{-N} f(g_0 \dummy)}^2 \dd g_0\\
        &\quad = \int_\Group \int_\Group \abs{(1 + \norm [\Group] g^2)^{-N} f(g_0 g)}^2 \dd g \dd g_0\\
        &\quad = \norm [\Lebesgue 2 \Group] f^2 \int_\Group (1 + \norm [\Group] g^2)^{-2 N} \dd g.
    \end{align*}

    Choosing $N$ sufficiently large,
    we therefore get that
    \begin{align}
        \int_\Group &\norm [\Lebesgue 2 \Group] {(1 + \norm [\Group] \dummy^2)^{-N} f(g_0 \dummy)}^2 \dd g_0
        \leq C \norm [\Lebesgue 2 \Group] f^2
        \label{eq:right_hand_side_of_ball_integral_for_L2_boundedness}
    \end{align}

    Therefore,
    using~\eqref{eq:right_hand_side_of_ball_integral_for_L2_boundedness}
    and~\eqref{eq:left_hand_side_of_ball_integral_for_L2_boundedness}
    in~\eqref{eq:integral_of_Tf_on_ball_of_radius_1},
    we obtain
    \begin{align*}
        \norm [\Lebesgue 2 \Group] {T f}^2
        &\leq C \SymbolSemiNorm m {\rho, \sigma} ? \sigma^2
        \norm [\Lebesgue 2 \Group] {(1 + \norm [\Group] \dummy^2)^{-N} f(g_0 \dummy)}^2,
    \end{align*}
    which concludes the proof.
\end{proof}

The aim of this subsection is to prove
that symbols of order $0$ induce bounded operators in $\Lebesgue 2 \Group$
when $\rho > \delta$.

These results would naturally generalise to symbols of order $m$ as follows:
if $\sigma \in \SymbolClass m {\rho, \delta}$,
where $\rho, \delta$ satisfy either of the conditions above,
then $\Op(\sigma)$ extends continuously to a continuous operator
\begin{align*}
    \Op(\sigma) : \Sobolev s \to \Sobolev {s - m}
\end{align*}
for every $s \in \R$.

Suppose that $\sigma_T \in \SymbolClass 0 {\rho, \delta}$ for $0 \leq \delta < \rho \leq 1$.
One way of showing that $T \defeq \Op(\sigma_T)$ is bounded would be to find $S \in \OperatorClass 0 {\rho, \delta}$ such that
\begin{align}
    \adj T T = C \Id {\Schwartz \Group} - \adj S S + R,
    \label{eq:L2_boundedness_decomposition}
\end{align}
where $R \in \OperatorClass m {\rho, \delta}$ for some $m < 0$.

It would then follow that
\begin{align*}
    \norm [\Lebesgue 2 \Group] {T \phi}^2
    &= \ip [\Lebesgue 2 \Group] {\adj T T \phi} \phi\\
    &= C \norm [\Lebesgue 2 \Group] {\phi}^2 - \norm [\Lebesgue 2 \Group] {S \phi}^2 + \ip [\Lebesgue 2 \Group] {R \phi} \phi\\
    &\leq C \norm [\Lebesgue 2 \Group] {\phi}^2 + \norm [\Lebesgue 2 \Group] {R \phi} \norm [\Lebesgue 2 \Group] \phi,
\end{align*}
reducing the boundedness of $T$ to that of $R$,
which is much easier to prove.

A sufficient condition to have \eqref{eq:L2_boundedness_decomposition} would be to have
\begin{align*}
    \adj {\sigma_T} \sigma_T = C \Id {\Lebesgue 2 \CompactGroup} - \adj {\sigma_S} \sigma_S,
\end{align*}
on the symbol side,
with $\sigma_S \defeq \Op^{-1}(S)$.
A good candidate for $\sigma_S$ would therefore be
\begin{align}
    \sigma_S \defeq \sqrt{C \Id {\Lebesgue 2 \CompactGroup} - \adj {\sigma_T} \sigma_T}.
    \label{eq:symbol_to_prove_L2_boundedness}
\end{align}

The condition that $S \in \OperatorClass 0 {\rho, \delta}$ is equivalent to showing
that $\sigma_S \in \SymbolClass 0 {\rho, \delta}$.
The crucial part of the proof is therefore to show that~\eqref{eq:symbol_to_prove_L2_boundedness} is a symbol of order $0$.

\begin{lemma}
\label{lemma:inverse_of_square_root_of_a_symbol_of_order_zero}
    Let $\rho, \delta \in \R$ be such that $1 \geq \rho > \delta \geq 0$.
    If $\sigma \in \SymbolClass 0 {\rho, \delta}$ is \emph{positive definite} and \emph{elliptic},
    then the map
    \begin{align*}
        \tilde \sigma(x, k; \lambda)
        \defeq \int_{\Gamma} z^{-\frac 1 2} (\sigma(x, k; \lambda) - z \Id {\Lebesgue 2 \CompactGroup})^{-1} \dd z
        % TODO specify what \gamma is
    \end{align*}
    also belongs to $\SymbolClass 0 {\rho, \delta}$.
\end{lemma}
\begin{proof}
    To shorten the notation,
    we write
    \begin{align*}
        R(z, \sigma)(x, k; \lambda) \defeq (\sigma(x, k; \lambda) - z \Id {\Lebesgue 2 \CompactGroup})^{-1}
    \end{align*}

    Let us now prove the following claim.

    \begin{claim}
        For every $\beta \in \N^{\dim \Group}$, and each $\alpha$
        % TODO: specify set for \alpha
        \begin{align}
            &\norm [\Lin {\Lebesgue 2 \CompactGroup}] {\Rep \lambda \BesselPotential {\rho \abs \alpha - \delta \abs \beta} \LeftDifferentialOperator \beta \DifferenceOperatorOrder \alpha R(z, \sigma)(x, k; \lambda)} \notag\\
            &\qquad \leq C_{\alpha, \beta} (1 + \abs z)^{-1}.
            \label{eq:estimates_on_the_resolvent}
        \end{align}
    \end{claim}
    \begin{proof}[Proof of the claim]
        First let us prove the claim for $\abs \alpha = \abs \beta = 0$.
    \end{proof}

    Using~\eqref{eq:estimates_on_the_resolvent},
    we can show that
    \begin{align*}
        &\norm [\Lin {\Lebesgue 2 \Group}] {\Rep \lambda \BesselPotential {\rho \abs \alpha - \delta \abs \beta} \LeftDifferentialOperator \beta \DifferenceOperatorOrder \alpha \tilde \sigma(x, k; \lambda)}\\
        &\quad \leq C_{\alpha, \beta} \int_\Gamma \abs z^{-\frac 1 2} (1 + \abs z)^{-1} \abs{\dd z} < +\infty,
    \end{align*}
    showing that $\tilde \sigma$ belongs to $\SymbolClass 0 {\rho, \delta}$.
\end{proof}

\begin{corollary}
\label{corollary:square_root_of_a_symbol_of_order_zero}
    Let $\rho, \delta \in \R$ be such that $1 \geq \rho > \delta \geq 0$.
    If $\sigma \in \SymbolClass 0 {\rho, \delta}$ is \emph{positive definite} and \emph{elliptic},
    then its \emph{square root}
    \begin{align*}
        (x, k; \lambda) \in \Group \times \VectorSpace \mapsto \sqrt{\sigma(x, k; \lambda)}
    \end{align*}
    also belongs to $\SymbolClass 0 {\rho, \delta}$.
\end{corollary}
\begin{proof}
    Let $\tilde \sigma$ be the symbol defined in Lemma~\ref{lemma:inverse_of_square_root_of_a_symbol_of_order_zero}.
    By the Helffer-Sjostrand formula,
    % TODO Reference for Helffer-Sjostrand
    we get
    \begin{align*}
        \sqrt{\sigma(x, k; \lambda)} = \tilde \sigma(x, k; \lambda) \sigma(x, k; \lambda),
    \end{align*}
    which must be in $\SymbolClass 0 {\rho, \delta}$,
    since $\tilde \sigma, \sigma \in \SymbolClass 0 {\rho, \delta}$ by Lemma~\ref{lemma:inclusion_in_zero_class}.
\end{proof}

\begin{proposition}[$L^2$ boundedness]
    Let $\rho, \delta \in \R$ be such that $1 \geq \rho > \delta \geq 0$.
    If $\sigma \in \SymbolClass 0 {\rho, \delta}$,
    then its associated operator $T \defeq \Op(\sigma)$ is bounded in $\Lebesgue 2 \Group$,
    i.e.\ we have
    \begin{align*}
        \norm [\Lebesgue 2 \Group] {T \phi} \leq C \norm [\Lebesgue 2 \Group] \phi.
    \end{align*}
    for every $\phi \in \Schwartz \Group$.
\end{proposition}
\begin{proof}
    \begin{description}
        \item[Step 1.] If $\sigma \in \SymbolClass m {\rho, \delta}$ for $m < -1$, then
            \begin{align*}
                \norm [\Lin{\Lebesgue 2 \Group}] {\Op(\sigma)} < \infty.
            \end{align*}
        \item[Step 2.] If $\sigma \in \SymbolClass m {\rho, \delta}$ for $m < 0$, then
            \begin{align*}
                \norm [\Lin{\Lebesgue 2 \Group}] {\Op(\sigma)} < \infty.
            \end{align*}

            Suppose by contradiction that the claim does not hold.
            Therefore, there exists $m < 0$ and $\sigma \in \SymbolClass m {\rho, \delta}$ such that
            $\Op(\sigma)$ is not bounded.
            In particular, for each $n \in \N$,
            \begin{align*}
                (\Op(\sigma) \adj {\Op(\sigma)})^n
            \end{align*}
            is in $\OperatorClass {2 m n} {\rho, \delta}$ and unbounded.
            When $n$ is such that $-2 m n < -1$, this contradicts Step 1.
        \item[Step 3.] Conclusion

            Let $C \geq 0$ be such that
            \begin{align*}
                \sup_{(x, k) \in \Group} \esssup_{\lambda \in \VectorSpace} \norm [\Lebesgue 2 \CompactGroup] {\sigma(x, k; \lambda)} \leq C.
            \end{align*}

            It follows that
            \begin{align*}
                4 C^2 \Id {\Lebesgue 2 \CompactGroup} - \adj \sigma \sigma
            \end{align*}
            is an operator of order $0$,
            and so by Corollary~\ref{corollary:square_root_of_a_symbol_of_order_zero}, the symbol
            \begin{align*}
                \sigma_S \defeq \sqrt{4 C^2 \Id {\Lebesgue 2 \CompactGroup} - \adj \sigma \sigma}
            \end{align*}
            is also in $\SymbolClass 0 {\rho, \delta}$.
            By definition, we have
            \begin{align}
                \adj \sigma \sigma = 4 C^2 \Id {\Lebesgue 2 \CompactGroup} - \adj {\sigma_S} \sigma_S.
                \label{eq:decomposition_of_unity_in_terms_of_symbols_squared}
            \end{align}

            By the adjoint and composition formulas,
            we have
            \begin{align*}
                \Op(\adj \sigma \sigma) = \adj T T + R_1\\
                \Op(\adj {\sigma_S} \sigma_S) = \adj S S +  R_2,
            \end{align*}
            with $R_1, R_2 \in \OperatorClass {\rho - \delta} {\rho, \delta}$.
            Therefore, applying $\Op$ on both sides of~\eqref{eq:decomposition_of_unity_in_terms_of_symbols_squared} yields
            \begin{align*}
                \adj T T = 4 C^2 \Id {\Schwartz \Group} - \adj S S + R,
                \quad R \defeq (R_2 - R_1) \in \OperatorClass {\rho - \delta} {\rho, \delta}.
            \end{align*}

            Now, fix $\phi \in \Lebesgue 2 \Group$.
            Since Step 2 implies that $R$ is bounded,
            we get
            \begin{align*}
                \norm [\Lebesgue 2 \Group] {T \phi}^2
                &= \ip [\Lebesgue 2 \Group] {\adj T T \phi} \phi\\
                &= 4 C^2 \norm [\Lebesgue 2 \Group] \phi^2 - \norm [\Lebesgue 2 \Group] {S \phi}^2 + \ip [\Lebesgue 2 \Group] {R \phi} {\phi}\\
                &\leq (4 C^2 + \norm [\Lin {\Lebesgue 2 \Group}] R) \norm [\Lebesgue 2 \Group] \phi^2,
            \end{align*}
            concluding the proof.
    \end{description}
\end{proof}

\subsection{Calder\'on-Zygmund theory}

\begin{definition}[Calder\'on-Zygmund kernel]
    We shall say that a measurable map
    \begin{align*}
        \kappa : (\Group \times \Group) \setminus \{(g, g) : g \in \Group\} \to \C
    \end{align*}
    is a \emph{Calder\'on-Zygmund kernel}
    if there exists $\gamma \in (0, 1]$,
    $C \geq 0$ and $A \geq 0$ such that the estimates
    \begin{align*}
        \abs {\kappa(g, h)} &\leq A \norm [\Group] {h^{-1} g}^{-\dim \Group} &\\
        \abs {\kappa(g, h) - \kappa(g', h)} &\leq A \frac {\norm [\Group] {g^{-1} g'}^{\gamma}} {\norm [\Group] {h^{-1} g}^{\dim \Group + \gamma}}
        &\text{ if } \norm [\Group] {g^{-1} g'} \leq \frac {\norm [\Group] {h^{-1} g}} 2\\
        \abs {\kappa(g, h) - \kappa(g, h')} &\leq A \frac {\norm [\Group] {h^{-1} h'}^{\gamma}} {\norm [\Group] {h^{-1} g}^{\dim \Group + \gamma}}
        &\text{ if } \norm [\Group] {h^{-1} h'} \leq \frac {\norm [\Group] {h^{-1} g}} 2
    \end{align*}
    hold for every $g, g', h, h' \in \Group$ satisfying
    \begin{align*}
        g \neq h, \quad
        g' \neq h, \quad
        g \neq h'.
    \end{align*}
\end{definition}

\section{Applications to partial differential equations}
